---
# Source: druid/templates/broker/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-druid-broker
  labels:
    app: druid
    chart: druid-1.15.2
    component: broker
    release: my-druid
    heritage: Helm
---
# Source: druid/templates/coordinator/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-druid-coordinator
  labels:
    app: druid
    chart: druid-1.15.2
    component: coordinator
    release: my-druid
    heritage: Helm
---
# Source: druid/templates/historical/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-druid-historical
  labels:
    app: druid
    chart: druid-1.15.2
    component: historical
    release: my-druid
    heritage: Helm
---
# Source: druid/templates/indexer/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-druid-indexer
  labels:
    app: druid
    chart: druid-1.15.2
    component: indexer
    release: my-druid
    heritage: Helm
---
# Source: druid/templates/router/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: true
metadata:
  name: my-druid-router
  labels:
    app: druid
    chart: druid-1.15.2
    component: router
    release: my-druid
    heritage: Helm
---
# Source: druid/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-druid-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-11.6.14
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  postgres-password: "cG9zdGdyZXM="
  password: "ZHJ1aWQ="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: druid/templates/broker/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-broker-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
stringData:
---
# Source: druid/templates/coordinator/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-coordinator-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
stringData:
---
# Source: druid/templates/historical/secret-historical-individual.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-historical-default-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
type: Opaque
data:
---
# Source: druid/templates/historical/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-historical-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
stringData:
---
# Source: druid/templates/indexer/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-indexer-default-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
stringData:
---
# Source: druid/templates/indexer/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-indexer-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
stringData:
  {}
---
# Source: druid/templates/router/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-router-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: router
stringData:
---
# Source: druid/templates/secret.yaml
kind: Secret
apiVersion: v1
metadata:
  name: my-druid-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
stringData:
  druid_metadata_storage_connector_password: "druid"
---
# Source: druid/templates/broker/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-broker-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
data:
---
# Source: druid/templates/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
data:
  druid_metadata_storage_type: postgresql
  druid_metadata_storage_connector_connectURI: jdbc:postgresql://my-druid-postgresql:5432/druid
  druid_metadata_storage_connector_user: "druid"
  DRUID_LOG4J: "<?xml version=\"1.0\" encoding=\"UTF-8\" ?>\n<Configuration status=\"WARN\">\n  <Appenders>\n    <Console name=\"Console\" target=\"SYSTEM_OUT\">\n      <PatternLayout pattern=\"%d{ISO8601} %p [%t] %c -%notEmpty{ [%markerSimpleName]} %m%n\"/>\n    </Console>\n  </Appenders>\n\n  <Loggers>\n    <Root level=\"info\">\n      <AppenderRef ref=\"Console\"/>\n    </Root>\n\n    <!-- Set level=\"debug\" to see stack traces for query errors -->\n    <Logger name=\"org.apache.druid.server.QueryResource\" level=\"info\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n    <Logger name=\"org.apache.druid.server.QueryLifecycle\" level=\"info\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n\n    <!-- Set level=\"debug\" or \"trace\" to see more Coordinator details (segment balancing, load/drop rules, etc) -->\n    <Logger name=\"org.apache.druid.server.coordinator\" level=\"info\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n\n    <!-- Set level=\"debug\" to see low-level details about segments and ingestion -->\n    <Logger name=\"org.apache.druid.segment\" level=\"info\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n\n    <!-- Set level=\"debug\" to see more information about extension initialization -->\n    <Logger name=\"org.apache.druid.initialization\" level=\"info\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n\n    <!-- Quieter logging at startup -->\n    <Logger name=\"org.skife.config\" level=\"warn\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n    <Logger name=\"com.sun.jersey.guice\" level=\"warn\" additivity=\"false\">\n      <Appender-ref ref=\"Console\"/>\n    </Logger>\n  </Loggers>\n</Configuration>\n"
  druid_coordinator_loadqueuepeon_type: "http"
  druid_discovery_k8s_clusterIdentifier: "druid-default"
  druid_discovery_type: "k8s"
  druid_emitter: "noop"
  druid_emitter_logging_logLevel: "debug"
  druid_indexer_logs_directory: "/opt/data/indexing-logs"
  druid_indexer_logs_type: "file"
  druid_indexer_runner_type: "httpRemote"
  druid_serverview_type: "http"
  druid_storage_type: "local"
  druid_zk_service_enabled: "false"
---
# Source: druid/templates/coordinator/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-coordinator-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
data:
---
# Source: druid/templates/historical/configmap-historical-individual.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-historical-default-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
data:
  
  DRUID_MAXDIRECTMEMORYSIZE: "400m"
  DRUID_XMS: "256m"
  DRUID_XMX: "256m"
  druid_segmentCache_locations: "[{\"path\":\"/opt/druid/var/druid/segment-cache\",\"maxSize\":\"1GiB\"}]"
  druid_server_tier: "tier_default"
---
# Source: druid/templates/historical/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-historical-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
data:
  druid_processing_buffer_sizeBytes: "50000000"
  druid_processing_numMergeBuffers: "2"
  druid_processing_numThreads: "1"
---
# Source: druid/templates/indexer/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-indexer-default-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
data:
  DRUID_XMS: 256m
  DRUID_XMX: 256m
  druid_worker_capacity: "1"
  druid_worker_category: default
---
# Source: druid/templates/indexer/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-indexer-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
data:
---
# Source: druid/templates/router/configmap.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-druid-router-config
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: router
data:
  druid_router_managementProxy_enabled: "true"
---
# Source: druid/templates/broker/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-druid-broker
  labels:
    app: druid
    chart: druid-1.15.2
    component: broker
    release: my-druid
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
---
# Source: druid/templates/coordinator/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-druid-coordinator
  labels:
    app: druid
    chart: druid-1.15.2
    component: coordinator
    release: my-druid
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
  - apiGroups:
      - batch
    resources:
      - jobs
    verbs:
      - '*'
---
# Source: druid/templates/historical/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-druid-historical
  labels:
    app: druid
    chart: druid-1.15.2
    component: historical
    release: my-druid
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
---
# Source: druid/templates/indexer/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-druid-indexer
  labels:
    app: druid
    chart: druid-1.15.2
    component: indexer
    release: my-druid
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
---
# Source: druid/templates/router/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-druid-router
  labels:
    app: druid
    chart: druid-1.15.2
    component: router
    release: my-druid
    heritage: Helm
rules:
  - apiGroups:
      - ""
    resources:
      - pods
      - configmaps
    verbs:
      - '*'
---
# Source: druid/templates/broker/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-druid-broker
  labels:
    app: druid
    chart: druid-1.15.2
    component: broker
    release: my-druid
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-druid-broker
subjects:
  - kind: ServiceAccount
    name: my-druid-broker
    namespace: default
---
# Source: druid/templates/coordinator/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-druid-coordinator
  labels:
    app: druid
    chart: druid-1.15.2
    component: coordinator
    release: my-druid
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-druid-coordinator
subjects:
  - kind: ServiceAccount
    name: my-druid-coordinator
    namespace: default
---
# Source: druid/templates/historical/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-druid-historical
  labels:
    app: druid
    chart: druid-1.15.2
    component: historical
    release: my-druid
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-druid-historical
subjects:
  - kind: ServiceAccount
    name: my-druid-historical
    namespace: default
---
# Source: druid/templates/indexer/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-druid-indexer
  labels:
    app: druid
    chart: druid-1.15.2
    component: indexer
    release: my-druid
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-druid-indexer
subjects:
  - kind: ServiceAccount
    name: my-druid-indexer
    namespace: default
---
# Source: druid/templates/router/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-druid-router
  labels:
    app: druid
    chart: druid-1.15.2
    component: router
    release: my-druid
    heritage: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-druid-router
subjects:
  - kind: ServiceAccount
    name: my-druid-router
    namespace: default
---
# Source: druid/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-11.6.14
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: primary
---
# Source: druid/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-11.6.14
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: primary
---
# Source: druid/templates/broker/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-broker-0
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
    statefulset.kubernetes.io/pod-name: my-druid-broker-0
spec:
  type: ClusterIP
  ports:
    - port: 8082
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: broker
    statefulset.kubernetes.io/pod-name: my-druid-broker-0
---
# Source: druid/templates/broker/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-broker
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
spec:
  type: ClusterIP
  ports:
    - port: 8082
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: broker
---
# Source: druid/templates/coordinator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-coordinator-0
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
    statefulset.kubernetes.io/pod-name: my-druid-coordinator-0
spec:
  type: ClusterIP
  ports:
    - port: 8081
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: coordinator
    statefulset.kubernetes.io/pod-name: my-druid-coordinator-0
---
# Source: druid/templates/coordinator/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-coordinator
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
spec:
  type: ClusterIP
  ports:
    - port: 8081
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: coordinator
---
# Source: druid/templates/historical/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-historical-default-0
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
    statefulset.kubernetes.io/pod-name: my-druid-historical-default-0
spec:
  type: ClusterIP
  ports:
    - port: 8083
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
    statefulset.kubernetes.io/pod-name: my-druid-historical-default-0
---
# Source: druid/templates/historical/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-historical-default
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
spec:
  type: ClusterIP
  ports:
    - port: 8083
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
---
# Source: druid/templates/indexer/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-indexer-default-0
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
    statefulset.kubernetes.io/pod-name: my-druid-indexer-default-0
spec:
  type: ClusterIP
  ports:
    - port: 8091
      targetPort: http
      protocol: TCP
      name: http
    - port: 8100
      targetPort: 8100
      protocol: TCP
      name: http-peon-0
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
    statefulset.kubernetes.io/pod-name: my-druid-indexer-default-0
---
# Source: druid/templates/indexer/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-indexer-default
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
spec:
  type: ClusterIP
  ports:
    - port: 8091
      targetPort: http
      protocol: TCP
      name: http
    - port: 8100
      targetPort: 8100
      protocol: TCP
      name: http-peon-0
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
---
# Source: druid/templates/router/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-router-0
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: router
    statefulset.kubernetes.io/pod-name: my-druid-router-0
spec:
  type: ClusterIP
  ports:
    - port: 8888
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: router
    statefulset.kubernetes.io/pod-name: my-druid-router-0
---
# Source: druid/templates/router/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-druid-router
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: router
spec:
  type: ClusterIP
  ports:
    - port: 8888
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: druid
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/component: router
---
# Source: druid/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: postgresql
    helm.sh/chart: postgresql-11.6.14
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: primary
  annotations:
spec:
  replicas: 1
  serviceName: my-druid-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-druid-postgresql
      labels:
        app.kubernetes.io/name: postgresql
        helm.sh/chart: postgresql-11.6.14
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: primary
      annotations:
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/instance: my-druid
                    app.kubernetes.io/component: primary
                namespaces:
                  - "default"
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:14.4.0-debian-11-r4
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "druid"
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-druid-postgresql
                  key: postgres-password
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-druid-postgresql
                  key: password
            - name: POSTGRES_DB
              value: "druid"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "druid" -d "dbname=druid" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                
                - |
                  exec pg_isready -U "druid" -d "dbname=druid" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: druid/templates/broker/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-broker
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: broker
spec:
  replicas: 1
  podManagementPolicy: Parallel
  serviceName: my-druid-broker
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: druid
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/component: broker
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: broker
      annotations:
        druid.k8s.enablePatching: "true"
        checksum/configmap: 36394d97782a126e4ae3486f2c37441b7ae7bad58dfa9f3c409a8bc667bc9e9b
        checksum/secret: 61395733a2428f71f12e6cbd60f441f905e9827afcab123707bf2c8f71d6bbbe
        checksum/configmap-broker: 1683d669de01a25706c1f49dad2615cde5aa6c57b41884685cb6677da9f51a9f
        checksum/secret-broker: 39b13bdd7bdcd9e3a548a0d8d342c6ee175b1bb565891b6117f13a2f787982d9
    spec:
      securityContext:
        fsGroup: 1000
      serviceAccountName: my-druid-broker
      containers:
        - name: my-druid-broker
          image: "apache/druid:26.0.0"
          imagePullPolicy: IfNotPresent
          args: [ "broker" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: druid_host
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: druid_extensions_loadList
              value: "[\"druid-basic-security\",\"druid-bloom-filter\",\"druid-datasketches\",\"druid-histogram\",\"druid-kinesis-indexing-service\",\"druid-kubernetes-extensions\",\"druid-lookups-cached-global\",\"druid-lookups-cached-single\",\"druid-pac4j\",\"druid-parquet-extensions\",\"druid-s3-extensions\",\"druid-stats\",\"postgresql-metadata-storage\",\"prometheus-emitter\"]"
          envFrom:
            - configMapRef:
                name: my-druid-config
            - configMapRef:
                name: my-druid-broker-config
            - secretRef:
                name: my-druid-config
            - secretRef:
                name: my-druid-broker-config
          ports:
            - name: http
              containerPort: 8082
              protocol: TCP
          livenessProbe:
            failureThreshold: 60
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
            httpGet:
              path: /status/health
              port: http
          readinessProbe:
            failureThreshold: 30
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
            httpGet:
              path: /druid/broker/v1/readiness
              port: http
---
# Source: druid/templates/coordinator/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-coordinator
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: coordinator
spec:
  replicas: 1
  podManagementPolicy: Parallel
  serviceName: my-druid-coordinator
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: druid
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/component: coordinator
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: coordinator
      annotations:
        druid.k8s.enablePatching: "true"
        checksum/configmap: 36394d97782a126e4ae3486f2c37441b7ae7bad58dfa9f3c409a8bc667bc9e9b
        checksum/secret: 61395733a2428f71f12e6cbd60f441f905e9827afcab123707bf2c8f71d6bbbe
        checksum/configmap-coordinator: b878c16bc1e10c4ba050071a3b5334bed35855b41e6afa6e5f035c97c6898de6
        checksum/secret-coordinator: 1763ca8bdb6dc4db6d3f898cb1d2e12e91cf85bdbca385c3185db2cfd73af0f3
    spec:
      securityContext:
        fsGroup: 1000
      serviceAccountName: my-druid-coordinator
      containers:
        - name: my-druid-coordinator
          image: "apache/druid:26.0.0"
          imagePullPolicy: IfNotPresent
          args: [ "coordinator" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: druid_host
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: druid_extensions_loadList
              value: "[\"druid-basic-security\",\"druid-bloom-filter\",\"druid-datasketches\",\"druid-histogram\",\"druid-kinesis-indexing-service\",\"druid-kubernetes-extensions\",\"druid-lookups-cached-global\",\"druid-lookups-cached-single\",\"druid-pac4j\",\"druid-parquet-extensions\",\"druid-s3-extensions\",\"druid-stats\",\"postgresql-metadata-storage\",\"prometheus-emitter\"]"
          envFrom:
            - configMapRef:
                name: my-druid-config
            - configMapRef:
                name: my-druid-coordinator-config
            - secretRef:
                name: my-druid-config
            - secretRef:
                name: my-druid-coordinator-config
          ports:
            - name: http
              containerPort: 8081
              protocol: TCP
          livenessProbe:
            failureThreshold: 15
            initialDelaySeconds: 60
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 60
            httpGet:
              path: /status/health
              port: http
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 60
            periodSeconds: 15
            successThreshold: 1
            timeoutSeconds: 60
            httpGet:
              path: /status/selfDiscovered
              port: http
---
# Source: druid/templates/historical/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-historical-default
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: historical
    app.kubernetes.io/component: historical-default
spec:
  replicas: 1
  podManagementPolicy: Parallel
  serviceName: my-druid-historical-default
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: druid
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/part-of: historical
      app.kubernetes.io/component: historical-default
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: historical
        app.kubernetes.io/component: historical-default
      annotations:
        druid.k8s.enablePatching: "true"
        checksum/configmap: 36394d97782a126e4ae3486f2c37441b7ae7bad58dfa9f3c409a8bc667bc9e9b
        checksum/configmap-historicals: c768f22967e5fe23f7b0fa5a5cf33713e343fdce0ac617530ef5244bb76d47ad
        checksum/configmap-historicals-individual: 908d916c2bf21e8ad40f91d366ac38917059cd52f517510d1c03e905cec85eb2
        checksum/secret: 61395733a2428f71f12e6cbd60f441f905e9827afcab123707bf2c8f71d6bbbe
        checksum/secret-historicals: ff2b3d310b258673d3efb236d5681c5b2dda1a629c7ca805267e3222bf1def72
        checksum/secret-historicals-individual: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
    spec:
      nodeSelector:
        {}
      securityContext:
        fsGroup: 1000
      serviceAccountName: my-druid-historical
      containers:
        - name: historical
          image: "apache/druid:26.0.0"
          imagePullPolicy: "IfNotPresent"
          args: [ "historical" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: druid_host
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: druid_extensions_loadList
              value: "[\"druid-basic-security\",\"druid-bloom-filter\",\"druid-datasketches\",\"druid-histogram\",\"druid-kinesis-indexing-service\",\"druid-kubernetes-extensions\",\"druid-lookups-cached-global\",\"druid-lookups-cached-single\",\"druid-pac4j\",\"druid-parquet-extensions\",\"druid-s3-extensions\",\"druid-stats\",\"postgresql-metadata-storage\",\"prometheus-emitter\"]"
          # Order defines precedence
          envFrom:
            - configMapRef:
                name: my-druid-config
            - secretRef:
                name: my-druid-config
            - configMapRef:
                name: my-druid-historical-config
            - secretRef:
                name: my-druid-historical-config
            - configMapRef:
                name: my-druid-historical-default-config
            - secretRef:
                name: my-druid-historical-default-config
          ports:
            - containerPort: 8083
              name: http
          startupProbe:
            failureThreshold: 400
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
            httpGet:
              path: /status/health
              port: http
          livenessProbe:
            failureThreshold: 60
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
            httpGet:
              path: /status/health
              port: http
          readinessProbe:
            failureThreshold: 30
            initialDelaySeconds: 60
            periodSeconds: 60
            successThreshold: 1
            timeoutSeconds: 10
            httpGet:
              path: /druid/historical/v1/readiness
              port: http
          resources:
            {}
          volumeMounts:
            - mountPath: /opt/druid/var
              name: data
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - ReadWriteOnce
        resources:
          requests:
            storage: "2Gi"
---
# Source: druid/templates/indexer/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-indexer-default
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: indexer
    app.kubernetes.io/component: indexer-default
spec:
  replicas: 1
  podManagementPolicy: Parallel
  serviceName: my-druid-indexer-default
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: druid
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/part-of: indexer
      app.kubernetes.io/component: indexer-default
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/part-of: indexer
        app.kubernetes.io/component: indexer-default
      annotations:
        druid.k8s.enablePatching: "true"
        # This restarts all indexers for now as we use the same file
        checksum/configmap: 36394d97782a126e4ae3486f2c37441b7ae7bad58dfa9f3c409a8bc667bc9e9b
        checksum/secret: 61395733a2428f71f12e6cbd60f441f905e9827afcab123707bf2c8f71d6bbbe
        checksum/configmap-indexers: 1e6c96efcf3704a51b85dfc774260be5ab7ef8b12065fb6223b292b488b6ebd1
        checksum/secret-indexers: d4e697eee2f9fdd8e4b4828b974f5f30c2099a88a5af4bc634d1ba7dd79f4ea4
    spec:
      nodeSelector:
        {}
      securityContext:
        fsGroup: 1000
      serviceAccountName: my-druid-indexer
      containers:
        - name: indexer
          image: "apache/druid:26.0.0"
          imagePullPolicy: "IfNotPresent"
          args: [ "middleManager" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: druid_host
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: druid_extensions_loadList
              value: "[\"druid-basic-security\",\"druid-bloom-filter\",\"druid-datasketches\",\"druid-histogram\",\"druid-kinesis-indexing-service\",\"druid-kubernetes-extensions\",\"druid-lookups-cached-global\",\"druid-lookups-cached-single\",\"druid-pac4j\",\"druid-parquet-extensions\",\"druid-s3-extensions\",\"druid-stats\",\"postgresql-metadata-storage\",\"prometheus-emitter\"]"
          envFrom:
            - configMapRef:
                name: my-druid-config
            - configMapRef:
                name: my-druid-indexer-default-config
            - secretRef:
                name: my-druid-config
            - secretRef:
                name: my-druid-indexer-default-config
          ports:
            - containerPort: 8091
              name: http
          livenessProbe:
            failureThreshold: 15
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /status/health
              port: http
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            httpGet:
              path: /status/selfDiscovered
              port: http
          resources:
            {}
          volumeMounts:
            - mountPath: /opt/druid/var
              name: data
      volumes:
        - name: data
          emptyDir:
            sizeLimit: "1Gi"
---
# Source: druid/templates/router/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-druid-router
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: router
spec:
  replicas: 1
  podManagementPolicy: Parallel
  serviceName: my-druid-router
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: druid
      app.kubernetes.io/instance: my-druid
      app.kubernetes.io/component: router
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: router
        druid.k8s.enablePatching: "true"
      annotations:
        checksum/configmap: 36394d97782a126e4ae3486f2c37441b7ae7bad58dfa9f3c409a8bc667bc9e9b
        checksum/secret: 61395733a2428f71f12e6cbd60f441f905e9827afcab123707bf2c8f71d6bbbe
        checksum/configmap-router: 81523c7e81e7a4dcb252b5d85e64887bec564042b14bfae7bd926db23b987ba4
        checksum/secret-router: 860a713c07bcb33194524b6061d50b2ed1c0d8a71c2816e2bfb26443dbffacbf
    spec:
      securityContext:
        fsGroup: 1000
      serviceAccountName: my-druid-router
      containers:
        - name: my-druid-router
          image: "apache/druid:26.0.0"
          imagePullPolicy: IfNotPresent
          args: [ "router" ]
          env:
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: druid_host
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: druid_extensions_loadList
              value: "[\"druid-basic-security\",\"druid-bloom-filter\",\"druid-datasketches\",\"druid-histogram\",\"druid-kinesis-indexing-service\",\"druid-kubernetes-extensions\",\"druid-lookups-cached-global\",\"druid-lookups-cached-single\",\"druid-pac4j\",\"druid-parquet-extensions\",\"druid-s3-extensions\",\"druid-stats\",\"postgresql-metadata-storage\",\"prometheus-emitter\"]"
            - name: druid_router_tierToBrokerMap
              value: '{"tier_default":"druid/broker"}'
          envFrom:
            - configMapRef:
                name: my-druid-config
            - configMapRef:
                name: my-druid-router-config
            - secretRef:
                name: my-druid-config
            - secretRef:
                name: my-druid-router-config
          ports:
            - name: http
              containerPort: 8888
              protocol: TCP
          livenessProbe:
            failureThreshold: 15
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /status/health
              port: http
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 60
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 1
            httpGet:
              path: /status/selfDiscovered
              port: http
---
# Source: druid/templates/config/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-druid-config-job-overlord-dyn-cfg
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: config-job-overlord-dyn-cfg
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation
data:
  config.json:
    "{\"selectStrategy\":{\"type\":\"equalDistributionWithCategorySpec\",\"workerCategorySpec\":{\"categoryMap\":{\"compact\":{\"defaultCategory\":\"default\"},\"index\":{\"defaultCategory\":\"default\"},\"index_parallel\":{\"defaultCategory\":\"default\"},\"kill\":{\"defaultCategory\":\"default\"},\"single_phase_sub_task\":{\"defaultCategory\":\"default\"}},\"strong\":true}}}"
---
# Source: druid/templates/config/job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-druid-config-job-overlord-dyn-cfg
  labels:
    app.kubernetes.io/name: druid
    helm.sh/chart: druid-1.15.2
    app.kubernetes.io/instance: my-druid
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/component: config-job-overlord-dyn-cfg
  annotations:
    "helm.sh/hook": post-install,post-upgrade
    "helm.sh/hook-delete-policy": before-hook-creation
spec:
  backoffLimit: 7
  ttlSecondsAfterFinished: 3600
  template:
    metadata:
      labels:
        app.kubernetes.io/name: druid
        helm.sh/chart: druid-1.15.2
        app.kubernetes.io/instance: my-druid
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/component: config-job-overlord-dyn-cfg
    spec:
      securityContext:
        fsGroup: 1000
      restartPolicy: Never
      containers:
        - name: job
          image: curlimages/curl:8.5.0
          command: ["curl"]
          args:
            - "-v"
            - "--fail-with-body"
            - "--connect-timeout"
            - "5"
            - "--max-time"
            - "10"
            - "--retry-connrefused"
            - "--retry"
            - "180"
            - "--retry-delay"
            - "1"
            - "--retry-max-time"
            - "180"
            - "-X"
            - "POST"
            - http://my-druid-coordinator:8081/druid/indexer/v1/worker
            - "-H"
            - "Content-Type: application/json"
            - "-H"
            - "X-Druid-Author: config-job-overlord-dyn-cfg"
            - "-H"
            - "X-Druid-Comment: changed by config-job"
            - "-d"
            - "@/config.json"
          volumeMounts:
            - name: config
              mountPath: /config.json
              subPath: config.json
      volumes:
        - name: config
          configMap:
            name: my-druid-config-job-overlord-dyn-cfg
            defaultMode: 420
