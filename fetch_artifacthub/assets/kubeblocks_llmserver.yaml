---
# Source: llmserver/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-llmserver
  labels:
    helm.sh/chart: llmserver-0.3.0
    app.kubernetes.io/name: llmserver
    app.kubernetes.io/instance: my-llmserver
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: llmserver/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-llmserver-baichuan-13b
  labels:
    helm.sh/chart: llmserver-0.3.0
    app.kubernetes.io/name: llmserver
    app.kubernetes.io/instance: my-llmserver
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: llmserver
    app.kubernetes.io/instance: my-llmserver
    chat.kubeblocks.io/model-name: baichuan-13b
---
# Source: llmserver/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-llmserver-baichuan-13b
  labels:
    helm.sh/chart: llmserver-0.3.0
    app.kubernetes.io/name: llmserver
    app.kubernetes.io/instance: my-llmserver
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: llmserver
      app.kubernetes.io/instance: my-llmserver
      chat.kubeblocks.io/model-name: baichuan-13b
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 25%
  template:
    metadata:
      labels:
        app.kubernetes.io/name: llmserver
        app.kubernetes.io/instance: my-llmserver
        chat.kubeblocks.io/model-name: baichuan-13b
    spec:
      serviceAccountName: my-llmserver
      securityContext:
        {}
      containers:
        - name: llmserver
          securityContext:
            {}
          image: "registry.cn-hangzhou.aliyuncs.com/apecloud/kubechat-llmserver:v0.1.1"
          imagePullPolicy: IfNotPresent
          command:
            - /bin/sh
            - -c
            - |
              mkdir -p /app/resources
              ln -s /data/models /app/resources
              uvicorn server.llmserver:app --host 0.0.0.0 --log-config uvicorn-log-config.yaml
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          volumeMounts:
            - name: data
              mountPath: /data
          env:
            - name: LLM_MODEL
              value: "baichuan-13b"
          resources:
            limits:
              nvidia.com/gpu: 1
      nodeSelector:
        null
      volumes:
        - name: data
          hostPath:
            path: /data/kubechat
---
# Source: llmserver/templates/tests/test-connection.yaml
apiVersion: v1
kind: Pod
metadata:
  name: "my-llmserver-test-connection"
  labels:
    helm.sh/chart: llmserver-0.3.0
    app.kubernetes.io/name: llmserver
    app.kubernetes.io/instance: my-llmserver
    app.kubernetes.io/version: "0.1.1"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": test
spec:
  containers:
    - name: wget
      image: busybox
      command: ['wget']
      args: ['my-llmserver:8000']
  restartPolicy: Never
