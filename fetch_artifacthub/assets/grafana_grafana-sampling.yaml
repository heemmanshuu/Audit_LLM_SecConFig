---
# Source: grafana-sampling/charts/alloy-deployment/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-grafana-sampling
  namespace: default
  labels:
    helm.sh/chart: alloy-deployment-0.6.0
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
---
# Source: grafana-sampling/templates/configmap_deployment.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-grafana-sampling-deployment
  labels:
    helm.sh/chart: grafana-sampling-1.0.1
    app.kubernetes.io/name: grafana-sampling
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
data:
  config.alloy: |-
    otelcol.receiver.otlp "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.receiver.otlp/
    
      // configures the default grpc endpoint "0.0.0.0:4317"
      grpc { }
      // configures the default http/protobuf endpoint "0.0.0.0:4318"
      http { }
    
      output {
        traces = [otelcol.processor.batch.default.input]
      }
    }
    
    otelcol.processor.batch "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.batch/
      output {
        traces = [otelcol.exporter.loadbalancing.default.input]
      }
    }
    
    otelcol.exporter.loadbalancing "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.exporter.loadbalancing/
      resolver {
    
        kubernetes {
          service = "my-grafana-sampling-statefulset.default"
        }
      }
    
      protocol {
        otlp {
          client {
            tls {
              insecure = true
            }
          }
        }
      }
    }
---
# Source: grafana-sampling/templates/configmap_statefulset.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-grafana-sampling-statefulset
  labels:
    helm.sh/chart: grafana-sampling-1.0.1
    app.kubernetes.io/name: grafana-sampling
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
data:
   config.alloy: |-
    otelcol.receiver.otlp "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.receiver.otlp/
    
      // configures the default grpc endpoint "0.0.0.0:4317"
      grpc { }
    
      output {
        traces = [
          
          otelcol.processor.tail_sampling.default.input,
          
          
          otelcol.connector.servicegraph.default.input,
          otelcol.processor.transform.drop_unneeded_resource_attributes.input,
          
        ]
      }
    }
    
    otelcol.connector.spanmetrics "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.connector.spanmetrics/
      dimension {
        name = "service.namespace"
      }
      dimension {
        name = "service.version"
      }
      dimension {
        name = "deployment.environment"
      }
      dimension {
        name = "k8s.cluster.name"
      }
    
      resource_metrics_key_attributes = [
        "service.name",
        "span.name",
        "span.kind",
        "status.code",
        "service.namespace",
        "service.version",
        "deployment.environment",
        "k8s.cluster.name",
      ]
    
      
      namespace = "traces.spanmetrics"
    
      histogram {
        unit = "s"
    
        explicit {
          buckets = ["0s", "0.005s", "0.01s", "0.025s", "0.05s", "0.075s", "0.1s", "0.25s", "0.5s", "0.75s", "1s", "2.5s", "5s", "7.5s", "10s"]
        }
      }
    
      output {
        metrics = [otelcol.processor.filter.drop_unneeded_span_metrics.input]
      }
    }
    
    
    
    otelcol.processor.transform "drop_unneeded_resource_attributes" {
        // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
        error_mode = "ignore"
    
        trace_statements {
            context = "resource"
            statements = [
                "delete_key(attributes, \"k8s.pod.start_time\")",
                "delete_key(attributes, \"os.description\")",
                "delete_key(attributes, \"os.type\")",
                "delete_key(attributes, \"process.command_args\")",
                "delete_key(attributes, \"process.executable.path\")",
                "delete_key(attributes, \"process.pid\")",
                "delete_key(attributes, \"process.runtime.description\")",
                "delete_key(attributes, \"process.runtime.name\")",
                "delete_key(attributes, \"process.runtime.version\")",
            ]
        }
    
        output {
            traces = [otelcol.connector.spanmetrics.default.input]
        }
    }
    
    otelcol.processor.transform "use_grafana_metric_names" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.transform/
      error_mode = "ignore"
    
      metric_statements {
        context    = "metric"
        statements = [
          "set(name, \"traces.spanmetrics.latency\") where name == \"traces.spanmetrics.duration\"",
          "set(name, \"traces.spanmetrics.calls.total\") where name == \"traces.spanmetrics.calls\"",
        ]
      }
    
      output {
        metrics = [otelcol.processor.batch.default.input]
      }
    }
    
    otelcol.processor.filter "drop_unneeded_span_metrics" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.filter/
      error_mode = "ignore"
    
      metrics {
        datapoint = [
          "IsMatch(metric.name, \"traces.spanmetrics.calls|traces.spanmetrics.duration\") and IsMatch(attributes[\"span.kind\"], \"SPAN_KIND_INTERNAL|SPAN_KIND_CLIENT|SPAN_KIND_PRODUCER\")",
        ]
      }
    
      output {
        // TODO: only use grafana_metric_names is legacy is enabled.
        
            metrics = [otelcol.processor.transform.use_grafana_metric_names.input]
        
      }
    }
    
    otelcol.connector.servicegraph "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.connector.servicegraph/
      dimensions = [
        "service.namespace",
        "service.version",
        "deployment.environment",
        "k8s.cluster.name",
      ]
      latency_histogram_buckets = ["0s", "0.005s", "0.01s", "0.025s", "0.05s", "0.075s", "0.1s", "0.25s", "0.5s", "0.75s", "1s", "2.5s", "5s", "7.5s", "10s"]
    
      store {
        ttl = "2s"
      }
    
      output {
        metrics = [otelcol.processor.batch.default.input]
      }
    }
    
    otelcol.exporter.prometheus "grafana_cloud_prometheus" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.exporter.prometheus/
      add_metric_suffixes = false
      forward_to          = [prometheus.remote_write.grafana_cloud_prometheus.receiver]
    }
    
    prometheus.remote_write "grafana_cloud_prometheus" {
      // https://grafana.com/docs/alloy/latest/reference/components/prometheus.remote_write/
      endpoint {
        url = env("GRAFANA_CLOUD_PROMETHEUS_URL")
    
        basic_auth {
          username = env("GRAFANA_CLOUD_PROMETHEUS_USERNAME")
          password = env("GRAFANA_CLOUD_API_KEY")
        }
        queue_config {
          retry_on_http_429 = false
        }
      }
      external_labels = {
        "__metrics_gen_instance" = env("POD_UID"),
      }
    }
    
    otelcol.processor.tail_sampling "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.tail_sampling/
    
      decision_wait = "15s"
    
    
        policy {
          name = "sample-successful-requests"
          type = "and"
          and {
            and_sub_policy {
              name = "status-code-policy"
              type = "status_code"
              status_code {
                status_codes = ["OK", "UNSET"]
              }
            }
            and_sub_policy {
              name = "probabilistic-policy"
              type = "probabilistic"
              probabilistic {
                sampling_percentage = 10
              }
            }
          }
        }
    
    
    
    
      policy {
        name = "sample-long-requests"
        type = "and"
        and {
          and_sub_policy {
            name = "latency"
            type = "latency"
            latency {
              threshold_ms = 5000
            }
          }
          and_sub_policy {
           name = "probabilistic-policy"
           type = "probabilistic"
            probabilistic {
             sampling_percentage = 50
            }
          }
        }
      }
    
      output {
        traces = [otelcol.processor.batch.default.input]
      }
    }
    
    otelcol.processor.batch "default" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.processor.batch/
      output {
        
        metrics = [otelcol.exporter.prometheus.grafana_cloud_prometheus.input]
        
        traces  = [otelcol.exporter.otlp.grafana_cloud_tempo.input]
      }
    }
    
    otelcol.exporter.otlp "grafana_cloud_tempo" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.exporter.otlp/
      client {
        endpoint = env("GRAFANA_CLOUD_TEMPO_ENDPOINT")
        auth     = otelcol.auth.basic.grafana_cloud_tempo.handler
      }
    }
    
    otelcol.auth.basic "grafana_cloud_tempo" {
      // https://grafana.com/docs/alloy/latest/reference/components/otelcol.auth.basic/
      username = env("GRAFANA_CLOUD_TEMPO_USERNAME")
      password = env("GRAFANA_CLOUD_API_KEY")
    }
---
# Source: grafana-sampling/charts/alloy-deployment/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: my-grafana-sampling-deployment
  labels:
    helm.sh/chart: alloy-deployment-0.6.0
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
rules:
  # Rules which allow discovery.kubernetes to function.
  - apiGroups:
      - ""
      - "discovery.k8s.io"
      - "networking.k8s.io"
    resources:
      - endpoints
      - endpointslices
      - ingresses
      - nodes
      - nodes/proxy
      - nodes/metrics
      - pods
      - services
    verbs:
      - get
      - list
      - watch
  # Rules which allow loki.source.kubernetes and loki.source.podlogs to work.
  - apiGroups:
      - ""
    resources:
      - pods
      - pods/log
      - namespaces
    verbs:
      - get
      - list
      - watch
  - apiGroups:
      - "monitoring.grafana.com"
    resources:
      - podlogs
    verbs:
      - get
      - list
      - watch
  # Rules which allow mimir.rules.kubernetes to work.
  - apiGroups: ["monitoring.coreos.com"]
    resources:
      - prometheusrules
    verbs:
      - get
      - list
      - watch
  - nonResourceURLs:
      - /metrics
    verbs:
      - get
  # Rules for prometheus.kubernetes.*
  - apiGroups: ["monitoring.coreos.com"]
    resources:
      - podmonitors
      - servicemonitors
      - probes
    verbs:
      - get
      - list
      - watch
  # Rules which allow eventhandler to work.
  - apiGroups:
      - ""
    resources:
      - events
    verbs:
      - get
      - list
      - watch
  # needed for remote.kubernetes.*
  - apiGroups: [""]
    resources:
      - "configmaps"
      - "secrets"
    verbs:
      - get
      - list
      - watch
  # needed for otelcol.processor.k8sattributes
  - apiGroups: ["apps"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
  - apiGroups: ["extensions"]
    resources: ["replicasets"]
    verbs: ["get", "list", "watch"]
---
# Source: grafana-sampling/charts/alloy-deployment/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: my-grafana-sampling-deployment
  labels:
    helm.sh/chart: alloy-deployment-0.6.0
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: rbac
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: my-grafana-sampling-deployment
subjects:
  - kind: ServiceAccount
    name: my-grafana-sampling
    namespace: default
---
# Source: grafana-sampling/charts/alloy-deployment/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-grafana-sampling-deployment
  labels:
    helm.sh/chart: alloy-deployment-0.6.0
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: networking
spec:
  type: ClusterIP
  selector:
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
  internalTrafficPolicy: Cluster
  ports:
    - name: http-metrics
      port: 12345
      targetPort: 12345
      protocol: "TCP"
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
      protocol: TCP
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
---
# Source: grafana-sampling/charts/alloy-statefulset/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-grafana-sampling-statefulset
  labels:
    helm.sh/chart: alloy-statefulset-0.6.0
    app.kubernetes.io/name: statefulset
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
    app.kubernetes.io/component: networking
spec:
  type: ClusterIP
  clusterIP: None
  selector:
    app.kubernetes.io/name: statefulset
    app.kubernetes.io/instance: my-grafana-sampling
  internalTrafficPolicy: Cluster
  ports:
    - name: http-metrics
      port: 12345
      targetPort: 12345
      protocol: "TCP"
    - name: otlp-grpc
      port: 4317
      targetPort: 4317
      protocol: TCP
---
# Source: grafana-sampling/charts/alloy-deployment/templates/controllers/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-grafana-sampling-deployment
  labels:
    helm.sh/chart: alloy-deployment-0.6.0
    app.kubernetes.io/name: deployment
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
spec:
  replicas: 1
  minReadySeconds: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: deployment
      app.kubernetes.io/instance: my-grafana-sampling
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: alloy
      labels:
        app.kubernetes.io/name: deployment
        app.kubernetes.io/instance: my-grafana-sampling
    spec:
      serviceAccountName: my-grafana-sampling
      containers:
        - name: alloy
          image: docker.io/grafana/alloy:v1.3.0
          imagePullPolicy: IfNotPresent
          args:
            - run
            - /etc/alloy/config.alloy
            - --storage.path=/tmp/alloy
            - --server.http.listen-addr=0.0.0.0:12345
            - --server.http.ui-path-prefix=/
            - --stability.level=generally-available
          env:
            - name: ALLOY_DEPLOY_MODE
              value: "helm"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
          ports:
            - containerPort: 12345
              name: http-metrics
            - containerPort: 4317
              name: otlp-grpc
              protocol: TCP
            - containerPort: 4318
              name: otlp-http
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 12345
              scheme: HTTP
            initialDelaySeconds: 10
            timeoutSeconds: 1
          resources:
            requests:
              cpu: "1"
              memory: 2G
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
        - name: config-reloader
          image: ghcr.io/jimmidyson/configmap-reload:v0.12.0
          args:
            - --volume-dir=/etc/alloy
            - --webhook-url=http://localhost:12345/-/reload
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
          resources:
            requests:
              cpu: 1m
              memory: 5Mi
      dnsPolicy: ClusterFirst
      volumes:
        - name: config
          configMap:
            name: my-grafana-sampling-deployment
---
# Source: grafana-sampling/charts/alloy-statefulset/templates/controllers/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-grafana-sampling-statefulset
  labels:
    helm.sh/chart: alloy-statefulset-0.6.0
    app.kubernetes.io/name: statefulset
    app.kubernetes.io/instance: my-grafana-sampling
    
    app.kubernetes.io/version: "v1.3.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/part-of: alloy
spec:
  replicas: 1
  podManagementPolicy: Parallel
  minReadySeconds: 10
  serviceName: my-grafana-sampling-statefulset
  selector:
    matchLabels:
      app.kubernetes.io/name: statefulset
      app.kubernetes.io/instance: my-grafana-sampling
  template:
    metadata:
      annotations:
        kubectl.kubernetes.io/default-container: alloy
      labels:
        app.kubernetes.io/name: statefulset
        app.kubernetes.io/instance: my-grafana-sampling
    spec:
      serviceAccountName: my-grafana-sampling
      containers:
        - name: alloy
          image: docker.io/grafana/alloy:v1.3.0
          imagePullPolicy: IfNotPresent
          args:
            - run
            - /etc/alloy/config.alloy
            - --storage.path=/tmp/alloy
            - --server.http.listen-addr=0.0.0.0:12345
            - --server.http.ui-path-prefix=/
            - --stability.level=generally-available
          env:
            - name: ALLOY_DEPLOY_MODE
              value: "helm"
            - name: HOSTNAME
              valueFrom:
                fieldRef:
                  fieldPath: spec.nodeName
            -
              name: GRAFANA_CLOUD_API_KEY
              value: <REQUIRED>
            -
              name: GRAFANA_CLOUD_PROMETHEUS_URL
              value: <REQUIRED>
            -
              name: GRAFANA_CLOUD_PROMETHEUS_USERNAME
              value: <REQUIRED>
            -
              name: GRAFANA_CLOUD_TEMPO_ENDPOINT
              value: <REQUIRED>
            -
              name: GRAFANA_CLOUD_TEMPO_USERNAME
              value: <REQUIRED>
            -
              name: POD_UID
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: metadata.uid
          ports:
            - containerPort: 12345
              name: http-metrics
            - containerPort: 4317
              name: otlp-grpc
              protocol: TCP
          readinessProbe:
            httpGet:
              path: /-/ready
              port: 12345
              scheme: HTTP
            initialDelaySeconds: 10
            timeoutSeconds: 1
          resources:
            requests:
              cpu: "1"
              memory: 2G
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
        - name: config-reloader
          image: ghcr.io/jimmidyson/configmap-reload:v0.12.0
          args:
            - --volume-dir=/etc/alloy
            - --webhook-url=http://localhost:12345/-/reload
          volumeMounts:
            - name: config
              mountPath: /etc/alloy
          resources:
            requests:
              cpu: 1m
              memory: 5Mi
      dnsPolicy: ClusterFirst
      volumes:
        - name: config
          configMap:
            name: my-grafana-sampling-statefulset
