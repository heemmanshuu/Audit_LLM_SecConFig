---
# Source: sliding-sync-proxy/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-sliding-sync-proxy-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
type: Opaque
data:
  postgres-password: "d0Z3cHR2WE5hRg=="
  password: "c2xpZGluZ19zeW5j"
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: sliding-sync-proxy/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-sliding-sync-proxy
  labels:
    helm.sh/chart: sliding-sync-proxy-0.2.13
    app.kubernetes.io/name: sliding-sync-proxy
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/version: "0.99.19"
    app.kubernetes.io/managed-by: Helm
data:
  SYNCV3_BINDADDR: OjgwMDg=
  SYNCV3_DB: cG9zdGdyZXNxbDovL3NsaWRpbmdfc3luYzpzbGlkaW5nX3N5bmNAbXktc2xpZGluZy1zeW5jLXByb3h5LXBvc3RncmVzcWw6NTQzMi9zbGlkaW5nX3N5bmM/c3NsbW9kZT1wcmVmZXI=
  SYNCV3_SECRET: OEN0cHMwMFk4T1dXZFJOTTdsckFsRmRIYVZDNkpVbjVYUVRCZlhwWFNFa1JtTmh0SkJMMGdWUkM4SlZ0cng1Vw==
  SYNCV3_SERVER: aHR0cHM6Ly9tYXRyaXguZXhhbXBsZS5jb20=
---
# Source: sliding-sync-proxy/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sliding-sync-proxy-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: sliding-sync-proxy/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sliding-sync-proxy-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: sliding-sync-proxy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-sliding-sync-proxy
  labels:
    helm.sh/chart: sliding-sync-proxy-0.2.13
    app.kubernetes.io/name: sliding-sync-proxy
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/version: "0.99.19"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 80
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: sliding-sync-proxy
    app.kubernetes.io/instance: my-sliding-sync-proxy
---
# Source: sliding-sync-proxy/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-sliding-sync-proxy
  labels:
    helm.sh/chart: sliding-sync-proxy-0.2.13
    app.kubernetes.io/name: sliding-sync-proxy
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/version: "0.99.19"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: sliding-sync-proxy
      app.kubernetes.io/instance: my-sliding-sync-proxy
  template:
    metadata:
      annotations:
        checksum/secrets: 3587833c7fe639058ca09f24b464fa9ac5ab880b26ccf59a96818a74ee765ee0
      labels:
        app.kubernetes.io/name: sliding-sync-proxy
        app.kubernetes.io/instance: my-sliding-sync-proxy
    spec:
      securityContext:
        fsGroup: 2000
      containers:
        - name: sliding-sync-proxy
          securityContext:
            capabilities:
              drop:
              - ALL
            readOnlyRootFilesystem: true
            runAsNonRoot: true
            runAsUser: 1000
          image: "ghcr.io/matrix-org/sliding-sync:v0.99.19"
          imagePullPolicy: IfNotPresent
          envFrom:
            - secretRef:
                name: my-sliding-sync-proxy
          ports:
            - name: http
              containerPort: 8008
              protocol: TCP
          livenessProbe:
            tcpSocket:
              port: http
          readinessProbe:
            tcpSocket:
              port: http
          resources:
            {}
---
# Source: sliding-sync-proxy/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-sliding-sync-proxy-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-sliding-sync-proxy
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 15.4.0
    helm.sh/chart: postgresql-12.12.10
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: my-sliding-sync-proxy-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-sliding-sync-proxy
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: my-sliding-sync-proxy-postgresql
      labels:
        app.kubernetes.io/instance: my-sliding-sync-proxy
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 15.4.0
        helm.sh/chart: postgresql-12.12.10
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: default
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-sliding-sync-proxy
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql:15.4.0-debian-11-r45
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "sliding_sync"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-sliding-sync-proxy-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-sliding-sync-proxy-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "sliding_sync"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "sliding_sync" -d "dbname=sliding_sync" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "sliding_sync" -d "dbname=sliding_sync" -h 127.0.0.1 -p 5432
                  [ -f /opt/bitnami/postgresql/tmp/.initialized ] || [ -f /bitnami/postgresql/.initialized ]
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "16Gi"
