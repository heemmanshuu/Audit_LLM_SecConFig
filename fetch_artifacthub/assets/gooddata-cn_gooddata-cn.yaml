---
# Source: gooddata-cn/charts/etcd/templates/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: my-gooddata-cn-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
    app.kubernetes.io/component: etcd
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/name: etcd
      app.kubernetes.io/component: etcd
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    # Allow inbound connections
    - ports:
        - port: 2379
        - port: 2380
    # Allow prometheus scrapes for metrics
    - ports:
        - port: 2379
---
# Source: gooddata-cn/charts/etcd/templates/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: my-gooddata-cn-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
    app.kubernetes.io/component: etcd
spec:
  minAvailable: 51%
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/name: etcd
      app.kubernetes.io/component: etcd
---
# Source: gooddata-cn/charts/etcd/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
automountServiceAccountToken: false
metadata:
  name: my-gooddata-cn-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-gooddata-cn-redis-ha
  namespace: "default"
  labels:
    heritage: Helm
    release: my-gooddata-cn
    chart: redis-ha-4.27.2
    app: my-gooddata-cn-redis-ha
---
# Source: gooddata-cn/templates/organization-controller/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-gooddata-cn-controller
  labels:

    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: gooddata-cn/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: my-gooddata-cn
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: false
---
# Source: gooddata-cn/charts/etcd/templates/token-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-etcd-jwt-token
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
type: Opaque
data:
  jwt-token.pem: "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"
---
# Source: gooddata-cn/charts/postgresql-ha/templates/pgpool/custom-users-secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-db-pgpool-custom-users
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: pgpool
type: Opaque
data:
  usernames: ""
  passwords: ""
---
# Source: gooddata-cn/charts/postgresql-ha/templates/pgpool/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-db-pgpool
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: pgpool
type: Opaque
data:
  admin-password: "cGdwb29sYWRtaW4="
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-db-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
type: Opaque
data:
  postgresql-password: "c2VjcmV0"
  repmgr-password: "cmVwbWdycGFzc3dvcmQ="
---
# Source: gooddata-cn/templates/auth-service/secret-license.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-license-key
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  license: PHB1dC15b3VyLWxpY2Vuc2Uta2V5LWhlcmU+
---
# Source: gooddata-cn/templates/automation/secret-smtp.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-automation-smtp-credentials
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: automation
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  smtp_host: ""
  smtp_username: ""
  smtp_password: ""
---
# Source: gooddata-cn/templates/dex/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-dex
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
stringData:
  config.yaml: |-
    issuer: https://localhost/dex
    storage:
      type: postgres
      config:
        host: "my-gooddata-cn-db-pgpool"
        port: 5432
        database: dex
        user: "postgres"
        password: $DEX_PGPASSWORD
        ssl:
          mode: disable
    logger:
      format: json
      level: info
    web:
      http: "0.0.0.0:5556"
    grpc:
      addr: "0.0.0.0:5000"
      tlsCert: ""
      tlsKey: ""
      tlsClientCA: ""
      reflection: true
    telemetry:
      http: "0.0.0.0:5558"
    oauth2:
      alwaysShowLoginScreen: false
      responseTypes:
      - code
      - token
      - id_token
      skipApprovalScreen: true
    enablePasswordDB: true
    expiry:
      deviceRequests: 24h
      idTokens: 24h
      signingKeys: 48h
    frontend:
      dir: web/
      issuer: GoodData.CN
      logoUrl: theme/logo.svg
      theme: gdc
---
# Source: gooddata-cn/templates/export-controller/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-export-controller
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
---
# Source: gooddata-cn/templates/metadata-api/secret-db-exporter.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-md-exporter-postgres-password
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  exporter-password: VmVyeVNlY3JldFBhc3N3b3Jk
---
# Source: gooddata-cn/templates/metadata-api/secret-encryptor.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-encryptor-keyset
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  keySet: ""
---
# Source: gooddata-cn/templates/metadata-api/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-metadata-bootstrap
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  user: Ym9vdHN0cmFw
  password: VmVyeVNlY3JldFBhc3N3b3Jk
---
# Source: gooddata-cn/templates/quiver/secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: my-gooddata-cn-secrets
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/extended-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-db-postgresql-extended-configuration
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
data:
  override.conf: |-
    max_connections=500
    shared_buffers=128MB
    work_mem=8MB
    synchronous_commit=remote_apply
    random_page_cost=1.1
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/hooks-scripts-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-db-postgresql-hooks-scripts
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
data:
  pre-stop.sh: |-
    #!/bin/bash
    set -o errexit
    set -o pipefail
    set -o nounset

    # Debug section
    exec 3>&1
    exec 4>&2

    # Load Libraries
    . /opt/bitnami/scripts/liblog.sh
    . /opt/bitnami/scripts/libpostgresql.sh
    . /opt/bitnami/scripts/librepmgr.sh

    # Load PostgreSQL & repmgr environment variables
    . /opt/bitnami/scripts/postgresql-env.sh

    # Auxiliary functions
    is_new_primary_ready() {
        return_value=1
        currenty_primary_node="$(repmgr_get_primary_node)"
        currenty_primary_host="$(echo $currenty_primary_node | awk '{print $1}')"

        info "$currenty_primary_host != $REPMGR_NODE_NETWORK_NAME"
        if [[ $(echo $currenty_primary_node | wc -w) -eq 2 ]] && [[ "$currenty_primary_host" != "$REPMGR_NODE_NETWORK_NAME" ]]; then
            info "New primary detected, leaving the cluster..."
            return_value=0
        else
            info "Waiting for a new primary to be available..."
        fi
        return $return_value
    }

    export MODULE="pre-stop-hook"

    if [[ "${BITNAMI_DEBUG}" == "true" ]]; then
        info "Bash debug is on"
    else
        info "Bash debug is off"
        exec 1>/dev/null
        exec 2>/dev/null
    fi

    postgresql_enable_nss_wrapper

    # Prepare env vars for managing roles
    readarray -t primary_node < <(repmgr_get_upstream_node)
    primary_host="${primary_node[0]}"

    # Stop postgresql for graceful exit.
    postgresql_stop

    if [[ -z "$primary_host" ]] || [[ "$primary_host" == "$REPMGR_NODE_NETWORK_NAME" ]]; then
        info "Primary node need to wait for a new primary node before leaving the cluster"
        retry_while is_new_primary_ready 10 5
    else
        info "Standby node doesn't need to wait, leaving the cluster."
    fi
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-redis-ha-configmap
  namespace: "default"
  labels:
    heritage: Helm
    release: my-gooddata-cn
    chart: redis-ha-4.27.2
    app: my-gooddata-cn-redis-ha
data:
  redis.conf: |
    dir "/data"
    port 6379
    rename-command FLUSHDB ""
    rename-command FLUSHALL ""
    maxmemory 100m
    maxmemory-policy allkeys-lru
    min-replicas-max-lag 5
    min-replicas-to-write 1
    rdbchecksum yes
    rdbcompression yes
    repl-diskless-sync yes
    save 900 1

  sentinel.conf: |
    dir "/data"
    port 26379
        sentinel down-after-milliseconds mymaster 10000
        sentinel failover-timeout mymaster 180000
        maxclients 10000
        sentinel parallel-syncs mymaster 5

  init.sh: |
    echo "$(date) Start..."
    HOSTNAME="$(hostname)"
    INDEX="${HOSTNAME##*-}"
    SENTINEL_PORT=26379
    ANNOUNCE_IP=''
    MASTER=''
    MASTER_GROUP="mymaster"
    QUORUM="2"
    REDIS_CONF=/data/conf/redis.conf
    REDIS_PORT=6379
    REDIS_TLS_PORT=
    SENTINEL_CONF=/data/conf/sentinel.conf
    SENTINEL_TLS_PORT=
    SERVICE=my-gooddata-cn-redis-ha
    SENTINEL_TLS_REPLICATION_ENABLED=false
    REDIS_TLS_REPLICATION_ENABLED=false

    set -eu
    sentinel_get_master() {
    set +e
        if [ "$SENTINEL_PORT" -eq 0 ]; then
            redis-cli -h "${SERVICE}" -p "${SENTINEL_TLS_PORT}"  --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key sentinel get-master-addr-by-name "${MASTER_GROUP}" |\
            grep -E '((^\s*((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))\s*$)|(^\s*((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?s*$))'
        else
            redis-cli -h "${SERVICE}" -p "${SENTINEL_PORT}"  sentinel get-master-addr-by-name "${MASTER_GROUP}" |\
            grep -E '((^\s*((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))\s*$)|(^\s*((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?s*$))'
        fi
    set -e
    }

    sentinel_get_master_retry() {
        master=''
        retry=${1}
        sleep=3
        for i in $(seq 1 "${retry}"); do
            master=$(sentinel_get_master)
            if [ -n "${master}" ]; then
                break
            fi
            sleep $((sleep + i))
        done
        echo "${master}"
    }

    identify_master() {
        echo "Identifying redis master (get-master-addr-by-name).."
        echo "  using sentinel (my-gooddata-cn-redis-ha), sentinel group name (mymaster)"
        MASTER="$(sentinel_get_master_retry 3)"
        if [ -n "${MASTER}" ]; then
            echo "  $(date) Found redis master (${MASTER})"
        else
            echo "  $(date) Did not find redis master (${MASTER})"
        fi
    }

    sentinel_update() {
        echo "Updating sentinel config.."
        echo "  evaluating sentinel id (\${SENTINEL_ID_${INDEX}})"
        eval MY_SENTINEL_ID="\$SENTINEL_ID_${INDEX}"
        echo "  sentinel id (${MY_SENTINEL_ID}), sentinel grp (${MASTER_GROUP}), quorum (${QUORUM})"
        sed -i "1s/^/sentinel myid ${MY_SENTINEL_ID}\\n/" "${SENTINEL_CONF}"
        if [ "$SENTINEL_TLS_REPLICATION_ENABLED" = true ]; then
            echo "  redis master (${1}:${REDIS_TLS_PORT})"
            sed -i "2s/^/sentinel monitor ${MASTER_GROUP} ${1} ${REDIS_TLS_PORT} ${QUORUM} \\n/" "${SENTINEL_CONF}"
        else
            echo "  redis master (${1}:${REDIS_PORT})"
            sed -i "2s/^/sentinel monitor ${MASTER_GROUP} ${1} ${REDIS_PORT} ${QUORUM} \\n/" "${SENTINEL_CONF}"
        fi
        echo "sentinel announce-ip ${ANNOUNCE_IP}" >> ${SENTINEL_CONF}
        if [ "$SENTINEL_PORT" -eq 0 ]; then
            echo "  announce (${ANNOUNCE_IP}:${SENTINEL_TLS_PORT})"
            echo "sentinel announce-port ${SENTINEL_TLS_PORT}" >> ${SENTINEL_CONF}
        else
            echo "  announce (${ANNOUNCE_IP}:${SENTINEL_PORT})"
            echo "sentinel announce-port ${SENTINEL_PORT}" >> ${SENTINEL_CONF}
        fi
    }

    redis_update() {
        echo "Updating redis config.."
        if [ "$REDIS_TLS_REPLICATION_ENABLED" = true ]; then
            echo "  we are slave of redis master (${1}:${REDIS_TLS_PORT})"
            echo "slaveof ${1} ${REDIS_TLS_PORT}" >> "${REDIS_CONF}"
            echo "slave-announce-port ${REDIS_TLS_PORT}" >> ${REDIS_CONF}
        else
            echo "  we are slave of redis master (${1}:${REDIS_PORT})"
            echo "slaveof ${1} ${REDIS_PORT}" >> "${REDIS_CONF}"
            echo "slave-announce-port ${REDIS_PORT}" >> ${REDIS_CONF}
        fi
        echo "slave-announce-ip ${ANNOUNCE_IP}" >> ${REDIS_CONF}
    }

    copy_config() {
        echo "Copying default redis config.."
        echo "  to '${REDIS_CONF}'"
        cp /readonly-config/redis.conf "${REDIS_CONF}"
        echo "Copying default sentinel config.."
        echo "  to '${SENTINEL_CONF}'"
        cp /readonly-config/sentinel.conf "${SENTINEL_CONF}"
    }

    setup_defaults() {
        echo "Setting up defaults.."
        echo "  using statefulset index (${INDEX})"
        if [ "${INDEX}" = "0" ]; then
            echo "Setting this pod as master for redis and sentinel.."
            echo "  using announce (${ANNOUNCE_IP})"
            redis_update "${ANNOUNCE_IP}"
            sentinel_update "${ANNOUNCE_IP}"
            echo "  make sure ${ANNOUNCE_IP} is not a slave (slaveof no one)"
            sed -i "s/^.*slaveof.*//" "${REDIS_CONF}"
        else
            echo "Getting redis master ip.."
            echo "  blindly assuming (${SERVICE}-announce-0) or (${SERVICE}-server-0) are master"
            DEFAULT_MASTER="$(getent_hosts 0 | awk '{ print $1 }')"
            if [ -z "${DEFAULT_MASTER}" ]; then
                echo "Error: Unable to resolve redis master (getent hosts)."
                exit 1
            fi
            echo "  identified redis (may be redis master) ip (${DEFAULT_MASTER})"
            echo "Setting default slave config for redis and sentinel.."
            echo "  using master ip (${DEFAULT_MASTER})"
            redis_update "${DEFAULT_MASTER}"
            sentinel_update "${DEFAULT_MASTER}"
        fi
    }

    redis_ping() {
    set +e
        if [ "$REDIS_PORT" -eq 0 ]; then
            redis-cli -h "${MASTER}" -p "${REDIS_TLS_PORT}" --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key ping
        else
            redis-cli -h "${MASTER}" -p "${REDIS_PORT}" ping
        fi
    set -e
    }

    redis_ping_retry() {
        ping=''
        retry=${1}
        sleep=3
        for i in $(seq 1 "${retry}"); do
            if [ "$(redis_ping)" = "PONG" ]; then
               ping='PONG'
               break
            fi
            sleep $((sleep + i))
            MASTER=$(sentinel_get_master)
        done
        echo "${ping}"
    }

    find_master() {
        echo "Verifying redis master.."
        if [ "$REDIS_PORT" -eq 0 ]; then
            echo "  ping (${MASTER}:${REDIS_TLS_PORT})"
        else
            echo "  ping (${MASTER}:${REDIS_PORT})"
        fi
        if [ "$(redis_ping_retry 3)" != "PONG" ]; then
            echo "  $(date) Can't ping redis master (${MASTER})"
            echo "Attempting to force failover (sentinel failover).."

            if [ "$SENTINEL_PORT" -eq 0 ]; then
                echo "  on sentinel (${SERVICE}:${SENTINEL_TLS_PORT}), sentinel grp (${MASTER_GROUP})"
                if redis-cli -h "${SERVICE}" -p "${SENTINEL_TLS_PORT}"  --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key sentinel failover "${MASTER_GROUP}" | grep -q 'NOGOODSLAVE' ; then
                    echo "  $(date) Failover returned with 'NOGOODSLAVE'"
                    echo "Setting defaults for this pod.."
                    setup_defaults
                    return 0
                fi
            else
                echo "  on sentinel (${SERVICE}:${SENTINEL_PORT}), sentinel grp (${MASTER_GROUP})"
                if redis-cli -h "${SERVICE}" -p "${SENTINEL_PORT}"  sentinel failover "${MASTER_GROUP}" | grep -q 'NOGOODSLAVE' ; then
                    echo "  $(date) Failover returned with 'NOGOODSLAVE'"
                    echo "Setting defaults for this pod.."
                    setup_defaults
                    return 0
                fi
            fi

            echo "Hold on for 10sec"
            sleep 10
            echo "We should get redis master's ip now. Asking (get-master-addr-by-name).."
            if [ "$SENTINEL_PORT" -eq 0 ]; then
                echo "  sentinel (${SERVICE}:${SENTINEL_TLS_PORT}), sentinel grp (${MASTER_GROUP})"
            else
                echo "  sentinel (${SERVICE}:${SENTINEL_PORT}), sentinel grp (${MASTER_GROUP})"
            fi
            MASTER="$(sentinel_get_master)"
            if [ "${MASTER}" ]; then
                echo "  $(date) Found redis master (${MASTER})"
                echo "Updating redis and sentinel config.."
                sentinel_update "${MASTER}"
                redis_update "${MASTER}"
            else
                echo "$(date) Error: Could not failover, exiting..."
                exit 1
            fi
        else
            echo "  $(date) Found reachable redis master (${MASTER})"
            echo "Updating redis and sentinel config.."
            sentinel_update "${MASTER}"
            redis_update "${MASTER}"
        fi
    }

    redis_ro_update() {
        echo "Updating read-only redis config.."
        echo "  redis.conf set 'replica-priority 0'"
        echo "replica-priority 0" >> ${REDIS_CONF}
    }

    getent_hosts() {
        index=${1:-${INDEX}}
        service="${SERVICE}-announce-${index}"
        host=$(getent hosts "${service}")
        echo "${host}"
    }

    identify_announce_ip() {
        echo "Identify announce ip for this pod.."
        echo "  using (${SERVICE}-announce-${INDEX}) or (${SERVICE}-server-${INDEX})"
        ANNOUNCE_IP=$(getent_hosts | awk '{ print $1 }')
        echo "  identified announce (${ANNOUNCE_IP})"
    }

    mkdir -p /data/conf/

    echo "Initializing config.."
    copy_config

    # where is redis master
    identify_master

    identify_announce_ip

    if [ -z "${ANNOUNCE_IP}" ]; then
        "Error: Could not resolve the announce ip for this pod."
        exit 1
    elif [ "${MASTER}" ]; then
        find_master
    else
        setup_defaults
    fi

    if [ "${AUTH:-}" ]; then
        echo "Setting redis auth values.."
        ESCAPED_AUTH=$(echo "${AUTH}" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/replace-default-auth/${ESCAPED_AUTH}/" "${REDIS_CONF}" "${SENTINEL_CONF}"
    fi

    if [ "${SENTINELAUTH:-}" ]; then
        echo "Setting sentinel auth values"
        ESCAPED_AUTH_SENTINEL=$(echo "$SENTINELAUTH" | sed -e 's/[\/&]/\\&/g');
        sed -i "s/replace-default-sentinel-auth/${ESCAPED_AUTH_SENTINEL}/" "$SENTINEL_CONF"
    fi

    echo "$(date) Ready..."

  fix-split-brain.sh: |
    HOSTNAME="$(hostname)"
    INDEX="${HOSTNAME##*-}"
    SENTINEL_PORT=26379
    ANNOUNCE_IP=''
    MASTER=''
    MASTER_GROUP="mymaster"
    QUORUM="2"
    REDIS_CONF=/data/conf/redis.conf
    REDIS_PORT=6379
    REDIS_TLS_PORT=
    SENTINEL_CONF=/data/conf/sentinel.conf
    SENTINEL_TLS_PORT=
    SERVICE=my-gooddata-cn-redis-ha
    SENTINEL_TLS_REPLICATION_ENABLED=false
    REDIS_TLS_REPLICATION_ENABLED=false

    ROLE=''
    REDIS_MASTER=''

    set -eu
    sentinel_get_master() {
    set +e
        if [ "$SENTINEL_PORT" -eq 0 ]; then
            redis-cli -h "${SERVICE}" -p "${SENTINEL_TLS_PORT}"  --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key sentinel get-master-addr-by-name "${MASTER_GROUP}" |\
            grep -E '((^\s*((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))\s*$)|(^\s*((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?s*$))'
        else
            redis-cli -h "${SERVICE}" -p "${SENTINEL_PORT}"  sentinel get-master-addr-by-name "${MASTER_GROUP}" |\
            grep -E '((^\s*((([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))\s*$)|(^\s*((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?s*$))'
        fi
    set -e
    }

    sentinel_get_master_retry() {
        master=''
        retry=${1}
        sleep=3
        for i in $(seq 1 "${retry}"); do
            master=$(sentinel_get_master)
            if [ -n "${master}" ]; then
                break
            fi
            sleep $((sleep + i))
        done
        echo "${master}"
    }

    identify_master() {
        echo "Identifying redis master (get-master-addr-by-name).."
        echo "  using sentinel (my-gooddata-cn-redis-ha), sentinel group name (mymaster)"
        MASTER="$(sentinel_get_master_retry 3)"
        if [ -n "${MASTER}" ]; then
            echo "  $(date) Found redis master (${MASTER})"
        else
            echo "  $(date) Did not find redis master (${MASTER})"
        fi
    }

    sentinel_update() {
        echo "Updating sentinel config.."
        echo "  evaluating sentinel id (\${SENTINEL_ID_${INDEX}})"
        eval MY_SENTINEL_ID="\$SENTINEL_ID_${INDEX}"
        echo "  sentinel id (${MY_SENTINEL_ID}), sentinel grp (${MASTER_GROUP}), quorum (${QUORUM})"
        sed -i "1s/^/sentinel myid ${MY_SENTINEL_ID}\\n/" "${SENTINEL_CONF}"
        if [ "$SENTINEL_TLS_REPLICATION_ENABLED" = true ]; then
            echo "  redis master (${1}:${REDIS_TLS_PORT})"
            sed -i "2s/^/sentinel monitor ${MASTER_GROUP} ${1} ${REDIS_TLS_PORT} ${QUORUM} \\n/" "${SENTINEL_CONF}"
        else
            echo "  redis master (${1}:${REDIS_PORT})"
            sed -i "2s/^/sentinel monitor ${MASTER_GROUP} ${1} ${REDIS_PORT} ${QUORUM} \\n/" "${SENTINEL_CONF}"
        fi
        echo "sentinel announce-ip ${ANNOUNCE_IP}" >> ${SENTINEL_CONF}
        if [ "$SENTINEL_PORT" -eq 0 ]; then
            echo "  announce (${ANNOUNCE_IP}:${SENTINEL_TLS_PORT})"
            echo "sentinel announce-port ${SENTINEL_TLS_PORT}" >> ${SENTINEL_CONF}
        else
            echo "  announce (${ANNOUNCE_IP}:${SENTINEL_PORT})"
            echo "sentinel announce-port ${SENTINEL_PORT}" >> ${SENTINEL_CONF}
        fi
    }

    redis_update() {
        echo "Updating redis config.."
        if [ "$REDIS_TLS_REPLICATION_ENABLED" = true ]; then
            echo "  we are slave of redis master (${1}:${REDIS_TLS_PORT})"
            echo "slaveof ${1} ${REDIS_TLS_PORT}" >> "${REDIS_CONF}"
            echo "slave-announce-port ${REDIS_TLS_PORT}" >> ${REDIS_CONF}
        else
            echo "  we are slave of redis master (${1}:${REDIS_PORT})"
            echo "slaveof ${1} ${REDIS_PORT}" >> "${REDIS_CONF}"
            echo "slave-announce-port ${REDIS_PORT}" >> ${REDIS_CONF}
        fi
        echo "slave-announce-ip ${ANNOUNCE_IP}" >> ${REDIS_CONF}
    }

    copy_config() {
        echo "Copying default redis config.."
        echo "  to '${REDIS_CONF}'"
        cp /readonly-config/redis.conf "${REDIS_CONF}"
        echo "Copying default sentinel config.."
        echo "  to '${SENTINEL_CONF}'"
        cp /readonly-config/sentinel.conf "${SENTINEL_CONF}"
    }

    setup_defaults() {
        echo "Setting up defaults.."
        echo "  using statefulset index (${INDEX})"
        if [ "${INDEX}" = "0" ]; then
            echo "Setting this pod as master for redis and sentinel.."
            echo "  using announce (${ANNOUNCE_IP})"
            redis_update "${ANNOUNCE_IP}"
            sentinel_update "${ANNOUNCE_IP}"
            echo "  make sure ${ANNOUNCE_IP} is not a slave (slaveof no one)"
            sed -i "s/^.*slaveof.*//" "${REDIS_CONF}"
        else
            echo "Getting redis master ip.."
            echo "  blindly assuming (${SERVICE}-announce-0) or (${SERVICE}-server-0) are master"
            DEFAULT_MASTER="$(getent_hosts 0 | awk '{ print $1 }')"
            if [ -z "${DEFAULT_MASTER}" ]; then
                echo "Error: Unable to resolve redis master (getent hosts)."
                exit 1
            fi
            echo "  identified redis (may be redis master) ip (${DEFAULT_MASTER})"
            echo "Setting default slave config for redis and sentinel.."
            echo "  using master ip (${DEFAULT_MASTER})"
            redis_update "${DEFAULT_MASTER}"
            sentinel_update "${DEFAULT_MASTER}"
        fi
    }

    redis_ping() {
    set +e
        if [ "$REDIS_PORT" -eq 0 ]; then
            redis-cli -h "${MASTER}" -p "${REDIS_TLS_PORT}" --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key ping
        else
            redis-cli -h "${MASTER}" -p "${REDIS_PORT}" ping
        fi
    set -e
    }

    redis_ping_retry() {
        ping=''
        retry=${1}
        sleep=3
        for i in $(seq 1 "${retry}"); do
            if [ "$(redis_ping)" = "PONG" ]; then
               ping='PONG'
               break
            fi
            sleep $((sleep + i))
            MASTER=$(sentinel_get_master)
        done
        echo "${ping}"
    }

    find_master() {
        echo "Verifying redis master.."
        if [ "$REDIS_PORT" -eq 0 ]; then
            echo "  ping (${MASTER}:${REDIS_TLS_PORT})"
        else
            echo "  ping (${MASTER}:${REDIS_PORT})"
        fi
        if [ "$(redis_ping_retry 3)" != "PONG" ]; then
            echo "  $(date) Can't ping redis master (${MASTER})"
            echo "Attempting to force failover (sentinel failover).."

            if [ "$SENTINEL_PORT" -eq 0 ]; then
                echo "  on sentinel (${SERVICE}:${SENTINEL_TLS_PORT}), sentinel grp (${MASTER_GROUP})"
                if redis-cli -h "${SERVICE}" -p "${SENTINEL_TLS_PORT}"  --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key sentinel failover "${MASTER_GROUP}" | grep -q 'NOGOODSLAVE' ; then
                    echo "  $(date) Failover returned with 'NOGOODSLAVE'"
                    echo "Setting defaults for this pod.."
                    setup_defaults
                    return 0
                fi
            else
                echo "  on sentinel (${SERVICE}:${SENTINEL_PORT}), sentinel grp (${MASTER_GROUP})"
                if redis-cli -h "${SERVICE}" -p "${SENTINEL_PORT}"  sentinel failover "${MASTER_GROUP}" | grep -q 'NOGOODSLAVE' ; then
                    echo "  $(date) Failover returned with 'NOGOODSLAVE'"
                    echo "Setting defaults for this pod.."
                    setup_defaults
                    return 0
                fi
            fi

            echo "Hold on for 10sec"
            sleep 10
            echo "We should get redis master's ip now. Asking (get-master-addr-by-name).."
            if [ "$SENTINEL_PORT" -eq 0 ]; then
                echo "  sentinel (${SERVICE}:${SENTINEL_TLS_PORT}), sentinel grp (${MASTER_GROUP})"
            else
                echo "  sentinel (${SERVICE}:${SENTINEL_PORT}), sentinel grp (${MASTER_GROUP})"
            fi
            MASTER="$(sentinel_get_master)"
            if [ "${MASTER}" ]; then
                echo "  $(date) Found redis master (${MASTER})"
                echo "Updating redis and sentinel config.."
                sentinel_update "${MASTER}"
                redis_update "${MASTER}"
            else
                echo "$(date) Error: Could not failover, exiting..."
                exit 1
            fi
        else
            echo "  $(date) Found reachable redis master (${MASTER})"
            echo "Updating redis and sentinel config.."
            sentinel_update "${MASTER}"
            redis_update "${MASTER}"
        fi
    }

    redis_ro_update() {
        echo "Updating read-only redis config.."
        echo "  redis.conf set 'replica-priority 0'"
        echo "replica-priority 0" >> ${REDIS_CONF}
    }

    getent_hosts() {
        index=${1:-${INDEX}}
        service="${SERVICE}-announce-${index}"
        host=$(getent hosts "${service}")
        echo "${host}"
    }

    identify_announce_ip() {
        echo "Identify announce ip for this pod.."
        echo "  using (${SERVICE}-announce-${INDEX}) or (${SERVICE}-server-${INDEX})"
        ANNOUNCE_IP=$(getent_hosts | awk '{ print $1 }')
        echo "  identified announce (${ANNOUNCE_IP})"
    }

    redis_role() {
    set +e
        if [ "$REDIS_PORT" -eq 0 ]; then
            ROLE=$(redis-cli  -p "${REDIS_TLS_PORT}" --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key info | grep role | sed 's/role://' | sed 's/\r//')
        else
            ROLE=$(redis-cli  -p "${REDIS_PORT}" info | grep role | sed 's/role://' | sed 's/\r//')
        fi
    set -e
    }

    identify_redis_master() {
    set +e
        if [ "$REDIS_PORT" -eq 0 ]; then
            REDIS_MASTER=$(redis-cli  -p "${REDIS_TLS_PORT}" --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key info | grep master_host | sed 's/master_host://' | sed 's/\r//')
        else
            REDIS_MASTER=$(redis-cli  -p "${REDIS_PORT}" info | grep master_host | sed 's/master_host://' | sed 's/\r//')
        fi
    set -e
    }

    reinit() {
    set +e
        sh /readonly-config/init.sh

        if [ "$REDIS_PORT" -eq 0 ]; then
            echo "shutdown" | redis-cli  -p "${REDIS_TLS_PORT}" --tls --cacert /tls-certs/ca.crt  --cert /tls-certs/redis.crt --key /tls-certs/redis.key
        else
            echo "shutdown" | redis-cli  -p "${REDIS_PORT}"
        fi
    set -e
    }

    identify_announce_ip

    while [ -z "${ANNOUNCE_IP}" ]; do
        echo "Error: Could not resolve the announce ip for this pod."
        sleep 30
        identify_announce_ip
    done

    trap "exit 0" TERM
    while true; do
        sleep 60

        # where is redis master
        identify_master

        if [ "$MASTER" = "$ANNOUNCE_IP" ]; then
            redis_role
            if [ "$ROLE" != "master" ]; then
                reinit
            fi
        elif [ "${MASTER}" ]; then
            identify_redis_master
            if [ "$REDIS_MASTER" != "$MASTER" ]; then
                reinit
            fi
        fi
    done


  haproxy_init.sh: |
    HAPROXY_CONF=/data/haproxy.cfg
    cp /readonly/haproxy.cfg "$HAPROXY_CONF"
    for loop in $(seq 1 10); do
      getent hosts my-gooddata-cn-redis-ha-announce-0 && break
      echo "Waiting for service my-gooddata-cn-redis-ha-announce-0 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP0=$(getent hosts "my-gooddata-cn-redis-ha-announce-0" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP0" ]; then
      echo "Could not resolve the announce ip for my-gooddata-cn-redis-ha-announce-0"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE0/$ANNOUNCE_IP0/" "$HAPROXY_CONF"
    for loop in $(seq 1 10); do
      getent hosts my-gooddata-cn-redis-ha-announce-1 && break
      echo "Waiting for service my-gooddata-cn-redis-ha-announce-1 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP1=$(getent hosts "my-gooddata-cn-redis-ha-announce-1" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP1" ]; then
      echo "Could not resolve the announce ip for my-gooddata-cn-redis-ha-announce-1"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE1/$ANNOUNCE_IP1/" "$HAPROXY_CONF"
    for loop in $(seq 1 10); do
      getent hosts my-gooddata-cn-redis-ha-announce-2 && break
      echo "Waiting for service my-gooddata-cn-redis-ha-announce-2 to be ready ($loop) ..." && sleep 1
    done
    ANNOUNCE_IP2=$(getent hosts "my-gooddata-cn-redis-ha-announce-2" | awk '{ print $1 }')
    if [ -z "$ANNOUNCE_IP2" ]; then
      echo "Could not resolve the announce ip for my-gooddata-cn-redis-ha-announce-2"
      exit 1
    fi
    sed -i "s/REPLACE_ANNOUNCE2/$ANNOUNCE_IP2/" "$HAPROXY_CONF"
  trigger-failover-if-master.sh: |
    get_redis_role() {
      is_master=$(
        redis-cli \
          -h localhost \
          -p 6379 \
          info | grep -c 'role:master' || true
      )
    }
    get_redis_role
    if [[ "$is_master" -eq 1 ]]; then
      echo "This node is currently master, we trigger a failover."
      response=$(
        redis-cli \
          -h localhost \
          -p 26379 \
          SENTINEL failover mymaster
      )
      if [[ "$response" != "OK" ]] ; then
        echo "$response"
        exit 1
      fi
      timeout=30
      while [[ "$is_master" -eq 1 && $timeout -gt 0 ]]; do
        sleep 1
        get_redis_role
        timeout=$((timeout - 1))
      done
      echo "Failover successful"
    fi
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-health-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-redis-ha-health-configmap
  namespace: "default"
  labels:
    heritage: Helm
    release: my-gooddata-cn
    chart: redis-ha-4.27.2
    app: my-gooddata-cn-redis-ha
data:
  redis_liveness.sh: |
    response=$(
      redis-cli \
        -h localhost \
        -p 6379 \
        ping
    )
    if [ "$response" != "PONG" ] && [ "${response:0:7}" != "LOADING" ] ; then
      echo "$response"
      exit 1
    fi
    echo "response=$response"
  redis_readiness.sh: |
    response=$(
      redis-cli \
        -h localhost \
        -p 6379 \
        ping
    )
    if [ "$response" != "PONG" ] ; then
      echo "$response"
      exit 1
    fi
    echo "response=$response"
  sentinel_liveness.sh: |
    response=$(
      redis-cli \
        -h localhost \
        -p 26379 \
        ping
    )
    if [ "$response" != "PONG" ]; then
      echo "$response"
      exit 1
    fi
    echo "response=$response"
---
# Source: gooddata-cn/templates/api-gateway/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-api-gateway-config
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  application-routes.yaml: |
    api-gateway:
      routes:
        - path: /analyze/**
          url: "http://my-gooddata-cn-analytical-designer:9300"
        - path: /dashboards/**
          url: "http://my-gooddata-cn-dashboards:9500"
        - path: /modeler/**
          url: "http://my-gooddata-cn-ldm-modeler:9400"
        - path: /metrics/**
          url: "http://my-gooddata-cn-measure-editor:9700"
        - path: /components/**
          url: "http://my-gooddata-cn-web-components:9800"
        - path: /**
          url: "http://my-gooddata-cn-home-ui:9600"
      linkHeaders:
        {}
---
# Source: gooddata-cn/templates/export-controller/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-export-controller-config
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  application-cspConfig.yaml: |
    gdc:
      csp:
        additionalDirectives:
          {}
#        General CSP directives in application. It isn't intended to override them.
#        generalDirectives:
---
# Source: gooddata-cn/templates/metadata-api/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-metadata-api-config
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  application-cspConfig.yaml: |
    gdc:
      csp:
        additionalDirectives:
          {}
#        General CSP directives in application. It isn't intended to override them.
#        generalDirectives:
---
# Source: gooddata-cn/templates/organization-controller/configmap-apisix-crd-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-org-controller-apisix-crd-tpl
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  ingress.yaml: |-
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: my-gooddata-cn-ingress-all
      labels: {}
      # TBD - won't be managed by Helm
      annotations:
        k8s.apisix.apache.org/http-to-https: "true"
        k8s.apisix.apache.org/rewrite-target-regex: ^/(apidocs)$
        k8s.apisix.apache.org/rewrite-target-regex-template: /$1/
        k8s.apisix.apache.org/upstream-read-timeout: 182s
        k8s.apisix.apache.org/use-regex: "true"
    spec:
      ingressClassName: apisix
      rules:
        - http:
            paths:
            # Apidocs              
              - path: /apidocs
                pathType: Prefix
                backend:
                  service:
                    name: my-gooddata-cn-apidocs
                    port:
                      number: 9999

          # Provided by Organization Custom Resource - spec.hostname
          host: ''
      tls:
        - hosts:
            - ''
          secretName: ''
  routes.yaml: |-
    apiVersion: apisix.apache.org/v2
    kind: ApisixRoute
    metadata:
      name: my-gooddata-cn-apisix-routes
      labels: { }
    spec:
      http:
        # afm-exec-api        
        - name: afm-exec-api-execution-execute
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/workspaces/[^/]+/execution/afm/execute"
          backends:
          - serviceName: my-gooddata-cn-afm-exec-api
            servicePort: 9000
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: afm-exec-api-execution
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/workspaces/[^/]+/execution/.*"
          backends:
          - serviceName: my-gooddata-cn-afm-exec-api
            servicePort: 9000
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: afm-exec-api-ai
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/workspaces/[^/]+/ai/.*"
          backends:
          - serviceName: my-gooddata-cn-afm-exec-api
            servicePort: 9000
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: afm-exec-api-schemas
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/schemas/afm"
          backends:
          - serviceName: my-gooddata-cn-afm-exec-api
            servicePort: 9000
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # export-controller        
        - name: export-controller-tabular
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/workspaces/[^/]+/export/tabular"
          backends:
          - serviceName: my-gooddata-cn-export-controller
            servicePort: 6580
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: export-controller-visual
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/workspaces/[^/]+/export/visual"
          backends:
          - serviceName: my-gooddata-cn-export-controller
            servicePort: 6580
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: export-controller-schemas
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/schemas/export"
          backends:
          - serviceName: my-gooddata-cn-export-controller
            servicePort: 6580
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # auth-service        
        - name: auth-service-auth
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/auth"
          backends:
          - serviceName: my-gooddata-cn-auth-service
            servicePort: 9050
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: auth-service-schemas
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/schemas/auth"
          backends:
          - serviceName: my-gooddata-cn-auth-service
            servicePort: 9050
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: auth-service-invite
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/invite"
          backends:
          - serviceName: my-gooddata-cn-auth-service
            servicePort: 9050
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: auth-service-profile
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/profile"
          backends:
          - serviceName: my-gooddata-cn-auth-service
            servicePort: 9050
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: auth-service
          priority: 300
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/login"
            - "/login/*"
            - "/oauth2"
            - "/oauth2/*"
            - "/logout"
            - "/appLogin"
          backends:
          - serviceName: my-gooddata-cn-auth-service
            servicePort: 9050
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # scan-model        
        - name: scan-model-scan
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/dataSources/[^/]+/scan"
          backends:
          - serviceName: my-gooddata-cn-scan-model
            servicePort: 9060
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: scan-model-dtest
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/dataSources/[^/]+/test"
          backends:
          - serviceName: my-gooddata-cn-scan-model
            servicePort: 9060
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: scan-model-test
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/dataSource/test"
          backends:
          - serviceName: my-gooddata-cn-scan-model
            servicePort: 9060
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: scan-model-col-stats
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/dataSources/[^/]+/computeColumnStatistics"
          backends:
          - serviceName: my-gooddata-cn-scan-model
            servicePort: 9060
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: scan-model-schemas
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/schemas/scan"
          backends:
          - serviceName: my-gooddata-cn-scan-model
            servicePort: 9060
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # result-cache        
        - name: result-cache-collect
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/collectCacheUsage"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-schemas
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/schemas/result"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-upload
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/staging/upload"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-analyze
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/staging/analyzeCsv"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-import
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/dataSources/[^/]+/importCsv"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-list
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/dataSources/[^/]+/listFiles"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-delete
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/dataSources/[^/]+/deleteFiles"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true        
        - name: result-cache-manifests
          priority: 999
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
            exprs:
            - subject:
                scope: Path
              op: RegexMatch
              value: "/api/v\\d+/actions/fileStorage/dataSources/[^/]+/readCsvFileManifests"
          backends:
          - serviceName: my-gooddata-cn-result-cache
            servicePort: 9040
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # metadata-api        
        - name: metadata-api
          priority: 200
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/api/*"
          backends:
          - serviceName: my-gooddata-cn-metadata-api
            servicePort: 9007
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true

        # api-gateway        
        - name: api-gateway
          priority: 101
          timeout:
            read: 182s
          match:
            hosts:
            - ''
            paths:
            - "/analyze"
            - "/components"
            - "/dashboards"
            - "/modeler"
            - "/metrics"
            - "/"
            - "/*"
          backends:
          - serviceName: my-gooddata-cn-api-gateway
            servicePort: 9092
          plugins:
          - name: redirect
            enable: true
            config:
              http_to_https: true          
          - name: proxy-rewrite
            enable: true
            config:
              regex_uri:
              - "^/(analyze|components|dashboards|metrics|modeler)$"
              - "/$1/"
---
# Source: gooddata-cn/templates/organization-controller/configmap-ingress-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-org-controller-ingress-tpl
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: |-
    apiVersion: networking.k8s.io/v1
    kind: Ingress
    metadata:
      name: my-gooddata-cn-ingress-all
      labels: {}
        # TBD - won't be managed by Helm
      annotations:
        nginx.ingress.kubernetes.io/use-regex: "true"
        nginx.ingress.kubernetes.io/proxy-body-size: 20m
        nginx.ingress.kubernetes.io/proxy-body-size: "20971520"
        nginx.ingress.kubernetes.io/configuration-snippet: |
          rewrite ^(/analyze)$ $1/ permanent;
          rewrite ^(/apidocs)$ $1/ permanent;
          rewrite ^(/components)$ $1/ permanent;
          rewrite ^(/dashboards)$ $1/ permanent;
          rewrite ^(/metrics)$ $1/ permanent;
          rewrite ^(/modeler)$ $1/ permanent;
    spec:
      ingressClassName: nginx
      rules:
        - http:
            paths:
              # AFM              
              - path: /api/v\d+/actions/workspaces/[^/]+/execution/.*
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-afm-exec-api
                    port:
                      number: 9000              
              - path: /api/v\d+/actions/workspaces/[^/]+/ai/.*
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-afm-exec-api
                    port:
                      number: 9000              
              - path: /api/v\d+/schemas/afm
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-afm-exec-api
                    port:
                      number: 9000

              # API Gateway              
              - path: /analyze
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092              
              - path: /components
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092              
              - path: /dashboards
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092              
              - path: /modeler
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092              
              - path: /metrics
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092              
              - path: /
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-api-gateway
                    port:
                      number: 9092

              # Auth Service              
              - path: /api/v\d+/auth
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /api/v\d+/schemas/auth
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /login
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /oauth2
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /logout
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /appLogin
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /api/v\d+/actions/invite
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050              
              - path: /api/v\d+/profile
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-auth-service
                    port:
                      number: 9050

              # Scan              
              - path: /api/v\d+/actions/dataSources/[^/]+/scan.*
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-scan-model
                    port:
                      number: 9060              
              - path: /api/v\d+/actions/dataSources/[^/]+/test
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-scan-model
                    port:
                      number: 9060              
              - path: /api/v\d+/actions/dataSource/test
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-scan-model
                    port:
                      number: 9060              
              - path: /api/v\d+/actions/dataSources/[^/]+/computeColumnStatistics
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-scan-model
                    port:
                      number: 9060              
              - path: /api/v\d+/schemas/scan
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-scan-model
                    port:
                      number: 9060

              # Apidocs              
              - path: /apidocs
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-apidocs
                    port:
                      number: 9999

              # Metadata
              # Catch-all rule for reporting errors for requests to non-existent URIs to /api              
              - path: /api
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-metadata-api
                    port:
                      number: 9007

              # Export controller              
              - path: /api/v\d+/actions/workspaces/[^/]+/export/tabular.*
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-export-controller
                    port:
                      number: 6580              
              - path: /api/v\d+/actions/workspaces/[^/]+/export/visual.*
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-export-controller
                    port:
                      number: 6580              
              - path: /api/v\d+/schemas/export
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-export-controller
                    port:
                      number: 6580

              # Result cache              
              - path: /api/v\d+/actions/collectCacheUsage
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/schemas/result
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/staging/upload
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/staging/analyzeCsv
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/dataSources/[^/]+/importCsv
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/dataSources/[^/]+/listFiles
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/dataSources/[^/]+/deleteFiles
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040              
              - path: /api/v\d+/actions/fileStorage/dataSources/[^/]+/readCsvFileManifests
                pathType: ImplementationSpecific
                backend:
                  service:
                    name: my-gooddata-cn-result-cache
                    port:
                      number: 9040

          # Provided by Organization Custom Resource - spec.hostname
          host: ''
      tls:
        - hosts:
            - ''
          secretName: ''
---
# Source: gooddata-cn/templates/quiver/config.yaml
kind: ConfigMap
apiVersion: v1
metadata:
  name: my-gooddata-cn-quiver-config
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  # Quiver default config files for various envs
  quiver-cache.conf.toml: |
    # Note: many config params are set through ENV variables so check them

    #######################################################################
    # Shard configuration
    #######################################################################

    memory_cache_size = "256M"
    mmap_cache_size = "256M"
    disk_cache_size = "900M"

    #######################################################################
    # Node configuration
    #######################################################################

    etcd_registration_resolver = "force"
    listen_flight_host = "0.0.0.0"
    metrics_host = "0.0.0.0"
    modules = [
      "quiver_shard",
      "quiver_policy",
    ]
        
    etcd.0 = { host = "my-gooddata-cn-etcd-0.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.1 = { host = "my-gooddata-cn-etcd-1.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.2 = { host = "my-gooddata-cn-etcd-2.my-gooddata-cn-etcd-headless", port = 2379 }
    telemetry_log_keys = { "trace_id" = "traceId", "span_id" = "spanId", "parent_span_id" = "parentSpanId" }
    otel_service_name = "quiver-cache"

    # DoGet throttling; primarily intended to avoid thundering herds causing excessive
    # memory spikes. All flights with size above 5MiB are subject to throttling which
    # ensures the all currently active DoGet requests can be sending at most 200Mi in
    # total. Flights smaller than that are not throttled at all.
    concurrent_get_sum_limit = "200Mi"
    concurrent_get_size_threshold = "5Mi"
    concurrent_get_throttle_timeout = 2000

    #######################################################################
    # Cache policy configuration
    #######################################################################

    limit_reporting_prometheus = true
    metrics_for_policies = ["default"]
    metrics_for_storclasses = [
        "raw_cache",
        "result_cache",
        "raw_cache_non_durable",
        "result_cache_non_durable",
        "raw_cache_tmp",
        "result_cache_tmp",
        "files_cache",
    ]

    #######################################################################
    # Storage and storage class configuration
    #######################################################################

    [storage_class.raw_cache]
    flight_prefix = "cache/raw"
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    [storage_class.result_cache]
    flight_prefix = "cache/result"
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    [storage_class.raw_cache_non_durable]
    flight_prefix = "cache/raw_non_durable"
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    [storage_class.result_cache_non_durable]
    flight_prefix = "cache/result_non_durable"
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    [storage_class.raw_cache_tmp]
    flight_prefix = "cache/raw_tmp"
    flight_ttl = 900
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    [storage_class.result_cache_tmp]
    flight_prefix = "cache/result_tmp"
    flight_ttl = 900
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"

    # obsolete, use files_cache instead
    [storage_class.connector_cache]
    flight_prefix = "cache/connector"
    cache_tier.in_memory = { type = "memory", max_flight_size = "1M", upload_spill_to = "on_disk", spill_to = "on_disk", move_to = "on_disk", move_after = 30 }
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'in_memory'
    durability = "none"
    flight_ttl = 900

    [storage_class.files_cache]
    flight_prefix = "cache/files"
    cache_tier.on_disk = { type = "disk" }
    upload_to_tier = 'on_disk'
    durability = "none"
    flight_ttl = 900

  quiver-xtab.conf.toml: |
    # Note: many config params are set through ENV variables so check them

    #######################################################################
    # Node configuration
    #######################################################################

    etcd_registration_resolver = "force"
    listen_flight_host = "0.0.0.0"
    metrics_host = "0.0.0.0"
    modules = [
      "quiver_dataframe",
    ]
    dataframe_ops = [
        "gooddata_df_ops.crosstab.op",
        "gooddata_df_ops.alerting.op",
    ]
        
    etcd.0 = { host = "my-gooddata-cn-etcd-0.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.1 = { host = "my-gooddata-cn-etcd-1.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.2 = { host = "my-gooddata-cn-etcd-2.my-gooddata-cn-etcd-headless", port = 2379 }
    telemetry_log_keys = { "trace_id" = "traceId", "span_id" = "spanId", "parent_span_id" = "parentSpanId" }
    otel_service_name = "quiver-xtab"

    #######################################################################
    # Dataframe configuration
    #######################################################################

    dataframe_mem_limit = "256M"
    dataframe_task_threads = 2
    dataframe_task_workers = 1

  quiver-datasource.conf.toml: |
    # Note: many config params are set through ENV variables so check them

    #######################################################################
    # Node configuration
    #######################################################################

    etcd_registration_resolver = "force"
    listen_flight_host = "0.0.0.0"
    metrics_host = "0.0.0.0"
    modules = [
      "quiver_connector", "quiver_sql_query"
    ]
        
    etcd.0 = { host = "my-gooddata-cn-etcd-0.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.1 = { host = "my-gooddata-cn-etcd-1.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.2 = { host = "my-gooddata-cn-etcd-2.my-gooddata-cn-etcd-headless", port = 2379 }
    telemetry_log_keys = { "trace_id" = "traceId", "span_id" = "spanId", "parent_span_id" = "parentSpanId" }
    otel_service_name = "quiver-datasource"

    # plug in secrets provider that talks back to tiger to obtain secrets
    # needed to authenticate to a data source; this provider is only needed
    # in the datasource pods because they run quiver-connector module which
    # spin up connectors to data sources
    secrets_providers = ["tiger_secrets_provider.provider"]

    #######################################################################
    # Connector configuration
    #######################################################################

    [driver.files]
    package = "quiver_ds_files.driver"

    [driver.flight]
    package = "quiver_ds_flight.driver"

  quiver-ml.conf.toml: |
    # Note: many config params are set through ENV variables so check them

    #######################################################################
    # Node configuration
    #######################################################################

    etcd_registration_resolver = "force"
    listen_flight_host = "0.0.0.0"
    metrics_host = "0.0.0.0"
    modules = [
      "quiver_dataframe",
    ]
    dataframe_ops = [
      "gooddata_df_ops.anomaly_detection.op",
      "gooddata_df_ops.clustering.op",
      "gooddata_df_ops.forecast.op",
      "gooddata_df_ops.kda.op",
    ]
        
    etcd.0 = { host = "my-gooddata-cn-etcd-0.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.1 = { host = "my-gooddata-cn-etcd-1.my-gooddata-cn-etcd-headless", port = 2379 }
    etcd.2 = { host = "my-gooddata-cn-etcd-2.my-gooddata-cn-etcd-headless", port = 2379 }
    telemetry_log_keys = { "trace_id" = "traceId", "span_id" = "spanId", "parent_span_id" = "parentSpanId" }
    otel_service_name = "quiver-ml"

    #######################################################################
    # Dataframe configuration
    #######################################################################

    dataframe_mem_limit = "256M"
    dataframe_task_threads = 2
    dataframe_task_workers = 1
  quiver.logging.ini: |
    [loggers]
    keys = root, quiver

    [handlers]
    keys = quiver_stream_handler

    [formatters]
    keys = quiver_formatter

    [logger_root]
    level = INFO
    handlers = quiver_stream_handler

    [logger_quiver]
    level = INFO
    qualname = quiver
    handlers =

    [handler_quiver_stream_handler]
    class = StreamHandler
    level = DEBUG
    formatter = quiver_formatter
    args = (sys.stderr,)

    [formatter_quiver_formatter]
    format = %(message)s
---
# Source: gooddata-cn/templates/ui-env-configs.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-env-configs
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  env-configs.js: |-
    window._env_ = {
        INTERCOM_API_KEY: "",
    };
---
# Source: gooddata-cn/templates/visual-exporter-service/squid-config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-squid-config
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: visualExporterService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  squid.conf: |+
    # listening port
    http_port localhost:3128

    # disable caching
    cache deny all

    #disable pid file
    pid_filename none

    # logging to stdout
    access_log stdio:/dev/stdout
    cache_store_log none
    cache_log stdio:/dev/stdout

    # disable log file rotation
    logfile_rotate 0

    debug_options 28,2

    # specify ACLs
    acl localsrc src 127.0.0.1/32 ::1

    acl localdst dst 0.0.0.0/8       # RFC1700
    acl localdst dst 10.0.0.0/8      # RFC1918 possible internal network
    acl localdst dst 127.0.0.0/8 ::1 # RFC1700
    acl localdst dst 172.16.0.0/12   # RFC1918 possible internal network
    acl localdst dst 192.168.0.0/16  # RFC1918 possible internal network
    acl localdst dst 169.254.0.0/16  # RFC3927 link-local
    acl localdst dst fc00::/7        # RFC 4193 local private network range
    acl localdst dst fe80::/10       # RFC 4291 link-local (directly plugged) machines

    # ports and methods
    acl Safe_ports port 80 443 8443
    acl SSL_ports port 443 8443
    acl CONNECT method CONNECT
    acl METHODS method GET POST PUT DELETE CONNECT

    # acces rules
    http_access deny !Safe_ports
    http_access deny !METHODS
    http_access deny CONNECT !SSL_ports
    http_access allow localsrc !localdst

    http_access deny all
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-gooddata-cn-redis-ha
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
rules:
- apiGroups:
    - ""
  resources:
    - endpoints
  verbs:
    - get
---
# Source: gooddata-cn/templates/organization-controller/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: my-gooddata-cn-controller
  labels:

    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
rules:
# operator posts events about progress and errors
- apiGroups: [""]
  resources: ["events"]
  verbs: ["create"]
# operator monitors its configmap for changes
- apiGroups: [""]
  resources: ["configmaps"]
  verbs: ["get", "watch", "list", "patch"]
# operator manages Ingress objects
- apiGroups: ["networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["*"]
  # operator manages Apisix objects
- apiGroups: ["apisix.apache.org"]
  resources: ["*"]
  verbs: ["*"]
# watch and handle our custom resources
- apiGroups: ["controllers.gooddata.com"]
  resources: ["organizations", "organizations/finalizers"]
  verbs: ["get", "list", "watch", "patch", "update"]
# peering of operator instances
- apiGroups: ["kopf.dev"]
  resources: ["kopfpeerings"]
  verbs: ["list", "watch", "patch", "get"]
# operator gets secret for oauthClientSecret
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["get"]
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-gooddata-cn-redis-ha
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
subjects:
- kind: ServiceAccount
  name: my-gooddata-cn-redis-ha
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-gooddata-cn-redis-ha
---
# Source: gooddata-cn/templates/organization-controller/rolebinding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: my-gooddata-cn-controller
  labels:

    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: my-gooddata-cn-controller
subjects:
  - kind: ServiceAccount
    name: my-gooddata-cn-controller
---
# Source: gooddata-cn/charts/etcd/templates/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-etcd-headless
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
    app.kubernetes.io/component: etcd
  annotations:
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  publishNotReadyAddresses: true
  ports:
    - name: client
      port: 2379
      targetPort: client
    - name: peer
      port: 2380
      targetPort: peer
  selector:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/name: etcd
    app.kubernetes.io/component: etcd
---
# Source: gooddata-cn/charts/etcd/templates/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
    app.kubernetes.io/component: etcd
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: "client"
      port: 2379
      targetPort: client
      nodePort: null
    - name: "peer"
      port: 2380
      targetPort: peer
      nodePort: null
  selector:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/name: etcd
    app.kubernetes.io/component: etcd
---
# Source: gooddata-cn/charts/postgresql-ha/templates/pgpool/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-db-pgpool
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: pgpool
  annotations:
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: "postgresql"
      port: 5432
      targetPort: postgresql
      protocol: TCP
      nodePort: null
  selector:
    app.kubernetes.io/name: db
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pgpool
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/metrics-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-db-postgresql-metrics
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
    prometheus: kube-prometheus
  annotations:
    prometheus.io/port: "9187"
    prometheus.io/scrape: "true"
spec:
  type: ClusterIP
  
  
  ports:
    - name: metrics
      port: 9187
      targetPort: metrics
      nodePort: null
  selector:
    app.kubernetes.io/name: db
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: postgresql
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-db-postgresql-headless
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - name: "postgresql"
      port: 5432
      targetPort: postgresql
      protocol: TCP
  selector:
    app.kubernetes.io/name: db
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: postgresql
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-db-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
  annotations:
spec:
  type: ClusterIP
  ports:
    - name: "postgresql"
      port: 5432
      targetPort: postgresql
      protocol: TCP
  selector:
    app.kubernetes.io/name: db
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: postgresql
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-announce-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-redis-ha-announce-0
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
  annotations:
spec:
  publishNotReadyAddresses: true
  type: ClusterIP
  ports:
  - name: tcp-server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: tcp-sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  - name: http-exporter
    port: 9121
    protocol: TCP
    targetPort: exporter-port
  selector:
    release: my-gooddata-cn
    app: redis-ha
    "statefulset.kubernetes.io/pod-name": my-gooddata-cn-redis-ha-server-0
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-announce-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-redis-ha-announce-1
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
  annotations:
spec:
  publishNotReadyAddresses: true
  type: ClusterIP
  ports:
  - name: tcp-server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: tcp-sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  - name: http-exporter
    port: 9121
    protocol: TCP
    targetPort: exporter-port
  selector:
    release: my-gooddata-cn
    app: redis-ha
    "statefulset.kubernetes.io/pod-name": my-gooddata-cn-redis-ha-server-1
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-announce-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-redis-ha-announce-2
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
  annotations:
spec:
  publishNotReadyAddresses: true
  type: ClusterIP
  ports:
  - name: tcp-server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: tcp-sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  - name: http-exporter
    port: 9121
    protocol: TCP
    targetPort: exporter-port
  selector:
    release: my-gooddata-cn
    app: redis-ha
    "statefulset.kubernetes.io/pod-name": my-gooddata-cn-redis-ha-server-2
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-redis-ha
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
    exporter: enabled
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  ports:
  - name: tcp-server
    port: 6379
    protocol: TCP
    targetPort: redis
  - name: tcp-sentinel
    port: 26379
    protocol: TCP
    targetPort: sentinel
  - name: http-exporter-port
    port: 9121
    protocol: TCP
    targetPort: exporter-port
  selector:
    release: my-gooddata-cn
    app: redis-ha
---
# Source: gooddata-cn/templates/afm-exec-api/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-afm-exec-api-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6571
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
---
# Source: gooddata-cn/templates/afm-exec-api/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-afm-exec-api
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
---
# Source: gooddata-cn/templates/analytical-designer/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-analytical-designer
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: analyticalDesigner
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9300
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: analyticalDesigner
---
# Source: gooddata-cn/templates/api-gateway/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-api-gateway-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6572
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
---
# Source: gooddata-cn/templates/api-gateway/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-api-gateway
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9092
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
---
# Source: gooddata-cn/templates/apidocs/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-apidocs
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiDocs
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9999
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiDocs
---
# Source: gooddata-cn/templates/auth-service/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-auth-service-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6573
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
---
# Source: gooddata-cn/templates/auth-service/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-auth-service
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9050
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
---
# Source: gooddata-cn/templates/calcique/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-calcique-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: calcique
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6577
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: calcique
---
# Source: gooddata-cn/templates/dashboards/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-dashboards
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dashboards
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9500
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dashboards
---
# Source: gooddata-cn/templates/dex/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-dex-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  sessionAffinity: None
  ports:
  - name: grpc
    targetPort: grpc
    port: 5000
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
---
# Source: gooddata-cn/templates/dex/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-dex
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
  - name: http
    targetPort: http
    port: 32000
  - name: metrics
    targetPort: metrics
    port: 37000
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
---
# Source: gooddata-cn/templates/export-controller/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-export-controller-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6578
      protocol: TCP
      targetPort: grpc
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
---
# Source: gooddata-cn/templates/export-controller/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-export-controller
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6580
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
---
# Source: gooddata-cn/templates/home-ui/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-home-ui
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: homeUi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9600
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: homeUi
---
# Source: gooddata-cn/templates/ldm-modeler/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-ldm-modeler
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: ldmModeler
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9400
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: ldmModeler
---
# Source: gooddata-cn/templates/measure-editor/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-measure-editor
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: measureEditor
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9700
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: measureEditor
---
# Source: gooddata-cn/templates/metadata-api/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-metadata-api-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6572
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
---
# Source: gooddata-cn/templates/metadata-api/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-metadata-api
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9007
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
---
# Source: gooddata-cn/templates/pdf-stapler-service/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-pdf-stapler-service-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pdfStaplerService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6889
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pdfStaplerService
---
# Source: gooddata-cn/templates/quiver/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-quiver-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 16001
      targetPort: grpc
      protocol: TCP
      name: grpc
  clusterIP: None
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
---
# Source: gooddata-cn/templates/result-cache/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-result-cache-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: resultCache
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6567
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: resultCache
---
# Source: gooddata-cn/templates/result-cache/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-result-cache
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: resultCache
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9040
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: resultCache
---
# Source: gooddata-cn/templates/scan-model/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-scan-model
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: scanModel
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9060
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: scanModel
---
# Source: gooddata-cn/templates/sql-executor/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-sql-executor-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: sqlExecutor
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6570
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: sqlExecutor
---
# Source: gooddata-cn/templates/tabular-exporter/service-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-tabular-exporter-headless
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: tabularExporter
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  clusterIP: None
  ports:
    - port: 6789
      targetPort: grpc
      protocol: TCP
      name: grpc
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: tabularExporter
---
# Source: gooddata-cn/templates/visual-exporter-service/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-visual-exporter-service
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: visualExporterService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: visualExporterService
---
# Source: gooddata-cn/templates/web-components/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: my-gooddata-cn-web-components
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: webComponents
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9800
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: webComponents
---
# Source: gooddata-cn/charts/postgresql-ha/templates/pgpool/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-db-pgpool
  namespace: "default"
  labels: 
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: pgpool
spec:
  replicas: 2
  selector:
    matchLabels: 
      app.kubernetes.io/name: db
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: pgpool
  template:
    metadata:
      labels: 
        app.kubernetes.io/name: db
        helm.sh/chart: postgresql-ha-9.4.9
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "14.5.0"
        app.kubernetes.io/component: pgpool
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-gooddata-cn
                    app.kubernetes.io/name: db
                    app.kubernetes.io/component: pgpool
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      initContainers:
      # Auxiliary vars to populate environment variables
      containers:
        - name: pgpool
          image: docker.io/bitnami/pgpool:4.3.3-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: PGPOOL_POSTGRES_CUSTOM_USERS
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-pgpool-custom-users
                  key: usernames
            - name: PGPOOL_POSTGRES_CUSTOM_PASSWORDS
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-pgpool-custom-users
                  key: passwords
            - name: PGPOOL_BACKEND_NODES
              value: 0:my-gooddata-cn-db-postgresql-0.my-gooddata-cn-db-postgresql-headless:5432,1:my-gooddata-cn-db-postgresql-1.my-gooddata-cn-db-postgresql-headless:5432,2:my-gooddata-cn-db-postgresql-2.my-gooddata-cn-db-postgresql-headless:5432,
            - name: PGPOOL_SR_CHECK_USER
              value: "repmgr"
            - name: PGPOOL_SR_CHECK_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-postgresql
                  key: repmgr-password
            - name: PGPOOL_SR_CHECK_DATABASE
              value: "postgres"
            - name: PGPOOL_ENABLE_LDAP
              value: "no"
            - name: PGPOOL_POSTGRES_USERNAME
              value: "postgres"
            - name: PGPOOL_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-postgresql
                  key: postgresql-password
            - name: PGPOOL_ADMIN_USERNAME
              value: "admin"
            - name: PGPOOL_ADMIN_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-pgpool
                  key: admin-password
            - name: PGPOOL_AUTHENTICATION_METHOD
              value: "scram-sha-256"
            - name: PGPOOL_ENABLE_LOAD_BALANCING
              value: "yes"
            - name: PGPOOL_DISABLE_LOAD_BALANCE_ON_WRITE
              value: transaction
            - name: PGPOOL_ENABLE_LOG_CONNECTIONS
              value: "no"
            - name: PGPOOL_ENABLE_LOG_HOSTNAME
              value: "yes"
            - name: PGPOOL_ENABLE_LOG_PER_NODE_STATEMENT
              value: "no"
            - name: PGPOOL_NUM_INIT_CHILDREN
              value: "70"
            - name: PGPOOL_RESERVED_CONNECTIONS
              value: '1'
            - name: PGPOOL_MAX_POOL
              value: "1"
            - name: PGPOOL_CHILD_LIFE_TIME
              value: ""
            - name: PGPOOL_CLIENT_IDLE_LIMIT
              value: "1860"
            - name: PGPOOL_ENABLE_TLS
              value: "no"
          envFrom:
          ports:
            - name: postgresql
              containerPort: 5432
              protocol: TCP
          livenessProbe:
            failureThreshold: 5
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /opt/bitnami/scripts/pgpool/healthcheck.sh
          readinessProbe:
            failureThreshold: 5
            initialDelaySeconds: 5
            periodSeconds: 5
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - bash
                - -ec
                - PGPASSWORD=${PGPOOL_POSTGRES_PASSWORD} psql -U "postgres" -d "postgres" -h /opt/bitnami/pgpool/tmp -tA -c "SELECT 1" >/dev/null
          resources:
            limits: {}
            requests: {}
          volumeMounts:
      volumes:
---
# Source: gooddata-cn/templates/afm-exec-api/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-afm-exec-api
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: afmExecApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: afmExecApi
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: afmExecApi
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9001"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: afm-exec-api
          securityContext:
            {}
          image: "gooddata/afm-exec-api:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9000
              protocol: TCP
            - name: actuator
              containerPort: 9001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9001
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9001
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9001
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9001/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=100M -Xms320m -Xmx320m -XX:MaxMetaspaceSize=170M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: GRPC_CALCIQUE_HOST
              value: "my-gooddata-cn-calcique-headless"
            - name: GRPC_CALCIQUE_PORT
              value: "6577"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_RESULTCACHE_HOST
              value: "my-gooddata-cn-result-cache-headless"
            - name: GRPC_RESULTCACHE_PORT
              value: "6567"
            - name: GRPC_LICENSE_HOST
              value: "my-gooddata-cn-auth-service-headless"
            - name: GRPC_LICENSE_PORT
              value: "6573"
            - name: GRPC_DATASOURCE_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_DATASOURCE_PORT
              value: "6572"
            - name: GRPC_SQLEXECUTOR_HOST
              value: "my-gooddata-cn-sql-executor-headless"
            - name: GRPC_SQLEXECUTOR_PORT
              value: "6570"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: QUIVER_LOCATION_ENDPOINTS
              value: "my-gooddata-cn-quiver-headless:16001"
            - name: LIMIT_MAX_AFM_RESULT_PAGE_SIZE_BYTES
              value: "5242880"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: GDC_FEATURES_VALUES_ENABLE_SCATTER_PLOT_CLUSTERING
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_SMART_FUNCTIONS
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MULTIPLE_DATA_SOURCES_IN_WORKSPACE
              value: "true"
          resources:
            limits:
              cpu: 750m
              memory: 965Mi
            requests:
              cpu: 100m
              memory: 600Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/analytical-designer/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-analytical-designer
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: analyticalDesigner
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: analyticalDesigner
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: analyticalDesigner
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: analytical-designer
          securityContext:
            {}
          image: "gooddata/analytical-designer:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /analyze/
              port: 9300
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /analyze/
              port: 9300
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 9300
              protocol: TCP
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
          volumeMounts:
            - name: env-configs
              mountPath: /usr/share/nginx/html/analyze/env-configs.js
              subPath: env-configs.js
      volumes:
        - name: env-configs
          configMap:
            name: my-gooddata-cn-env-configs
            defaultMode: 0444
---
# Source: gooddata-cn/templates/api-gateway/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-api-gateway
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiGateway
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: apiGateway
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: apiGateway
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9093"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      volumes:
        - name: route-config
          configMap:
            name: my-gooddata-cn-api-gateway-config
      containers:
        - name: api-gateway
          securityContext:
            {}
          image: "gooddata/api-gateway:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9092
              protocol: TCP
            - name: actuator
              containerPort: 9093
              protocol: TCP
            - name: grpc
              containerPort: 6572
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9093
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9093
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9093
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9093/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=60M -Xms140m -Xmx140m -XX:MaxMetaspaceSize=100M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: SPRING_CONFIG_LOCATION
              value: classpath:/,/app-config/application-routes.yaml
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: SPRING_PROFILES_ACTIVE
              value: default
          resources:
            limits:
              cpu: 500m
              memory: 540Mi
            requests:
              cpu: 100m
              memory: 300Mi
          volumeMounts:
            - name: route-config
              mountPath: /app-config/
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/apidocs/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-apidocs
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: apiDocs
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: apiDocs
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: apiDocs
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: apidocs
          securityContext:
            {}
          image: "gooddata/apidocs:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /
              port: 8080
          readinessProbe:
            httpGet:
              path: /
              port: 8080
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
---
# Source: gooddata-cn/templates/auth-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-auth-service
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: authService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: authService
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: authService
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9051"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: auth-service
          securityContext:
            {}
          image: "gooddata/auth-service:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9050
              protocol: TCP
            - name: actuator
              containerPort: 9051
              protocol: TCP
            - name: grpc
              containerPort: 6573
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9051
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9051
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9051
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9051/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=100M -Xms190m -Xmx190m -XX:MaxMetaspaceSize=150M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_INVITEGENERATOR_ENABLED
              value: "false"
            - name: PULSAR_PRODUCERS_INVITEGENERATOR_TOPIC
              value: "default/my-gooddata-cn/invitations"
            - name: PULSAR_PRODUCERS_INVITEGENERATOR_MESSAGE_TTL
              value: "300"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_PROFILES_ACTIVE
              value: default,localDex
            - name: GRPC_DEX_HOST
              value: "my-gooddata-cn-dex-headless"
            - name: GRPC_DEX_PORT
              value: "5000"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_KPI_DASHBOARD_EXPORT_PDF
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_USER_MANAGEMENT
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MYSQL_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MARIADB_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_ORACLE_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_SINGLESTORE_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_PDM_REMOVAL_DEPRECATION_PHASE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_COMPOSITE_GRAIN
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MOTHERDUCK_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_SMART_FUNCTIONS
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_SCATTER_PLOT_CLUSTERING
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_RICH_TEXT_DESCRIPTIONS
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_WORKSPACES_HIERARCHY_VIEW
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MULTIPLE_DATA_SOURCES_IN_WORKSPACE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_ROLLUP_TOTALS
              value: "true"
          resources:
            limits:
              cpu: 500m
              memory: 750Mi
            requests:
              cpu: 100m
              memory: 400Mi
          volumeMounts:
            - mountPath: /secret
              name: license
      volumes:
        - secret:
            items:
              - key: license
                path: license
            secretName: my-gooddata-cn-license-key
          name: license
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/automation/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-automation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: automation
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: automation
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: automation
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9098"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      initContainers:
        - name: check-postgres-db
          image: "gooddata/tools:3.17.0"
          securityContext:
            runAsUser: 1000
          env:
            - name: PGHOST
              value: "my-gooddata-cn-db-pgpool"
            - name: PGPORT
              value: "5432"
            - name: PGUSER
              value: "postgres"
            - name: PGDATABASE
              value: postgres
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: AUTOMATION_PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
          command: ['/bin/bash', '-c']
          args:
            - |+
              until pg_isready; do sleep 2; done;
              if [ "$(psql -Atq -c "select 1 from pg_database where datname = 'automation'")" != "1" ] ; then
                createdb automation || exit 1 ;
              fi ;
          resources:
            limits:
              cpu: 500m
              memory: 685Mi
            requests:
              cpu: 100m
              memory: 450Mi
      
      
      containers:
        - name: automation
          securityContext:
            {}
          image: "gooddata/automation:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: actuator
              containerPort: 9098
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9098
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9098
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9098
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9098/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=60M -Xms200m -Xmx200m -XX:MaxMetaspaceSize=210M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: GDC_AUTOMATION_ENCRYPTOR_KEYSET
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-encryptor-keyset"
                  key: keySet
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_EXPORT_TABULAR_SCHEDULED_TOPIC
              value: "default/my-gooddata-cn/export-tabular-scheduled.request"
            - name: PULSAR_PRODUCERS_EXPORT_TABULAR_SCHEDULED_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_EXPORT_VISUAL_SCHEDULED_TOPIC
              value: "default/my-gooddata-cn/export-visual-scheduled.request"
            - name: PULSAR_PRODUCERS_EXPORT_VISUAL_SCHEDULED_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_AUTOMATION_SYNC_TOPIC
              value: "default/my-gooddata-cn/automation-sync"
            - name: PULSAR_CONSUMERS_AUTOMATION_SYNC_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/automation-sync.DLQ"
            - name: PULSAR_CONSUMERS_METADATA_SYNC_TOPIC
              value: "default/my-gooddata-cn/metadata.sync"
            - name: GRPC_EXPORT_HOST
              value: "my-gooddata-cn-export-controller-headless"
            - name: GRPC_EXPORT_PORT
              value: "6578"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_AFMEXEC_HOST
              value: "my-gooddata-cn-afm-exec-api-headless"
            - name: GRPC_AFMEXEC_PORT
              value: "6571"
            - name: GRPC_RESULTCACHE_HOST
              value: "my-gooddata-cn-result-cache-headless"
            - name: GRPC_RESULTCACHE_PORT
              value: "6567"
            - name: QUIVER_LOCATION_ENDPOINTS
              value: "my-gooddata-cn-quiver-headless:16001"
            - name: SPRING_DATASOURCE_URL
              value: "jdbc:postgresql://my-gooddata-cn-db-pgpool:5432/automation"
            - name: SPRING_DATASOURCE_USERNAME
              value: "postgres"
            - name: SPRING_DATASOURCE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: SPRING_MAIL_HOST
              valueFrom:
                secretKeyRef:
                  key: smtp_host
                  name: "my-gooddata-cn-automation-smtp-credentials"
            - name: SPRING_MAIL_USERNAME
              valueFrom:
                secretKeyRef:
                  key: smtp_username
                  name: "my-gooddata-cn-automation-smtp-credentials"
            - name: SPRING_MAIL_PASSWORD
              valueFrom:
                secretKeyRef:
                  key: smtp_password
                  name: "my-gooddata-cn-automation-smtp-credentials"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: SPRING_PROFILES_ACTIVE
              value: default
          resources:
            limits:
              cpu: 500m
              memory: 685Mi
            requests:
              cpu: 100m
              memory: 450Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/calcique/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-calcique
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: calcique
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: calcique
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: calcique
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9012"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: calcique
          securityContext:
            {}
          image: "gooddata/calcique:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9011
              protocol: TCP
            - name: actuator
              containerPort: 9012
              protocol: TCP
            - name: grpc
              containerPort: 6577
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9012
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9012
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9012
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9012/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=110M -Xms380m -Xmx380m -XX:MaxMetaspaceSize=170M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_SQLEXECUTOR_TOPIC
              value: "default/my-gooddata-cn/sql.select"
            - name: PULSAR_PRODUCERS_SQLEXECUTOR_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_CALCIQUE_TOPIC
              value: "default/my-gooddata-cn/compute.calcique"
            - name: PULSAR_PRODUCERS_CALCIQUE_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_COMPUTE_TOPIC
              value: "default/my-gooddata-cn/compute.calcique"
            - name: PULSAR_CONSUMERS_COMPUTE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/compute.calcique.DLQ"
            - name: PULSAR_CONSUMERS_MODEL_UPDATE_TOPIC
              value: "default/my-gooddata-cn/metadata.model"
            - name: PULSAR_CONSUMERS_MODEL_UPDATE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/metadata.model.calcique.DLQ"
            - name: PULSAR_CONSUMERS_DATA_SOURCE_CHANGE_TOPIC
              value: "default/my-gooddata-cn/data-source.change"
            - name: PULSAR_CONSUMERS_DATA_SOURCE_CHANGE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/data-source.change.calcique.DLQ"
            - name: PULSAR_CONSUMERS_COMPUTE_RECEIVER_QUEUE_SIZE
              value: "1"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_DATASOURCE_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_DATASOURCE_PORT
              value: "6572"
            - name: GRPC_RAWCACHE_HOST
              value: "my-gooddata-cn-result-cache-headless"
            - name: GRPC_RAWCACHE_PORT
              value: "6567"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: GDC_FEATURES_VALUES_ENABLE_UDF_COUNT_CONTEXT
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MULTIPLE_DATA_SOURCES_IN_WORKSPACE
              value: "true"
          resources:
            limits:
              cpu: 500m
              memory: 1024Mi
            requests:
              cpu: 150m
              memory: 500Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/dashboards/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-dashboards
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dashboards
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: dashboards
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: dashboards
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: dashboards
          securityContext:
            {}
          image: "gooddata/dashboards:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /dashboards/
              port: 9500
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /dashboards/
              port: 9500
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 9500
              protocol: TCP
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
          volumeMounts:
            - name: env-configs
              mountPath: /usr/share/nginx/html/dashboards/env-configs.js
              subPath: env-configs.js
      volumes:
        - name: env-configs
          configMap:
            name: my-gooddata-cn-env-configs
            defaultMode: 0444
---
# Source: gooddata-cn/templates/dex/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-dex
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  strategy:
    rollingUpdate:
      maxSurge: 0
      maxUnavailable: 1
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: dex
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: dex
      annotations:
        checksum/config: 42eebe4fa1421932fdba1acf01d6b9dde8f675c9214c6ad795bcbd221a01310a
        prometheus.io/path: "/metrics"
        prometheus.io/port: "5558"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      initContainers:
        - name: check-postgres-db
          image: "gooddata/tools:3.17.0"
          securityContext:
            runAsUser: 1000
          env:
            - name: PGHOST
              value: "my-gooddata-cn-db-pgpool"
            - name: PGPORT
              value: "5432"
            - name: PGUSER
              value: "postgres"
            - name: PGDATABASE
              value: postgres
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: DEX_PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
          command: ['/bin/bash', '-c']
          args:
            - |+
              until pg_isready; do sleep 2; done;
              if [ "$(psql -Atq -c "select 1 from pg_database where datname = 'dex'")" != "1" ] ; then
                createdb dex || exit 1 ;
              fi ;
          resources:
            limits:
              cpu: 100m
              memory: 50Mi
            requests:
              cpu: 30m
              memory: 50Mi
      
      
      containers:
        - name: dex
          image: "gooddata/dex:3.17.0"
          env:
            - name: DEX_PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
          imagePullPolicy: Always
          resources:
            limits:
              cpu: 100m
              memory: 50Mi
            requests:
              cpu: 30m
              memory: 50Mi
          ports:
            - name: http
              containerPort: 5556
              protocol: TCP
            - name: grpc
              containerPort: 5000
              protocol: TCP
            - name: metrics
              containerPort: 5558
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /dex/healthz
              port: http
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /dex/healthz
              port: http
            initialDelaySeconds: 1
            periodSeconds: 10
            timeoutSeconds: 1
            failureThreshold: 2
          volumeMounts:
            - mountPath: /etc/dex/cfg
              name: config
      volumes:
        - secret:
            defaultMode: 420
            items:
              - key: config.yaml
                path: config.yaml
            secretName: my-gooddata-cn-dex
          name: config
---
# Source: gooddata-cn/templates/export-controller/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-export-controller
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: exportController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: exportController
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: exportController
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "6581"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      volumes:
        - name: app-config
          configMap:
            name: my-gooddata-cn-export-controller-config
      containers:
        - name: export-controller
          securityContext:
            runAsUser: 1000
          image: "gooddata/export-controller:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 6580
              protocol: TCP
            - name: grpc
              containerPort: 6578
              protocol: TCP
            - name: actuator
              containerPort: 6581
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 6581
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 6581
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 6581
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:6581/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=90M -Xms130m -Xmx130m -XX:MaxMetaspaceSize=155M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: SPRING_CONFIG_LOCATION
              value: classpath:/,/app-config/application-cspConfig.yaml
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_EXPORT_TABULAR_TOPIC
              value: "default/my-gooddata-cn/export-tabular.request"
            - name: PULSAR_PRODUCERS_EXPORT_TABULAR_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_EXPORT_TABULAR_TOPIC
              value: "default/my-gooddata-cn/export-tabular.request"
            - name: PULSAR_CONSUMERS_EXPORT_TABULAR_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/export-tabular.request.DLQ"
            - name: PULSAR_CONSUMERS_EXPORT_TABULAR_SCHEDULED_TOPIC
              value: "default/my-gooddata-cn/export-tabular-scheduled.request"
            - name: PULSAR_CONSUMERS_EXPORT_TABULAR_SCHEDULED_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/export-tabular-scheduled.request.DLQ"
            - name: PULSAR_PRODUCERS_EXPORT_VISUAL_TOPIC
              value: "default/my-gooddata-cn/export-visual.request"
            - name: PULSAR_CONSUMERS_EXPORT_VISUAL_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/export-visual.request.DLQ"
            - name: PULSAR_PRODUCERS_EXPORT_VISUAL_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_EXPORT_VISUAL_TOPIC
              value: "default/my-gooddata-cn/export-visual.request"
            - name: PULSAR_CONSUMERS_EXPORT_VISUAL_SCHEDULED_TOPIC
              value: "default/my-gooddata-cn/export-visual-scheduled.request"
            - name: PULSAR_CONSUMERS_EXPORT_VISUAL_SCHEDULED_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/export-visual-scheduled.request.DLQ"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_TABULAREXPORTER_HOST
              value: "my-gooddata-cn-tabular-exporter-headless"
            - name: GRPC_TABULAREXPORTER_PORT
              value: "6789"
            - name: VISUAL_EXPORTER_SERVICE_HOST
              value: "my-gooddata-cn-visual-exporter-service"
            - name: VISUAL_EXPORTER_SERVICE_PORT
              value: "8080"
            - name: GRPC_PDFSTAPLERSERVICE_HOST
              value: "my-gooddata-cn-pdf-stapler-service-headless"
            - name: GRPC_PDFSTAPLERSERVICE_PORT
              value: "6889"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: GDC_FILESTORAGEBASEURL
              value: "/tmp/exports"
            - name: GDC_EXPORT_SCHEDULED_EXPIREINSECONDS
              value: "60"
            # Create these variables only if S3 storage is used AND (custom secret provided OR aws secret key given)
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: GDC_FEATURES_VALUES_ENABLE_KPI_DASHBOARD_EXPORT_PDF
              value: "true"
          resources:
            limits:
              cpu: 500m
              memory: 685Mi
            requests:
              cpu: 100m
              memory: 450Mi
          volumeMounts:
            - name: app-config
              mountPath: /app-config/
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/home-ui/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-home-ui
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: homeUi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: homeUi
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: homeUi
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: home-ui
          securityContext:
            {}
          image: "gooddata/home-ui:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /
              port: 9600
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /
              port: 9600
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 9600
              protocol: TCP
          volumeMounts:
            - name: env-configs
              mountPath: /usr/share/nginx/html/env-configs.js
              subPath: env-configs.js
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
      volumes:
        - name: env-configs
          configMap:
            name: my-gooddata-cn-env-configs
            defaultMode: 0444
---
# Source: gooddata-cn/templates/ldm-modeler/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-ldm-modeler
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: ldmModeler
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: ldmModeler
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: ldmModeler
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: ldm-modeler
          securityContext:
            {}
          image: "gooddata/ldm-modeler:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /modeler/
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /modeler/
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
          volumeMounts:
            - name: env-configs
              mountPath: /usr/share/nginx/html/modeler/env-configs.js
              subPath: env-configs.js
      volumes:
        - name: env-configs
          configMap:
            name: my-gooddata-cn-env-configs
            defaultMode: 0444
---
# Source: gooddata-cn/templates/measure-editor/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-measure-editor
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: measureEditor
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: measureEditor
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: measureEditor
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: measure-editor
          securityContext:
            {}
          image: "gooddata/measure-editor:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics/
              port: 9700
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /metrics/
              port: 9700
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 9700
              protocol: TCP
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
          volumeMounts:
            - name: env-configs
              mountPath: /usr/share/nginx/html/metrics/env-configs.js
              subPath: env-configs.js
      volumes:
        - name: env-configs
          configMap:
            name: my-gooddata-cn-env-configs
            defaultMode: 0444
---
# Source: gooddata-cn/templates/metadata-api/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-metadata-api
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: metadataApi
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: metadataApi
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: metadataApi
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9008"
        prometheus.io/scrape: "true"
        checksum/config: 8f04e008063e1db6562f21cf263c96711468cddfa0a3e8fce180b063087ab2ce
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      initContainers:
        - name: check-postgres-db
          image: "gooddata/tools:3.17.0"
          securityContext:
            runAsUser: 1000
          env:
            - name: PGHOST
              value: "my-gooddata-cn-db-pgpool"
            - name: PGPORT
              value: "5432"
            - name: PGUSER
              value: "postgres"
            - name: PGDATABASE
              value: postgres
            - name: PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: MD_PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: MD_EXPORTER_PGPASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-md-exporter-postgres-password"
                  key: exporter-password
          command: ['/bin/bash', '-c']
          args:
            - |+
              until pg_isready; do sleep 2; done;
              if [ "$(psql -Atq -c "select 1 from pg_database where datname = 'md'")" != "1" ] ; then
                createdb md || exit 1 ;
              fi ;
              if [ "$(psql -Atq -c "select 1 from pg_roles where rolname = 'md_exporter'")" != "1" ] ; then
                psql -c "create role md_exporter with login password '$MD_EXPORTER_PGPASSWORD';" || true ;
              fi ;
              if [ "$(psql -Atq -c "select 1 from pg_auth_members where roleid = to_regrole('pg_read_all_stats') and member=to_regrole('md_exporter') ")" != "1" ] ; then
                psql -c "grant pg_read_all_stats to md_exporter;" || true ;
              fi ;
              if [ "$(psql -Atq -d "md" -c "select 1 from pg_extension where extname = 'pg_stat_statements' and to_regrole('md_exporter') is not null and not has_function_privilege('md_exporter', to_regproc('pg_stat_statements_reset'), 'EXECUTE') ")" = "1" ] ; then
                psql -d md -c "grant execute on function pg_stat_statements_reset(userid oid, dbid oid, queryid bigint) to md_exporter;" || true
              fi ;
          resources:
            limits:
              cpu: 1250m
              memory: 1300Mi
            requests:
              cpu: 100m
              memory: 800Mi
      
      
      volumes:
        - name: app-config
          configMap:
            name: my-gooddata-cn-metadata-api-config
      containers:
        - name: metadata-api
          securityContext:
            {}
          image: "gooddata/metadata-api:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9007
              protocol: TCP
            - name: actuator
              containerPort: 9008
              protocol: TCP
            - name: grpc
              containerPort: 6572
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9008
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9008
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9008
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9008/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=140M -Xms400m -Xmx400m -XX:MaxMetaspaceSize=210M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: SPRING_CONFIG_LOCATION
              value: classpath:/,/app-config/application-cspConfig.yaml
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_MODEL_UPDATE_TOPIC
              value: "default/my-gooddata-cn/metadata.model"
            - name: PULSAR_PRODUCERS_MODEL_UPDATE_MESSAGE_TTL
              value: "300"
            # Enable metadata sync only if AI service is deployed and can consume the messages
            - name: PULSAR_PRODUCERS_METADATA_SYNC_ENABLED
              value: "false"
            - name: PULSAR_PRODUCERS_METADATA_SYNC_TOPIC
              value: "default/my-gooddata-cn/metadata.sync"
            - name: PULSAR_PRODUCERS_METADATA_SYNC_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_DATA_SOURCE_CHANGE_TOPIC
              value: "default/my-gooddata-cn/data-source.change"
            - name: PULSAR_PRODUCERS_DATA_SOURCE_CHANGE_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_CACHE_COMMAND_TOPIC
              value: "default/my-gooddata-cn/metadata.cache-command"
            - name: PULSAR_PRODUCERS_CACHE_COMMAND_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_CACHE_SETTINGS_CHANGE_TOPIC
              value: "default/my-gooddata-cn/cache-settings.change"
            - name: PULSAR_PRODUCERS_CACHE_SETTINGS_CHANGE_MESSAGE_TTL
              value: "300"
            - name: PULSAR_PRODUCERS_AUTOMATION_SYNC_TOPIC
              value: "default/my-gooddata-cn/automation-sync"
            - name: PULSAR_PRODUCERS_AUTOMATION_SYNC_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_CACHE_SETTINGS_BOOTSTRAP_TOPIC
              value: "default/my-gooddata-cn/cache-settings.bootstrap"
            - name: PULSAR_CONSUMERS_CACHE_COMMAND_TOPIC
              value: "default/my-gooddata-cn/metadata.cache-command"
            - name: SPRING_DATASOURCE_URL
              value: "jdbc:postgresql://my-gooddata-cn-db-pgpool:5432/md?reWriteBatchedInserts=true"
            - name: SPRING_DATASOURCE_USERNAME
              value: "postgres"
            - name: SPRING_DATASOURCE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: GDC_METADATA_ENCRYPTOR_ENABLED
              value: "true"
            - name: GDC_METADATA_ENCRYPTOR_KEYSET
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-encryptor-keyset"
                  key: keySet
            - name: GRPC_DATASOURCEMETADATA_HOST
              value: "my-gooddata-cn-sql-executor-headless"
            - name: GRPC_DATASOURCEMETADATA_PORT
              value: "6570"
            - name: GRPC_LICENSE_HOST
              value: "my-gooddata-cn-auth-service-headless"
            - name: GRPC_LICENSE_PORT
              value: "6573"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: BOOTSTRAP_USER
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-metadata-bootstrap"
                  key: user
            - name: BOOTSTRAP_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-metadata-bootstrap"
                  key: password
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_PROFILES_ACTIVE
              value: default,localDex
            - name: GRPC_DEX_HOST
              value: "my-gooddata-cn-dex-headless"
            - name: GRPC_DEX_PORT
              value: "5000"
            - name: GDC_TIGER_OAUTH2_LOCAL_CALLBACK_SCHEMA
              value: "https"
            - name: GDC_TIGER_OAUTH2_LOCAL_CALLBACK_PORT
              value: 
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: GDC_EXTRA_CACHE
              value: ""
            - name: GDC_CACHE_STRATEGY
              value: ""
            - name: GDCN_SETTING_ENABLE_FILE_ANALYTICS
              value: '{"value":false}'
            - name: GDC_TXN_CONFIG_BIND_TO_PRIMARY
              value: "false"
            - name: GDC_FEATURES_VALUES_ENABLE_PDM_REMOVAL_DEPRECATION_PHASE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_USER_MANAGEMENT
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MYSQL_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MARIADB_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_ORACLE_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_SINGLESTORE_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_COMPOSITE_GRAIN
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MOTHERDUCK_DATA_SOURCE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_MULTIPLE_DATA_SOURCES_IN_WORKSPACE
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_ROLLUP_TOTALS
              value: "true"
          resources:
            limits:
              cpu: 1250m
              memory: 1300Mi
            requests:
              cpu: 100m
              memory: 800Mi
          volumeMounts:
            - name: app-config
              mountPath: /app-config/
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/organization-controller/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-organization-controller
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: organizationController
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: organizationController
      
    spec:
      serviceAccountName: my-gooddata-cn-controller
      volumes:
        - name: ingress-template
          configMap:
            name: my-gooddata-cn-org-controller-ingress-tpl
        - name: apisix-crd-template
          configMap:
            name: my-gooddata-cn-org-controller-apisix-crd-tpl
      
      
      containers:
        - name: organization-controller
          image: "gooddata/organization-controller:3.17.0"
          imagePullPolicy: Always
          volumeMounts:
            - name: ingress-template
              mountPath: /tmp/ingress-tpl
            - name: apisix-crd-template
              mountPath: /tmp/apisix-crd-tpl
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: KUBE_CLIENT_TIMEOUT
              value: "10"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: CONFIGMAP_NAME
              value: my-gooddata-cn-org-controller-ingress-tpl
            - name: APISIX_CRD_CONFIGMAP_NAME
              value: my-gooddata-cn-org-controller-apisix-crd-tpl
            - name: PEERING
              value: my-gooddata-cn
            - name: GRPC_METADATA_USER
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-metadata-bootstrap"
                  key: user
            - name: GRPC_METADATA_PASS
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-metadata-bootstrap"
                  key: password
          resources:
            limits:
              cpu: 100m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 50Mi
          livenessProbe:
            httpGet:
              path: /healthz
              port: 8080
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 3
---
# Source: gooddata-cn/templates/pdf-stapler-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-pdf-stapler-service
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pdfStaplerService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: pdfStaplerService
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: pdfStaplerService
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "8287"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: pdf-stapler-service
          securityContext:
            runAsUser: 1000
          image: "gooddata/pdf-stapler-service:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: grpc
              containerPort: 6889
              protocol: TCP
            - name: actuator
              containerPort: 8287
              protocol: TCP
          livenessProbe:
            grpc:
              port: 6889
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            grpc:
              port: 6889
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=50M -Xms210m -Xmx210m -XX:MaxMetaspaceSize=70M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: GDC_EXPORTERS_STAPLER_STORAGE_MOUNTPATH
              value: "/tmp"
            - name: GDC_EXPORTERS_STAPLER_STORAGE_STORAGEFOLDER
              value: ""
            - name: GDC_LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 500m
              memory: 550Mi
            requests:
              cpu: 100m
              memory: 410Mi
---
# Source: gooddata-cn/templates/quiver/deployment-cache.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-quiver-cache
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/subcomponent: quiver-cache
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: quiver
      app.kubernetes.io/subcomponent: quiver-cache
  template:
    metadata:
      annotations:
        prometheus.io/path: /
        prometheus.io/scrape: "true"
        prometheus.io/port: "16101"
        checksum/config: ecb5293591e05c58e816527757b90b82e65c1106c1f3fb1ec4641337077e1793
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: quiver
        app.kubernetes.io/subcomponent: quiver-cache
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
        fsGroup: 1000
      
      
      enableServiceLinks: false
      containers:
        - name: quiver-cache
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          image: "gooddata/quiver:3.17.0"
          imagePullPolicy: Always
          command:
            - quiver-node
            - --config
            - /tmp/quiver-cache.conf.toml
            - --logging-config
            - /tmp/quiver.logging.ini
            - --logging-event-key
            - action
            - --init-cluster-config
            - start
          ports:
            - name: grpc
              containerPort: 16001
              protocol: TCP
            - name: metrics
              containerPort: 16101
              protocol: TCP
          volumeMounts:
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver-cache.conf.toml
              subPath: quiver-cache.conf.toml
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver.logging.ini
              subPath: quiver.logging.ini
            - name: my-gooddata-cn-quiver-data-disk
              mountPath: /quiver/cache
            - name: my-gooddata-cn-quiver-server-data-disk
              mountPath: /quiver/server
          livenessProbe:
            httpGet:
              path: /live
              port: 8877
            initialDelaySeconds: 10
            periodSeconds: 15
            timeoutSeconds: 4
          readinessProbe:
            httpGet:
              path: /ready
              port: 8877
            initialDelaySeconds: 5
            periodSeconds: 15
            timeoutSeconds: 2
          env:
            - name: QUIVER_ETCD_KEYSPACE_PREFIX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: QUIVER_ADVERTISE_FLIGHT_PORT
              value: "16001"
            - name: QUIVER_ADVERTISE_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: QUIVER_PEER_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: QUIVER_DISK_DIR
              value: "/quiver/cache/data"
            - name: QUIVER_SERVER_WORK_DIR
              value: "/quiver/server/data"
            - name: GLIBC_TUNABLES
              value: "glibc.malloc.trim_threshold=128:glibc.malloc.arena_max=2"
            - name: PYTHONMALLOC
              value: "malloc"
            - name: QUIVER_NEW_FLIGHT_VIEW
              value: "1"
            - name: QUIVER_ASYNC_RESTORE
              value: "1"
            - name: QUIVER_CACHE_COUNT_LIMIT
              value: "5000"
            - name: QUIVER_LIMIT_FLIGHT_COUNT
              value: "50000"
            - name: QUIVER_ETCD_SHUFFLE_NODES
              value: "1"
            - name: QUIVER_ETCD_INIT_SERIALIZABLE
              value: "1"
            - name: QUIVER_ETCD_INIT_PAGE_SIZE
              value: "5000"
            - name: QUIVER_SERVER_CRITICAL_RSS_GRACE
              value: "15"
            - name: QUIVER_SERVER_MALLOC_TRIM_INTERVAL
              value: "5"
          resources:
            limits:
              cpu: 300m
              memory: 768Mi
            requests:
              cpu: 100m
              memory: 256Mi
      volumes:
        - name: my-gooddata-cn-quiver-config
          configMap:
            name: my-gooddata-cn-quiver-config
        - name: my-gooddata-cn-quiver-data-disk
          emptyDir:
            sizeLimit: 1Gi
        - name: my-gooddata-cn-quiver-server-data-disk
          emptyDir:
            sizeLimit: 256Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/quiver/deployment-ml.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-quiver-ml
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/subcomponent: quiver-ml
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: quiver
      app.kubernetes.io/subcomponent: quiver-ml
  template:
    metadata:
      annotations:
        prometheus.io/path: /
        prometheus.io/scrape: "true"
        prometheus.io/port: "16101"
        checksum/config: ecb5293591e05c58e816527757b90b82e65c1106c1f3fb1ec4641337077e1793
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: quiver
        app.kubernetes.io/subcomponent: quiver-ml
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
        fsGroup: 1000
      
      
      enableServiceLinks: false
      containers:
        - name: quiver-ml
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          image: "gooddata/quiver:3.17.0"
          imagePullPolicy: Always
          command:
            - quiver-node
            - --config
            - /tmp/quiver-ml.conf.toml
            - --logging-config
            - /tmp/quiver.logging.ini
            - --logging-event-key
            - action
            - --init-cluster-config
            - start
          ports:
            - name: grpc
              containerPort: 16001
              protocol: TCP
            - name: metrics
              containerPort: 16101
              protocol: TCP
          volumeMounts:
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver-ml.conf.toml
              subPath: quiver-ml.conf.toml
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver.logging.ini
              subPath: quiver.logging.ini
            - name: my-gooddata-cn-quiver-server-data-disk
              mountPath: /quiver/server
          livenessProbe:
            httpGet:
              path: /live
              port: 8877
            initialDelaySeconds: 10
            periodSeconds: 15
            timeoutSeconds: 4
          readinessProbe:
            httpGet:
              path: /ready
              port: 8877
            initialDelaySeconds: 5
            periodSeconds: 15
            timeoutSeconds: 2
          env:
            - name: QUIVER_DATAFRAME_SERVICE_NAME
              value: "dataframe-ml-svc"
            - name: QUIVER_ETCD_KEYSPACE_PREFIX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: QUIVER_ADVERTISE_FLIGHT_PORT
              value: "16001"
            - name: QUIVER_ADVERTISE_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: QUIVER_PEER_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: GLIBC_TUNABLES
              value: "glibc.malloc.trim_threshold=128:glibc.malloc.arena_max=2"
            - name: PYTHONMALLOC
              value: "malloc"
            - name: QUIVER_NEW_FLIGHT_VIEW
              value: "1"
            - name: QUIVER_ETCD_SHUFFLE_NODES
              value: "1"
            - name: QUIVER_ETCD_INIT_SERIALIZABLE
              value: "1"
            - name: QUIVER_ETCD_INIT_PAGE_SIZE
              value: "5000"
            - name: QUIVER_SERVER_WORK_DIR
              value: "/quiver/server/data"
            - name: QUIVER_SERVER_CRITICAL_RSS_GRACE
              value: "15"
            - name: QUIVER_SERVER_MALLOC_TRIM_INTERVAL
              value: "5"
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
      volumes:
        - name: my-gooddata-cn-quiver-config
          configMap:
            name: my-gooddata-cn-quiver-config
        - name: my-gooddata-cn-quiver-server-data-disk
          emptyDir:
            sizeLimit: 256Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/quiver/deployment-xtab.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-quiver-xtab
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: quiver
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/subcomponent: quiver-xtab
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: quiver
      app.kubernetes.io/subcomponent: quiver-xtab
  template:
    metadata:
      annotations:
        prometheus.io/path: /
        prometheus.io/scrape: "true"
        prometheus.io/port: "16101"
        checksum/config: ecb5293591e05c58e816527757b90b82e65c1106c1f3fb1ec4641337077e1793
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: quiver
        app.kubernetes.io/subcomponent: quiver-xtab
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
        fsGroup: 1000
      
      
      enableServiceLinks: false
      containers:
        - name: quiver-xtab
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
          image: "gooddata/quiver:3.17.0"
          imagePullPolicy: Always
          command:
            - quiver-node
            - --config
            - /tmp/quiver-xtab.conf.toml
            - --logging-config
            - /tmp/quiver.logging.ini
            - --logging-event-key
            - action
            - --init-cluster-config
            - start
          ports:
            - name: grpc
              containerPort: 16001
              protocol: TCP
            - name: metrics
              containerPort: 16101
              protocol: TCP
          volumeMounts:
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver-xtab.conf.toml
              subPath: quiver-xtab.conf.toml
            - name: my-gooddata-cn-quiver-config
              mountPath: /tmp/quiver.logging.ini
              subPath: quiver.logging.ini
            - name: my-gooddata-cn-quiver-server-data-disk
              mountPath: /quiver/server
          livenessProbe:
            httpGet:
              path: /live
              port: 8877
            initialDelaySeconds: 10
            periodSeconds: 15
            timeoutSeconds: 4
          readinessProbe:
            httpGet:
              path: /ready
              port: 8877
            initialDelaySeconds: 5
            periodSeconds: 15
            timeoutSeconds: 2
          env:
            - name: QUIVER_DATAFRAME_SERVICE_NAME
              value: "dataframe-svc"
            - name: QUIVER_ETCD_KEYSPACE_PREFIX
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: QUIVER_ADVERTISE_FLIGHT_PORT
              value: "16001"
            - name: QUIVER_ADVERTISE_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: QUIVER_PEER_FLIGHT_HOST
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: GLIBC_TUNABLES
              value: "glibc.malloc.trim_threshold=128:glibc.malloc.arena_max=2"
            - name: PYTHONMALLOC
              value: "malloc"
            - name: QUIVER_NEW_FLIGHT_VIEW
              value: "1"
            - name: QUIVER_ETCD_SHUFFLE_NODES
              value: "1"
            - name: QUIVER_ETCD_INIT_SERIALIZABLE
              value: "1"
            - name: QUIVER_ETCD_INIT_PAGE_SIZE
              value: "5000"
            - name: QUIVER_SERVER_WORK_DIR
              value: "/quiver/server/data"
            - name: QUIVER_SERVER_CRITICAL_RSS_GRACE
              value: "15"
            - name: QUIVER_SERVER_MALLOC_TRIM_INTERVAL
              value: "5"
          resources:
            limits:
              cpu: 500m
              memory: 512Mi
            requests:
              cpu: 200m
              memory: 256Mi
      volumes:
        - name: my-gooddata-cn-quiver-config
          configMap:
            name: my-gooddata-cn-quiver-config
        - name: my-gooddata-cn-quiver-server-data-disk
          emptyDir:
            sizeLimit: 256Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/result-cache/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-result-cache
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: resultCache
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: resultCache
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: resultCache
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9041"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: result-cache
          securityContext:
            {}
          image: "gooddata/result-cache:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: grpc
              containerPort: 6567
              protocol: TCP
            - name: http
              containerPort: 9040
              protocol: TCP
            - name: actuator
              containerPort: 9041
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9041
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9041
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9041
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          volumeMounts:
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9041/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=60M -Xms1100m -Xmx1100m -XX:MaxMetaspaceSize=180M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: GRPC_CALCIQUE_HOST
              value: "my-gooddata-cn-calcique-headless"
            - name: GRPC_CALCIQUE_PORT
              value: "6577"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_DATASOURCE_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_DATASOURCE_PORT
              value: "6572"
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_PRODUCERS_RESULT_XTAB_TOPIC
              value: "default/my-gooddata-cn/result.xtab"
            - name: PULSAR_PRODUCERS_RESULT_XTAB_MESSAGE_TTL
              value: "300"
            - name: PULSAR_CONSUMERS_RESULT_TOPIC
              value: "default/my-gooddata-cn/result.xtab"
            - name: PULSAR_CONSUMERS_RESULT_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/result.xtab.DLQ"
            - name: PULSAR_PRODUCERS_SQLEXECUTOR_TOPIC
              value: "default/my-gooddata-cn/sql.select"
            - name: PULSAR_PRODUCERS_SQLEXECUTOR_MESSAGE_TTL
              value: "300"
            - name: QUIVER_DATAFRAME_XTAB_SVC_NAME
              value: "dataframe-svc-v2"
            - name: QUIVER_DATAFRAME_ML_SVC_NAME
              value: "dataframe-ml-svc-v2"
            - name: PULSAR_CONSUMERS_DATA_SOURCE_CHANGE_TOPIC
              value: "default/my-gooddata-cn/data-source.change"
            - name: PULSAR_CONSUMERS_DATA_SOURCE_CHANGE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/data-source.change.DLQ"
            - name: PULSAR_CONSUMERS_MODEL_UPDATE_TOPIC
              value: "default/my-gooddata-cn/metadata.model"
            - name: PULSAR_CONSUMERS_MODEL_UPDATE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/metadata.model.DLQ"
            - name: PULSAR_CONSUMERS_CACHE_SETTINGS_CHANGE_TOPIC
              value: "default/my-gooddata-cn/cache-settings.change"
            - name: PULSAR_CONSUMERS_CACHE_SETTINGS_CHANGE_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/cache-settings.change.DLQ"
            - name: PULSAR_PRODUCERS_CACHE_SETTINGS_BOOTSTRAP_TOPIC
              value: "default/my-gooddata-cn/cache-settings.bootstrap"
            - name: PULSAR_PRODUCERS_CACHE_SETTINGS_BOOTSTRAP_MESSAGE_TTL
              value: "300"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: LIMIT_MAX_RESULT_XTAB_DIMENSION
              value: "10000"
            - name: LIMIT_MAX_RESULT_XTAB_CELLS
              value: "1000000"
            - name: LIMIT_MAX_RESULT_COLUMNS
              value: "1000"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: QUIVER_LOCATION_ENDPOINTS
              value: "my-gooddata-cn-quiver-headless:16001"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: GDC_WORKSPACE_BASELINE_CACHE
              value: "0"
            - name: GDC_TOTAL_CACHE_LIMIT
              value: "34359738368"
          resources:
            limits:
              cpu: 750m
              memory: 1555Mi
            requests:
              cpu: 100m
              memory: 1330Mi
      volumes:
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/scan-model/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-scan-model
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: scanModel
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: scanModel
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: scanModel
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9061"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: scan-model
          securityContext:
            {}
          image: "gooddata/scan-model:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 9060
              protocol: TCP
            - name: actuator
              containerPort: 9061
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9061
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9061
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9061
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9061/actuator/shutdown && sleep 5"]
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=90M -Xms110m -Xmx110m -XX:MaxMetaspaceSize=130M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_DATASOURCE_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_DATASOURCE_PORT
              value: "6572"
            - name: GRPC_DATASOURCEMETADATA_HOST
              value: "my-gooddata-cn-sql-executor-headless"
            - name: GRPC_DATASOURCEMETADATA_PORT
              value: "6570"
            - name: GRPC_LICENSE_HOST
              value: "my-gooddata-cn-auth-service-headless"
            - name: GRPC_LICENSE_PORT
              value: "6573"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_COOKIES_SAMESITE
              value: "Lax"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_REMOTE_ADDRESS
              value: "https://localhost"
            - name: SPRING_SECURITY_OAUTH2_CLIENT_REPOSITORY_LOCAL_ADDRESS
              value: "http://my-gooddata-cn-dex:32000"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: GDC_FEATURES_VALUES_ENABLE_SNOWFLAKE_KEY_PAIR_AUTHENTICATION
              value: "true"
          resources:
            limits:
              cpu: 500m
              memory: 560Mi
            requests:
              cpu: 100m
              memory: 300Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/sql-executor/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-sql-executor
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: sqlExecutor
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: sqlExecutor
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: sqlExecutor
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "9101"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: sql-executor
          securityContext:
            {}
          image: "gooddata/sql-executor:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9101
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 9101
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 9101
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          lifecycle:
            preStop:
              exec:
                command: ["sh", "-c", "sleep 5 && /usr/bin/curl -Ssf -X POST localhost:9101/actuator/shutdown && sleep 5"]
          ports:
            - name: grpc
              containerPort: 6570
              protocol: TCP
            - name: actuator
              containerPort: 9101
              protocol: TCP
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=110M -Xms460m -Xmx460m -XX:MaxMetaspaceSize=256M -XX:ActiveProcessorCount=6"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SPRING_MAIN_BANNER_MODE
              value: "off"
            - name: SPRING_CONFIG_ADDITIONAL_LOCATION
              value: classpath:git.properties
            - name: SPRING_ZIPKIN_ENABLED
              value: "false"
            - name: ZIPKIN_HOST
              value: "jaeger-collector.monitoring"
            - name: ZIPKIN_PORT
              value: "9411"
            - name: GDC_OTEL_PUBLIC_ENABLED
              value: "false"
            - name: GDC_OTEL_PUBLIC_COLLECTOR_URL
              value: ""
            - name: SPRING_LIFECYCLE_TIMEOUT_PER_SHUTDOWN_PHASE
              value: "60s"
            - name: PULSAR_SERVICEURL
              value: "pulsar://pulsar-broker.pulsar:6650"
            - name: PULSAR_ADMINURL
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_CONSUMERS_SELECT_TOPIC
              value: "default/my-gooddata-cn/sql.select"
            - name:  PULSAR_CONSUMERS_SELECT_DEAD_LETTER_TOPIC
              value: "default/my-gooddata-cn/sql.select.DLQ"
            - name: PULSAR_CONSUMERS_DATA_SOURCE_CHANGE_TOPIC
              value: "default/my-gooddata-cn/data-source.change"
            - name: GRPC_RAWCACHE_HOST
              value: "my-gooddata-cn-result-cache-headless"
            - name: GRPC_RAWCACHE_PORT
              value: "6567"
            - name: GRPC_GDSTORAGE_HOST
              value: "my-gooddata-cn-result-cache-headless"
            - name: GRPC_GDSTORAGE_PORT
              value: "6567"
            - name: GRPC_LICENSE_HOST
              value: "my-gooddata-cn-auth-service-headless"
            - name: GRPC_LICENSE_PORT
              value: "6573"
            - name: GRPC_METADATA_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_METADATA_PORT
              value: "6572"
            - name: GRPC_DATASOURCE_HOST
              value: "my-gooddata-cn-metadata-api-headless"
            - name: GRPC_DATASOURCE_PORT
              value: "6572"
            - name: BANNED_JDBC_URLS
              value: "jdbc:postgresql://my-gooddata-cn-db-pgpool:5432/dex\njdbc:postgresql://my-gooddata-cn-db-pgpool:5432/md?reWriteBatchedInserts=true\njdbc:postgresql://my-gooddata-cn-db-pgpool:5432/automation"
            - name: LOG4J_ASYNC_LOGGER_RING_BUFFER_SIZE
              value: "262144"
            - name: GDC_TELEMETRY_ENABLED
              value: "true"
            - name: GDC_TELEMETRY_SITE_ID
              value: "2"
            - name: LIMIT_MAX_RESULT_RAW_BYTES
              value: "100000000"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: SPRING_PROFILES_ACTIVE
              value: default
            - name: QUIVER_LOCATION_ENDPOINTS
              value: "my-gooddata-cn-quiver-headless:16001"
            - name: SQLEXECUTOR_HIKARI_MONITORING_ENABLED
              value: "true"
            - name: SQLEXECUTOR_GDSTORAGE_MAXCONNECTIONSPERDATASOURCE
              value: "2"
          resources:
            limits:
              cpu: 500m
              ephemeral-storage: 500Mi
              memory: 1356Mi
            requests:
              cpu: 100m
              ephemeral-storage: 500Mi
              memory: 550Mi
      terminationGracePeriodSeconds: 80
---
# Source: gooddata-cn/templates/tabular-exporter/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-tabular-exporter
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: tabularExporter
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: tabularExporter
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: tabularExporter
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: tabular-exporter
          securityContext:
            {}
          image: "gooddata/tabular-exporter:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: grpc
              containerPort: 6789
              protocol: TCP
          livenessProbe:
            grpc:
              port: 6789
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            grpc:
              port: 6789
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: AFM_EXEC_API_URL
              value: http://my-gooddata-cn-afm-exec-api:9000
            - name: MD_API_URL
              value: http://my-gooddata-cn-metadata-api:9007
            - name: GRPC_VERBOSITY
              value: "INFO"
            - name: GRPC_SERVER_MAX_CONNECTION_AGE
              value: "300"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_TIME
              value: "25"
            - name: GRPC_SERVER_PERMIT_KEEP_ALIVE_WITHOUT_CALLS
              value: "true"
            - name: GDC_FEATURES_VALUES_ENABLE_OPTIMIZED_XLSX_EXPORT
              value: "true"
            - name: MALLOC_TRIM_INTERVAL
              value: "30"
            - name: GLIBC_TUNABLES
              value: "glibc.malloc.trim_threshold=128:glibc.malloc.arena_max=2"
          resources:
            limits:
              cpu: 200m
              memory: 250Mi
            requests:
              cpu: 50m
              memory: 150Mi
---
# Source: gooddata-cn/templates/tools/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-tools
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: tools
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: tools
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: tools
      
    spec:
      serviceAccountName: my-gooddata-cn
      
      
      containers:
        - name: tools
          securityContext:
            {}
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          command: ["/bin/sleep"]
          args: ["infinity"]
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: PULSAR_CLIENT_FROM_ENV
              value: "true"
            - name: webServiceUrl
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_TENANT
              value: "default"
            - name: PULSAR_NAMESPACE
              value: "my-gooddata-cn"
          resources:
            limits:
              cpu: 200m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
---
# Source: gooddata-cn/templates/visual-exporter-service/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-visual-exporter-service
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: visualExporterService
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: visualExporterService
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: visualExporterService
      
      annotations:
        prometheus.io/path: "/actuator/prometheus"
        prometheus.io/port: "8287"
        prometheus.io/scrape: "true"
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
        - name: squid-config
          configMap:
            name: my-gooddata-cn-squid-config
      containers:
        - name: restapi
          securityContext:
            runAsUser: 1111
          image: "gooddata/visual-exporter-service:3.17.0"
          imagePullPolicy: Always
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
            - name: actuator
              containerPort: 8287
              protocol: TCP
          lifecycle:
            preStop:
              exec:
                command: ["/pre_stop_hook.sh"]
          livenessProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 8287
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 5
          readinessProbe:
            httpGet:
              path: /actuator/health/readiness
              port: 8287
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          startupProbe:
            httpGet:
              path: /actuator/health/liveness
              port: 8287
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
            failureThreshold: 12
          env:
            - name: JDK_JAVA_OPTIONS
              value: "-XX:+ExitOnOutOfMemoryError -XX:+UseG1GC -Xss384k -XX:+UseStringDeduplication -XX:MinHeapFreeRatio=15 -XX:MaxHeapFreeRatio=25 -XX:AdaptiveSizePolicyWeight=50 -XX:InitiatingHeapOccupancyPercent=25 -XX:GCTimeRatio=25 -XX:CompressedClassSpaceSize=32M --add-opens=java.base/sun.net=ALL-UNNAMED --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED -XX:ReservedCodeCacheSize=50M -Xms100m -Xmx100m -XX:MaxMetaspaceSize=70M"
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
            - name: SERVER_TOMCAT_THREADS_MAX
              value: "4"
            - name: SERVER_TOMCAT_ACCEPTCOUNT
              value: "200"
            - name: GDC_LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 500m
              memory: 350Mi
            requests:
              cpu: 100m
              memory: 300Mi
        - name: chromium
          securityContext:
            runAsUser: 1111
          image: "gooddata/visual-exporter-chromium:3.17.0"
          imagePullPolicy: Always
          lifecycle:
            preStop:
              exec:
                command: ["/pre_stop_hook.sh"]
          args:
            - --ignore-gpu-blacklist
            - --disable-background-networking
            - --disable-background-timer-throttling
            - --disable-client-side-phishing-detection
            - --disable-default-apps
            - --disable-extensions
            - --disable-hang-monitor
            - --disable-popup-blocking
            - --disable-prompt-on-repost
            - --disable-sync
            - --disable-translate
            - --enable-blink-features=PrintUsingScreenMedia
            - --no-sandbox
            - --no-first-run
            - --metrics-recording-only
            - --safebrowsing-disable-auto-update
            - --hide-scrollbars
            - --mute-audio
            - --remote-debugging-address=0.0.0.0
            - --remote-debugging-port=9222
            - --proxy-server=http://localhost:3128
            - --disable-http2
          ports:
            - name: remote-port
              protocol: TCP
              containerPort: 9222
          resources:
            limits:
              cpu: 2000m
              memory: 2048Mi
            requests:
              cpu: 200m
              memory: 550Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
          livenessProbe:
            httpGet:
              path: /
              port: 9222
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
          readinessProbe:
            httpGet:
              path: /
              port: 9222
              scheme: HTTP
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
        - name: proxy
          securityContext:
            runAsUser: 1111
          image: "gooddata/visual-exporter-proxy:3.17.0"
          imagePullPolicy: Always
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          args:
            - --foreground
            - -d
            - "1"
            - -f
            - /squid/squid.conf
          lifecycle:
            preStop:
              exec:
                command: ["/pre_stop_hook.sh"]
          livenessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - > #running squid should return BAD REQUEST response
                  [ $(curl -s -o /dev/null -I -w "%{http_code}" localhost:3128) -eq 400 ]
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - > #running squid should return BAD REQUEST response
                  [ $(curl -s -o /dev/null -I -w "%{http_code}" localhost:3128) -eq 400 ]
            initialDelaySeconds: 20
            periodSeconds: 30
            timeoutSeconds: 5
            failureThreshold: 2
          volumeMounts:
            - name: squid-config
              mountPath: /squid/
              readOnly: true
          resources:
            limits:
              cpu: 100m
              memory: 215Mi
            requests:
              cpu: 50m
              memory: 215Mi
---
# Source: gooddata-cn/templates/web-components/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: my-gooddata-cn-web-components
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: webComponents
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 2
  selector:
    matchLabels:
      app.kubernetes.io/name: gooddata-cn
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: webComponents
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: webComponents
      
    spec:
      serviceAccountName: my-gooddata-cn
      securityContext:
        runAsNonRoot: true
      
      
      containers:
        - name: web-components
          securityContext:
            {}
          image: "gooddata/web-components:3.17.0"
          imagePullPolicy: Always
          livenessProbe:
            failureThreshold: 5
            httpGet:
              path: /components/
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 5
            httpGet:
              path: /components/
              port: 8080
              scheme: HTTP
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 10
          ports:
            - name: http
              containerPort: 8080
              protocol: TCP
          env:
            - name: NODE_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: LOGGING_APPENDER
              value: "json"
          resources:
            limits:
              cpu: 100m
              memory: 35Mi
            requests:
              cpu: 10m
              memory: 15Mi
---
# Source: gooddata-cn/charts/etcd/templates/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-gooddata-cn-etcd
  namespace: "default"
  labels:
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: etcd
    app.kubernetes.io/version: 3.5.12
    helm.sh/chart: etcd-9.15.2
    app.kubernetes.io/component: etcd
spec:
  replicas: 3
  selector:
    matchLabels:
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/name: etcd
      app.kubernetes.io/component: etcd
  serviceName: my-gooddata-cn-etcd-headless
  podManagementPolicy: Parallel
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      labels:
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: etcd
        app.kubernetes.io/version: 3.5.12
        helm.sh/chart: etcd-9.15.2
        app.kubernetes.io/component: etcd
      annotations:
        prometheus.io/port: '2379'
        prometheus.io/scrape: "true"
        checksum/token-secret: 28c82de52e7f30e52e8fd373708de7241989d465d33ab96fdaae86f14656863b
    spec:
      
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-gooddata-cn
                    app.kubernetes.io/name: etcd
                    app.kubernetes.io/component: etcd
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      serviceAccountName: "my-gooddata-cn-etcd"
      containers:
        - name: etcd
          image: docker.io/bitnami/etcd:3.5.12-debian-12-r10
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsGroup: 0
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.podIP
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: MY_STS_NAME
              value: "my-gooddata-cn-etcd"
            - name: ETCDCTL_API
              value: "3"
            - name: ETCD_ON_K8S
              value: "yes"
            - name: ETCD_START_FROM_SNAPSHOT
              value: "no"
            - name: ETCD_DISASTER_RECOVERY
              value: "no"
            - name: ETCD_NAME
              value: "$(MY_POD_NAME)"
            - name: ETCD_DATA_DIR
              value: "/bitnami/etcd/data"
            - name: ETCD_LOG_LEVEL
              value: "info"
            - name: ALLOW_NONE_AUTHENTICATION
              value: "yes"
            - name: ETCD_AUTH_TOKEN
              value: "jwt,priv-key=/opt/bitnami/etcd/certs/token/jwt-token.pem,sign-method=RS256,ttl=10m"
            - name: ETCD_ADVERTISE_CLIENT_URLS
              value: "http://$(MY_POD_NAME).my-gooddata-cn-etcd-headless.default.svc.cluster.local:2379,http://my-gooddata-cn-etcd.default.svc.cluster.local:2379"
            - name: ETCD_LISTEN_CLIENT_URLS
              value: "http://0.0.0.0:2379"
            - name: ETCD_INITIAL_ADVERTISE_PEER_URLS
              value: "http://$(MY_POD_NAME).my-gooddata-cn-etcd-headless.default.svc.cluster.local:2380"
            - name: ETCD_LISTEN_PEER_URLS
              value: "http://0.0.0.0:2380"
            - name: ETCD_AUTO_COMPACTION_MODE
              value: "periodic"
            - name: ETCD_AUTO_COMPACTION_RETENTION
              value: "5m"
            - name: ETCD_INITIAL_CLUSTER_TOKEN
              value: "etcd-cluster-k8s"
            - name: ETCD_INITIAL_CLUSTER_STATE
              value: "new"
            - name: ETCD_INITIAL_CLUSTER
              value: "my-gooddata-cn-etcd-0=http://my-gooddata-cn-etcd-0.my-gooddata-cn-etcd-headless.default.svc.cluster.local:2380,my-gooddata-cn-etcd-1=http://my-gooddata-cn-etcd-1.my-gooddata-cn-etcd-headless.default.svc.cluster.local:2380,my-gooddata-cn-etcd-2=http://my-gooddata-cn-etcd-2.my-gooddata-cn-etcd-headless.default.svc.cluster.local:2380"
            - name: ETCD_CLUSTER_DOMAIN
              value: "my-gooddata-cn-etcd-headless.default.svc.cluster.local"
            - name: ETCD_SNAPSHOT_COUNT
              value: "5000"
          envFrom:
          ports:
            - name: client
              containerPort: 2379
              protocol: TCP
            - name: peer
              containerPort: 2380
              protocol: TCP
          livenessProbe:
            exec:
              command:
                - /opt/bitnami/scripts/etcd/healthcheck.sh
            initialDelaySeconds: 60
            periodSeconds: 30
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          readinessProbe:
            exec:
              command:
                - /opt/bitnami/scripts/etcd/healthcheck.sh
            initialDelaySeconds: 60
            periodSeconds: 10
            timeoutSeconds: 5
            successThreshold: 1
            failureThreshold: 5
          lifecycle:
            preStop:
              exec:
                command:
                  - /opt/bitnami/scripts/etcd/prestop.sh
          resources:
            limits:
              cpu: 300m
              memory: 512Mi
            requests:
              cpu: 100m
              memory: 256Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /opt/bitnami/etcd/conf/
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: data
              mountPath: /bitnami/etcd
            - name: etcd-jwt-token
              mountPath: /opt/bitnami/etcd/certs/token/
              readOnly: true
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: etcd-jwt-token
          secret:
            secretName: my-gooddata-cn-etcd-jwt-token
            defaultMode: 256
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: gooddata-cn/charts/postgresql-ha/templates/postgresql/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-gooddata-cn-db-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/name: db
    helm.sh/chart: postgresql-ha-9.4.9
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/version: "14.5.0"
    app.kubernetes.io/component: postgresql
spec:
  replicas: 3
  podManagementPolicy: Parallel
  serviceName: my-gooddata-cn-db-postgresql-headless
  updateStrategy:
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/name: db
      app.kubernetes.io/instance: my-gooddata-cn
      app.kubernetes.io/component: postgresql
  template:
    metadata:
      labels:
        app.kubernetes.io/name: db
        helm.sh/chart: postgresql-ha-9.4.9
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/version: "14.5.0"
        app.kubernetes.io/component: postgresql
      annotations:
        prometheus.io/port: "9187"
        prometheus.io/scrape: "true"
    spec:
      
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: my-gooddata-cn
                    app.kubernetes.io/name: db
                    app.kubernetes.io/component: postgresql
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
      hostNetwork: false
      hostIPC: false
      initContainers:
        - name: init-chmod-data
          image: docker.io/bitnami/bitnami-shell:11-debian-11-r43
          imagePullPolicy: "IfNotPresent"
          command:
            - sh
            - -c
            - |
              mkdir -p /bitnami/postgresql/conf /bitnami/postgresql/data /bitnami/postgresql/lock
              chmod 700 /bitnami/postgresql/conf /bitnami/postgresql/data /bitnami/postgresql/lock
              chown 1001:1001 /bitnami/postgresql
              find /bitnami/postgresql -mindepth 1 -maxdepth 1 -not -name ".snapshot" -not -name "lost+found" | \
                xargs -r chown -R 1001:1001
          securityContext:
            runAsUser: 0
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: data
              mountPath: /bitnami/postgresql
      containers:
        - name: postgresql
          image: docker.io/bitnami/postgresql-repmgr:14.5.0-debian-11-r28
          imagePullPolicy: "IfNotPresent"
          securityContext:
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
          lifecycle:
            preStop:
              exec:
                command:
                  - /pre-stop.sh
          # Auxiliary vars to populate environment variables
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            # PostgreSQL configuration
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            - name: POSTGRES_USER
              value: "postgres"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-postgresql
                  key: postgresql-password
            - name: POSTGRES_DB
              value: "postgres"
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "true"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit, repmgr"
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            # Repmgr configuration
            - name: REPMGR_PORT_NUMBER
              value: "5432"
            - name: REPMGR_PRIMARY_PORT
              value: "5432"
            - name: MY_POD_NAME
              valueFrom:
                fieldRef:
                  fieldPath: metadata.name
            - name: REPMGR_UPGRADE_EXTENSION
              value: "no"
            - name: REPMGR_PGHBA_TRUST_ALL
              value: "no"
            - name: REPMGR_MOUNTED_CONF_DIR
              value: "/bitnami/repmgr/conf"
            - name: REPMGR_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: REPMGR_PARTNER_NODES
              value: my-gooddata-cn-db-postgresql-0.my-gooddata-cn-db-postgresql-headless.$(REPMGR_NAMESPACE).svc.cluster.local,my-gooddata-cn-db-postgresql-1.my-gooddata-cn-db-postgresql-headless.$(REPMGR_NAMESPACE).svc.cluster.local,my-gooddata-cn-db-postgresql-2.my-gooddata-cn-db-postgresql-headless.$(REPMGR_NAMESPACE).svc.cluster.local,
            - name: REPMGR_PRIMARY_HOST
              value: "my-gooddata-cn-db-postgresql-0.my-gooddata-cn-db-postgresql-headless.$(REPMGR_NAMESPACE).svc.cluster.local"
            - name: REPMGR_NODE_NAME
              value: "$(MY_POD_NAME)"
            - name: REPMGR_NODE_NETWORK_NAME
              value: "$(MY_POD_NAME).my-gooddata-cn-db-postgresql-headless.$(REPMGR_NAMESPACE).svc.cluster.local"
            - name: REPMGR_LOG_LEVEL
              value: "NOTICE"
            - name: REPMGR_CONNECT_TIMEOUT
              value: "5"
            - name: REPMGR_RECONNECT_ATTEMPTS
              value: "2"
            - name: REPMGR_RECONNECT_INTERVAL
              value: "3"
            - name: REPMGR_USERNAME
              value: "repmgr"
            - name: REPMGR_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-postgresql
                  key: repmgr-password
            - name: REPMGR_DATABASE
              value: "repmgr"
            - name: REPMGR_FENCE_OLD_PRIMARY
              value: "no"
            - name: REPMGR_CHILD_NODES_CHECK_INTERVAL
              value: "5"
            - name: REPMGR_CHILD_NODES_CONNECTED_MIN_COUNT
              value: "1"
            - name: REPMGR_CHILD_NODES_DISCONNECT_TIMEOUT
              value: "30"
          envFrom:
          ports:
            - name: postgresql
              containerPort: 5432
              protocol: TCP
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - bash
                - -ec
                - 'PGPASSWORD=$POSTGRES_PASSWORD psql -w -U "postgres" -d "postgres" -h 127.0.0.1 -p 5432 -c "SELECT 1"'
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - bash
                - -ec
                - 'PGPASSWORD=$POSTGRES_PASSWORD psql -w -U "postgres" -d "postgres" -h 127.0.0.1 -p 5432 -c "SELECT 1"'
          resources:
            limits: {}
            requests: {}
          volumeMounts:
            - name: postgresql-extended-config
              mountPath: /bitnami/postgresql/conf/conf.d/
            - name: data
              mountPath: /bitnami/postgresql
            - name: hooks-scripts
              mountPath: /pre-stop.sh
              subPath: pre-stop.sh
            - mountPath: /dev/shm
              name: fake-shm
        - name: metrics
          image: docker.io/bitnami/postgres-exporter:0.11.1-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            runAsUser: 1001
          env:
            - name: PG_EXPORTER_WEB_LISTEN_ADDRESS
              value: :9187
            - name: DATA_SOURCE_URI
              value: "127.0.0.1:5432/postgres?sslmode=disable"
            - name: DATA_SOURCE_PASS
              valueFrom:
                secretKeyRef:
                  name: my-gooddata-cn-db-postgresql
                  key: postgresql-password
            - name: DATA_SOURCE_USER
              value: "postgres"
          envFrom:
          ports:
            - name: metrics
              containerPort: 9187
              protocol: TCP
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: metrics
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            httpGet:
              path: /
              port: metrics
          resources:
            limits: {}
            requests: {}
          volumeMounts:
      volumes:
        - emptyDir:
            medium: Memory
            sizeLimit: 128Mi
          name: fake-shm
        - name: hooks-scripts
          configMap:
            name: my-gooddata-cn-db-postgresql-hooks-scripts
            defaultMode: 0755
        - name: postgresql-extended-config
          configMap:
            name: my-gooddata-cn-db-postgresql-extended-configuration
  volumeClaimTemplates:
    - metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: gooddata-cn/charts/redis-ha/templates/redis-ha-statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: my-gooddata-cn-redis-ha-server
  namespace: "default"
  labels:
    my-gooddata-cn-redis-ha: replica
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
  annotations:
    {}
spec:
  selector:
    matchLabels:
      release: my-gooddata-cn
      app: redis-ha
  serviceName: my-gooddata-cn-redis-ha
  replicas: 3
  podManagementPolicy: OrderedReady
  updateStrategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/init-config: 80fbd76b83f24a0d17b9d01c54a9a6c371fe5d775473345c0f5cd5d58cb3fdca
        prometheus.io/port: "9121"
        prometheus.io/scrape: "true"
        prometheus.io/path: /metrics
      labels:
        release: my-gooddata-cn
        app: redis-ha
        my-gooddata-cn-redis-ha: replica
    spec:
      terminationGracePeriodSeconds: 60
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchLabels:
                  app: redis-ha
                  release: my-gooddata-cn
                  my-gooddata-cn-redis-ha: replica
              topologyKey: kubernetes.io/hostname
      securityContext: 
        fsGroup: 1000
        runAsNonRoot: true
        runAsUser: 1000
      serviceAccountName: my-gooddata-cn-redis-ha
      automountServiceAccountToken: false
      initContainers:
      - name: config-init
        image: redis:7.2.4-alpine
        imagePullPolicy: IfNotPresent
        resources:
          {}
        command:
        - sh
        args:
        - /readonly-config/init.sh
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault        
        env:
        - name: SENTINEL_ID_0
          value: a4a99486d46d2fc37370610b098166a156422635
        - name: SENTINEL_ID_1
          value: fcbab8856a9667049b1f2325868133e2ad385b72
        - name: SENTINEL_ID_2
          value: c6494246dd0a3e3f4b33e8ccbe752fda6e1f9548
        volumeMounts:
        - name: config
          mountPath: /readonly-config
          readOnly: true
        - name: data
          mountPath: /data


      containers:
      - name: redis
        image: redis:7.2.4-alpine
        imagePullPolicy: IfNotPresent
        command:
          - redis-server
        args:
          - /data/conf/redis.conf
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 15
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
              - sh
              - -c
              - /health/redis_liveness.sh
        readinessProbe:
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 15
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
              - sh
              - -c
              - /health/redis_readiness.sh
        resources:
          {}
        ports:
        - name: redis
          containerPort: 6379
        volumeMounts:
        - name: config
          mountPath: /readonly-config
          readOnly: true
        - mountPath: /data
          name: data
        - mountPath: /health
          name: health
        lifecycle:
          preStop:
            exec:
              command:
              - /bin/sh
              - /readonly-config/trigger-failover-if-master.sh
      - name: sentinel
        image: redis:7.2.4-alpine
        imagePullPolicy: IfNotPresent
        command:
          - redis-sentinel
        args:
          - /data/conf/sentinel.conf
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault
        livenessProbe:
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 15
          successThreshold: 1
          failureThreshold: 5
          exec:
            command:
              - sh
              - -c
              - /health/sentinel_liveness.sh
        readinessProbe:
          initialDelaySeconds: 30
          periodSeconds: 15
          timeoutSeconds: 15
          successThreshold: 3
          failureThreshold: 5
          exec:
            command:
              - sh
              - -c
              - /health/sentinel_liveness.sh
        resources:
          {}
        ports:
          - name: sentinel
            containerPort: 26379
        volumeMounts:
        - mountPath: /data
          name: data
        - mountPath: /health
          name: health
        lifecycle:
          {}

      - name: split-brain-fix
        image: redis:7.2.4-alpine
        imagePullPolicy: IfNotPresent
        command:
          - sh
        args:
          - /readonly-config/fix-split-brain.sh
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault        
        env:
        - name: SENTINEL_ID_0
          value: a4a99486d46d2fc37370610b098166a156422635
        - name: SENTINEL_ID_1
          value: fcbab8856a9667049b1f2325868133e2ad385b72
        - name: SENTINEL_ID_2
          value: c6494246dd0a3e3f4b33e8ccbe752fda6e1f9548
        resources:
          {}
        volumeMounts:
        - name: config
          mountPath: /readonly-config
          readOnly: true
        - mountPath: /data
          name: data
      - name: redis-exporter
        image: "oliver006/redis_exporter:v1.57.0"
        imagePullPolicy: IfNotPresent
        args:
        securityContext: 
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
          runAsNonRoot: true
          runAsUser: 1000
          seccompProfile:
            type: RuntimeDefault        
        env:
          - name: REDIS_ADDR
            value: redis://localhost:6379
        livenessProbe:
          httpGet:
            path: /metrics
            port: 9121
          initialDelaySeconds: 15
          periodSeconds: 15
          timeoutSeconds: 3
        readinessProbe:
          httpGet:
            path: /metrics
            port: 9121
          initialDelaySeconds: 15
          periodSeconds: 15
          successThreshold: 2
          timeoutSeconds: 3
        resources:
          {}
        ports:
          - name: exporter-port
            containerPort: 9121
        volumeMounts:
      volumes:
      - name: config
        configMap:
          name: my-gooddata-cn-redis-ha-configmap
      - name: health
        configMap:
          name: my-gooddata-cn-redis-ha-health-configmap
          defaultMode: 0755
  volumeClaimTemplates:
  - metadata:
      name: data
      annotations:
      labels:
        {}

    spec:
      accessModes:
        - "ReadWriteOnce"
      resources:
        requests:
          storage: "10Gi"
---
# Source: gooddata-cn/templates/dex/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: my-gooddata-cn-dex
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: dex
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  ingressClassName: nginx
  rules:
    - http:
        paths:          
          - path: /dex
            pathType: ImplementationSpecific
            backend:
              service:
                name: my-gooddata-cn-dex
                port:
                  number: 32000
      host: localhost
---
# Source: gooddata-cn/templates/organization-controller/peering.yaml
apiVersion: kopf.dev/v1
kind: KopfPeering
metadata:
  name: my-gooddata-cn
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: organizationController
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
---
# Source: gooddata-cn/templates/tests/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: my-gooddata-cn-chart-tests
  annotations:
    "helm.sh/hook": test
    # create this configmap as a prerequisite for the actual tests
    "helm.sh/hook-weight": "-1"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
data:
  # test publicly accessible microservices ( including web applications, api-docs and dex)
  public_rest_api_test.sh: |-
    #! /bin/bash

    source $TEST_DIR/utils.sh
    microservices=(afm-exec-api auth-service metadata-api scan-model analytical-designer apidocs dashboards home-ui ldm-modeler measure-editor dex)
    exit_code=0

    for i in "${microservices[@]}"
    do
      # we make use of kubelet defined environment variables to obtain microservice address and port
      # for service with a name tiger-metadata-api, there are env. variables TIGER_METADATA_API_SERVICE_HOST and TIGER_METADATA_API_SERVICE_PORT_HTTP
      service_address=$( get_service_address "$i" 'HTTP' )

      status_code=$( curl --connect-timeout 10 -s -o /dev/null -w "%{http_code}" http://${service_address} )

      echo "Microservice: $i"
      echo "Service address: $service_address"
      echo "HTTP status: $status_code"

      # the returned status code must be a number
      # a status code 000 is returned when connection is refused
      # we expect http status code less than 500
      if [[ $status_code =~ ^-?[0-9]+$ ]] && [ $status_code -gt 0 ] && [ $status_code -lt 500 ]
      then
        echo "Test result: PASSED"
      else
        echo "Test result: FAILED"
        exit_code=1
      fi
      echo
    done

    exit $exit_code

  # test Analytics core services
  core_services_test.sh: |-
    #! /bin/bash

    CALCIQUE_HOST="my-gooddata-cn-calcique-headless"
    CALCIQUE_PORT="6577"
    RESULT_CACHE_HOST="my-gooddata-cn-result-cache-headless"
    RESULT_CACHE_PORT="6567"
    SQL_EXECUTOR_HOST="my-gooddata-cn-sql-executor-headless"
    SQL_EXECUTOR_PORT="6570"

    microservices=("${CALCIQUE_HOST}:${CALCIQUE_PORT}" "${RESULT_CACHE_HOST}:${RESULT_CACHE_PORT}" "${SQL_EXECUTOR_HOST}:${SQL_EXECUTOR_PORT}")
    exit_code=0

    for i in "${microservices[@]}"
    do

      grpcurl -plaintext $i list > /dev/null
      status=$?

      echo "Microservice: $i"
      echo "Service address: $service_address"
      echo "GRPC call exit status: $status"

      # We check if the above 'grpcurl' call was sucessful
      if [ $status -eq 0 ]
      then
        echo "Test result: PASSED"
      else
        echo "Test result: FAILED"
        exit_code=1
      fi
      echo
    done

    exit $exit_code

  # test connectivity to postgres
  postgres_test.sh: |-
    #! /bin/bash

    test_postgres_connection() {
      echo "Microservice: $1"
      echo "PG user: $2"
      echo "Database: $4"

      PGPASSWORD=$3 psql -U $2 -d $4 -c 'select 1' -o /dev/null 2>/dev/null
      local status=$?
      echo "psql exit status: $status"

      if [ $status -eq 0 ]
      then
        echo "Test result: PASSED"
      else
        echo "Test result: FAILED"
        exit_code=1
      fi
      echo
    }

    exit_code=0
    test_postgres_connection "metadata-api" "$METADATA_USERNAME" "$METADATA_PASSWORD" "$METADATA_DATABASE"
    if [ -n "$DEX_USERNAME" ]
    then
      test_postgres_connection "dex" "$DEX_USERNAME" "$DEX_PASSWORD" "$DEX_DATABASE"
    fi

    exit $exit_code

  # publish test message to pulsar topic
  pulsar_test.sh: |-
    #! /bin/bash

    exit_code=0
    pulsarctl broker healthcheck
    exit_code=$((exit_code + $?))
    pulsarctl topics list "$PULSAR_TENANT/$PULSAR_NAMESPACE" > /dev/null
    exit_code=$((exit_code + $?))


    if [ $exit_code -eq 0 ]
    then
      echo "Test result: PASSED"
    else
      echo "Test result: FAILED"
      exit_code=1
    fi

    exit $exit_code

  # test connectivity to redis
  redis_test.sh: |-
    #! /bin/bash

    options=''
    server_address=''
    exit_code=0

    # We try to extract redis host and port based on env vars generated by template 'gooddata-cn.redisEnv' defined in ../_redis.tpl
    if [ -n "$SPRING_REDIS_SENTINEL_NODES" ]
    then
      server_address="${SPRING_REDIS_SENTINEL_NODES%%,*}"
      IFS=':' read -ra ADDR <<< "$server_address"
      options="-h ${ADDR[0]} -p ${ADDR[1]}"
    elif [ -n "$SPRING_REDIS_CLUSTER_NODES" ]
    then
      IFS=',' read -ra CLUSTER_NODES <<< "$SPRING_REDIS_CLUSTER_NODES"
      server_address="${CLUSTER_NODES[0]}"
      IFS=':' read -ra ADDR <<< "${CLUSTER_NODES[0]}"
      options="-h ${ADDR[0]} -p ${ADDR[1]}"
    elif [ -n "$SPRING_REDIS_HOST" ] && [ -n "$SPRING_REDIS_PORT" ]
    then
      server_address="$SPRING_REDIS_HOST:$SPRING_REDIS_PORT"
      options="-h $SPRING_REDIS_HOST -p $SPRING_REDIS_PORT"
    else
      echo "Couldn't extract host and port of redis service. Exiting."
      exit 1
    fi

    if [ -n "$SPRING_REDIS_PASSWORD" ]
    then
      options="$options -a $SPRING_REDIS_PASSWORD"
    fi

    if [ -n "$SPRING_REDIS_SSL" ] && [ "$SPRING_REDIS_SSL" != "false" ]
    then
      options="$options --tls --insecure"
    fi

    echo "Operation: ping"
    echo "Redis server address: $server_address"

    # -e for returning exit error code in case of a failure
    # --no-auth-warning for supressing warning about password passed as a parameter
    timeout -v 20 redis-cli -e --no-auth-warning $options ping > /dev/null

    if [ $? -eq 0 ]
    then
      echo "Test result: PASSED"
    else
      echo "Test result: FAILED"
      exit_code=1
    fi

    exit $exit_code

  utils.sh: |-
    #! /bin/bash

    # we make use of kubelet defined environment variables to obtain microservice address and port
    # kubelet defines environment variables holding services hosts and ports
    # e.g. for service tiger-metadata-api, there are env. variables TIGER_METADATA_API_SERVICE_HOST and TIGER_METADATA_API_SERVICE_PORT_(HTTP/GRPC)
    get_service_address() {
      local service_name=$1
      local port_var_suffix=$2

      local service_prefix='my-gooddata-cn'
      local env_name_prefix=$( echo "${service_prefix}_${service_name}" | tr '-' '_' )
      env_name_prefix=${env_name_prefix^^}
      local host_env_name=${env_name_prefix}_SERVICE_HOST
      local port_env_name=${env_name_prefix}_SERVICE_PORT_${port_var_suffix}

      echo "${!host_env_name}:${!port_env_name}"
    }
---
# Source: gooddata-cn/charts/redis-ha/templates/tests/test-redis-ha-configmap.yaml
apiVersion: v1
kind: Pod
metadata:
  name: my-gooddata-cn-redis-ha-configmap-test
  namespace: "default"
  labels:
    app: redis-ha
    heritage: "Helm"
    release: "my-gooddata-cn"
    chart: redis-ha-4.27.2
  annotations:
    "helm.sh/hook": test-success
spec:
  nodeSelector: 
    {}
  tolerations: 
    null
  containers:
  - name: check-init
    image: koalaman/shellcheck:v0.5.0
    args:
    - --shell=sh
    - /readonly-config/init.sh
    volumeMounts:
    - name: config
      mountPath: /readonly-config
      readOnly: true
    resources: 
      {}
    securityContext: 
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
      runAsNonRoot: true
      runAsUser: 1000
      seccompProfile:
        type: RuntimeDefault
  restartPolicy: Never
  volumes:
  - name: config
    configMap:
      name: my-gooddata-cn-redis-ha-configmap
---
# Source: gooddata-cn/templates/broker-namespace.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-create-namespace
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pulsarJob
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": pre-install
    "helm.sh/hook-weight": "-1"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
      initContainers:
      - name: wait-broker-ready
        image: "gooddata/tools:3.17.0"
        imagePullPolicy: Always
        command: ["sh", "-c"]
        args:
          - >-
            until pulsarctl broker healthcheck ; do
              sleep 3;
            done;
        env:
        - name: PULSAR_CLIENT_FROM_ENV
          value: "true"
        - name: webServiceUrl
          value: "http://pulsar-broker.pulsar:8080"
        - name: PULSAR_TENANT
          value: "default"
        - name: PULSAR_NAMESPACE
          value: "my-gooddata-cn"
      containers:
      - name: "create-namespace"
        image: "gooddata/tools:3.17.0"
        imagePullPolicy: Always
        env:
        - name: PULSAR_CLIENT_FROM_ENV
          value: "true"
        - name: webServiceUrl
          value: "http://pulsar-broker.pulsar:8080"
        - name: PULSAR_TENANT
          value: "default"
        - name: PULSAR_NAMESPACE
          value: "my-gooddata-cn"
        command: ["sh", "-e", "-c"]
        args:
          - >
            pulsarctl tenants get "${PULSAR_TENANT}" || \
              pulsarctl tenants create --allowed-clusters "pulsar" "${PULSAR_TENANT}" ;
            pulsarctl namespaces get-clusters "${PULSAR_TENANT}/${PULSAR_NAMESPACE}" || \
              pulsarctl namespaces create --clusters "pulsar" "${PULSAR_TENANT}/${PULSAR_NAMESPACE}" ;
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
      restartPolicy: Never
---
# Source: gooddata-cn/templates/pulsar-cleanup.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-pulsar-cleanup
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: pulsarCleanup
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
  annotations:
    "helm.sh/hook": post-delete
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": hook-succeeded,before-hook-creation
spec:
  template:
    spec:
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
      initContainers:
      - name: wait-broker-ready
        image: "gooddata/tools:3.17.0"
        imagePullPolicy: Always
        command: ["bash", "-c"]
        args:
          - >-
            until pulsarctl broker healthcheck ; do
              sleep 3;
            done;
        env:
        - name: PULSAR_CLIENT_FROM_ENV
          value: "true"
        - name: webServiceUrl
          value: "http://pulsar-broker.pulsar:8080"
        - name: PULSAR_TENANT
          value: "default"
        - name: PULSAR_NAMESPACE
          value: "my-gooddata-cn"
      containers:
      - name: "pulsar-cleanup"
        image: "gooddata/tools:3.17.0"
        imagePullPolicy: Always
        env:
        - name: PULSAR_CLIENT_FROM_ENV
          value: "true"
        - name: webServiceUrl
          value: "http://pulsar-broker.pulsar:8080"
        - name: PULSAR_TENANT
          value: "default"
        - name: PULSAR_NAMESPACE
          value: "my-gooddata-cn"
        command: ["bash", "-e", "-c"]
        args:
          - >
            echo "Waiting 120s for producers to shut down.";
            sleep 120;
            pulsarctl topics list "$PULSAR_TENANT/$PULSAR_NAMESPACE" -o json | \
                jq '.nonPartitionedTopics[] | select(test("/__change_events$")|not) | "pulsarctl topics delete --force --non-partitioned \(.)"' -r | \
                bash -e;
            pulsarctl namespace delete "$PULSAR_TENANT/$PULSAR_NAMESPACE";
            pulsarctl tenant delete "$PULSAR_TENANT";
        resources:
          limits:
            cpu: 100m
            memory: 100Mi
          requests:
            cpu: 100m
            memory: 100Mi
      restartPolicy: Never
---
# Source: gooddata-cn/templates/tests/core-services-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-core-services-test
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: chartTests
    spec:
      serviceAccountName: my-gooddata-cn
      containers:
        - name: my-gooddata-cn-core-services-test
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          env:
            - name: TEST_DIR
              value: /tests
          command: [ "bash", "$(TEST_DIR)/core_services_test.sh" ]
          resources:
            limits:
              cpu: 250m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
          volumeMounts:
            - mountPath: /tests
              name: test-scripts
      restartPolicy: Never
      volumes:
        - name: test-scripts
          configMap:
            name: my-gooddata-cn-chart-tests
            defaultMode: 0744
---
# Source: gooddata-cn/templates/tests/postgres-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-postgres-test
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: chartTests
    spec:
      serviceAccountName: my-gooddata-cn
      containers:
        - name: my-gooddata-cn-postgres-test
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          env:
            - name: PGHOST
              value: "my-gooddata-cn-db-pgpool"
            - name: PGPORT
              value: "5432"
            - name: METADATA_USERNAME
              value: "postgres"
            - name: METADATA_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: METADATA_DATABASE
              value: md
            - name: DEX_USERNAME
              value: "postgres"
            - name: DEX_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: "my-gooddata-cn-db-postgresql"
                  key: postgresql-password
            - name: DEX_DATABASE
              value: dex
            - name: TEST_DIR
              value: /tests
          command: [ "bash", "$(TEST_DIR)/postgres_test.sh" ]
          resources:
            limits:
              cpu: 250m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
          volumeMounts:
            - mountPath: /tests
              name: test-scripts
      restartPolicy: Never
      volumes:
        - name: test-scripts
          configMap:
            name: my-gooddata-cn-chart-tests
            defaultMode: 0744
---
# Source: gooddata-cn/templates/tests/public-restapi-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-public-restapi-test
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: chartTests
    spec:
      serviceAccountName: my-gooddata-cn
      containers:
        - name: my-gooddata-cn-public-restapi-test
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          env:
            - name: TEST_DIR
              value: /tests
          command: [ "bash", "$(TEST_DIR)/public_rest_api_test.sh" ]
          resources:
            limits:
              cpu: 250m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
          volumeMounts:
            - mountPath: /tests
              name: test-scripts
      restartPolicy: Never
      volumes:
        - name: test-scripts
          configMap:
            name: my-gooddata-cn-chart-tests
            defaultMode: 0744
---
# Source: gooddata-cn/templates/tests/pulsar-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-pulsar-test
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: chartTests
    spec:
      serviceAccountName: my-gooddata-cn
      containers:
        - name: my-gooddata-cn-pulsar-test
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          env:
            - name: PULSAR_CLIENT_FROM_ENV
              value: "true"
            - name: webServiceUrl
              value: "http://pulsar-broker.pulsar:8080"
            - name: PULSAR_TENANT
              value: "default"
            - name: PULSAR_NAMESPACE
              value: "my-gooddata-cn"
            - name: PULSAR_PREFIX
              value: "default/my-gooddata-cn"
            - name: TEST_DIR
              value: /tests
          command: [ "bash", "$(TEST_DIR)/pulsar_test.sh" ]
          resources:
            limits:
              cpu: 250m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
          volumeMounts:
            - mountPath: /tests
              name: test-scripts
      restartPolicy: Never
      volumes:
        - name: test-scripts
          configMap:
            name: my-gooddata-cn-chart-tests
            defaultMode: 0744
---
# Source: gooddata-cn/templates/tests/redis-job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: my-gooddata-cn-redis-test
  annotations:
    "helm.sh/hook": test
    "helm.sh/hook-weight": "0"
    "helm.sh/hook-delete-policy": before-hook-creation
  labels:
    helm.sh/chart: gooddata-cn-3.17.0
    app.kubernetes.io/name: gooddata-cn
    app.kubernetes.io/instance: my-gooddata-cn
    app.kubernetes.io/component: chartTests
    app.kubernetes.io/version: "1.0"
    app.kubernetes.io/managed-by: Helm
spec:
  backoffLimit: 0
  template:
    metadata:
      labels:
        app.kubernetes.io/name: gooddata-cn
        app.kubernetes.io/instance: my-gooddata-cn
        app.kubernetes.io/component: chartTests
    spec:
      serviceAccountName: my-gooddata-cn
      containers:
        - name: my-gooddata-cn-redis-test
          image: "gooddata/tools:3.17.0"
          imagePullPolicy: Always
          env:
            
            - name: SPRING_REDIS_SENTINEL_MASTER
              value: "mymaster"
            - name: SPRING_REDIS_SENTINEL_NODES
              value: "my-gooddata-cn-redis-ha-announce-0:26379,my-gooddata-cn-redis-ha-announce-1:26379,my-gooddata-cn-redis-ha-announce-2:26379"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_ENABLED
              value: "true"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_IDLE
              value: "30"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_COUNT
              value: "3"
            - name: GDC_REDIS_CLIENT_SOCKET_KEEPALIVE_INTERVAL
              value: "10"
            - name: GDC_REDIS_CLIENT_SOCKET_TCP_USER_TIMEOUT
              value: "60"
            - name: TEST_DIR
              value: /tests
          command: [ "bash", "$(TEST_DIR)/redis_test.sh" ]
          resources:
            limits:
              cpu: 250m
              memory: 200Mi
            requests:
              cpu: 10m
              memory: 5Mi
          volumeMounts:
            - mountPath: /tests
              name: test-scripts
      restartPolicy: Never
      volumes:
        - name: test-scripts
          configMap:
            name: my-gooddata-cn-chart-tests
            defaultMode: 0744
