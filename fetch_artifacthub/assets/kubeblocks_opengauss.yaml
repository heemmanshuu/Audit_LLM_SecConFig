---
# Source: opengauss/templates/agamotto-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opengauss-agamotto-configuration
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  agamotto-config.yaml: |-
    extensions:
      memory_ballast:
        size_mib: 32

    receivers:
      apecloudpostgresql:
        endpoint: ${env:ENDPOINT}
        username: ${env:DATA_SOURCE_USER}
        password: ${env:DATA_SOURCE_PASS}
        databases:
          - postgres
        exclude_databases:
          - template0
          - template1
        query_path: /opt/conf/custom-metrics.yaml
        collection_interval: 15s
        transport: tcp
        tls:
          insecure: true
          insecure_skip_verify: true

    processors:
      memory_limiter:
        limit_mib: 128
        spike_limit_mib: 32
        check_interval: 10s

    exporters:
      prometheus:
        endpoint: 0.0.0.0:9187
        send_timestamps: false
        metric_expiration: 20s
        enable_open_metrics: false
        resource_to_telemetry_conversion:
          enabled: true

    service:
      telemetry:
        logs:
          level: info
      pipelines:
        metrics:
          receivers: [ apecloudpostgresql ]
          processors: [ memory_limiter ]
          exporters: [ prometheus ]
      extensions: [ ]
---
# Source: opengauss/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opengauss-configuration
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  postgresql.conf: |-
    # -----------------------------------------------------------------------------
    #
    # postgresql_single.conf.sample
    #      Configuration file for centralized environment
    #
    # Portions Copyright (c) 1996-2012, PostgreSQL Global Development Group
    #
    #
    # IDENTIFICATION
    #      src/common/backend/utils/misc/postgresql_single.conf.sample
    #
    #
    # This file consists of lines of the form:
    #
    #   name = value
    #
    # (The "=" is optional.)  Whitespace may be used.  Comments are introduced with
    # "#" anywhere on a line.  The complete list of parameter names and allowed
    # values can be found in the openGauss documentation.
    #
    # The commented-out settings shown in this file represent the default values.
    # Re-commenting a setting is NOT sufficient to revert it to the default value;
    # you need to reload the server.
    #
    # This file is read on server startup and when the server receives a SIGHUP
    # signal.  If you edit the file on a running system, you have to SIGHUP the
    # server for the changes to take effect, or use "pg_ctl reload".  Some
    # parameters, which are marked below, require a server shutdown and restart to
    # take effect.
    #
    # Any parameter can also be given as a command-line option to the server, e.g.,
    # "postgres -c log_connections=on".  Some parameters can be changed at run time
    # with the "SET" SQL command.
    #
    # Memory units:  kB = kilobytes        Time units:  ms  = milliseconds
    #                MB = megabytes                     s   = seconds
    #                GB = gigabytes                     min = minutes
    #                                                   h   = hours
    #                                                   d   = days
    # -----------------------------------------------------------------------------
    
    
    #------------------------------------------------------------------------------
    # FILE LOCATIONS
    #------------------------------------------------------------------------------
    
    # The default values of these variables are driven from the -D command-line
    # option or PGDATA environment variable, represented here as ConfigDir.
    
    #data_directory = 'ConfigDir'           # use data in another directory
                                            # (change requires restart)
    #hba_file = 'ConfigDir/pg_hba.conf'     # host-based authentication file
                                            # (change requires restart)
    #ident_file = 'ConfigDir/pg_ident.conf' # ident configuration file
                                            # (change requires restart)
    
    # If external_pid_file is not explicitly set, no extra PID file is written.
    #external_pid_file = ''                 # write an extra PID file
                                            # (change requires restart)
    
    
    #------------------------------------------------------------------------------
    # CONNECTIONS AND AUTHENTICATION
    #------------------------------------------------------------------------------
    
    # - Connection Settings -
    
    #listen_addresses = 'localhost'         # what IP address(es) to listen on;
                                            # comma-separated list of addresses;
                                            # defaults to 'localhost'; use '*' for all
                                            # (change requires restart)
    #local_bind_address = '0.0.0.0'
    #port = 5432                            # (change requires restart)
    #max_connections = 10000                   # (change requires restart)
    # Note:  Increasing max_connections costs ~400 bytes of shared memory per
    # connection slot, plus lock space (see max_locks_per_transaction).
    #sysadmin_reserved_connections = 3      # (change requires restart)
    #unix_socket_directory = ''             # (change requires restart)
    #unix_socket_group = ''                 # (change requires restart)
    #unix_socket_permissions = 0700         # begin with 0 to use octal notation
                                            # (change requires restart)
    
    # - Security and Authentication -
    
    #authentication_timeout = 1min          # 1s-600s
    #session_timeout = 10min                 # allowed duration of any unused session, 0s-86400s(1 day), 0 is disabled
    #ssl = off                              # (change requires restart)
    #ssl_ciphers = 'ALL'                    # allowed SSL ciphers
                                            # (change requires restart)
    #ssl_cert_notify_time = 90              # 7-180 days
    #ssl_renegotiation_limit = 0            # amount of data between renegotiations, no longer supported
    #ssl_cert_file = 'server.crt'           # (change requires restart)
    #ssl_key_file = 'server.key'            # (change requires restart)
    #ssl_ca_file = ''                       # (change requires restart)
    #ssl_crl_file = ''                      # (change requires restart)
    
    # Kerberos and GSSAPI
    #krb_server_keyfile = ''
    #krb_srvname = 'postgres'               # (Kerberos only)
    #krb_caseins_users = off
    
    #modify_initial_password = false        #Whether to change the initial password of the initial user
    #password_policy = 1                    #Whether password complexity checks
    #password_reuse_time = 60               #Whether the new password can be reused in password_reuse_time days
    #password_reuse_max = 0                 #Whether the new password can be reused
    #password_lock_time = 1                 #The account will be unlocked automatically after a specified period of time
    #failed_login_attempts = 10             #Enter the wrong password reached failed_login_attempts times, the current account will be locked
    #password_encryption_type = 1           #Password storage type, 0 is md5 for PG, 1 is sha256 + md5, 2 is sha256 only
    #password_min_length = 8                #The minimal password length(6-999)
    #password_max_length = 32               #The maximal password length(6-999)
    #password_min_uppercase = 0             #The minimal upper character number in password(0-999)
    #password_min_lowercase = 0             #The minimal lower character number in password(0-999)
    #password_min_digital = 0               #The minimal digital character number in password(0-999)
    #password_min_special = 0               #The minimal special character number in password(0-999)
    #password_effect_time = 90d             #The password effect time(0-999)
    #password_notify_time = 7d              #The password notify time(0-999)
    
    # - TCP Keepalives -
    # see "man 7 tcp" for details
    
    #tcp_keepalives_idle = 0                # TCP_KEEPIDLE, in seconds;
                                            # 0 selects the system default
    #tcp_keepalives_interval = 0            # TCP_KEEPINTVL, in seconds;
                                            # 0 selects the system default
    #tcp_keepalives_count = 0               # TCP_KEEPCNT;
                                            # 0 selects the system default
    
    #------------------------------------------------------------------------------
    # RESOURCE USAGE (except WAL)
    #------------------------------------------------------------------------------
    
    # - Memory -
    #memorypool_enable = false
    #memorypool_size = 512MB
    
    #enable_memory_limit = true
    #max_process_memory = 12GB
    #UDFWorkerMemHardLimit = 1GB
    
    #shared_buffers = 32MB                   # min 128kB
                                            # (change requires restart)
    #bulk_write_ring_size = 2GB              # for bulkload, max shared_buffers
    #standby_shared_buffers_fraction = 0.3 #control shared buffers use in standby, 0.1-1.0
    #temp_buffers = 8MB                     # min 800kB
    #max_prepared_transactions = 200
                                            # (change requires restart)
    # Note:  Increasing max_prepared_transactions costs ~600 bytes of shared memory
    # per transaction slot, plus lock space (see max_locks_per_transaction).
    # It is not advisable to set max_prepared_transactions nonzero unless you
    # actively intend to use prepared transactions.
    #work_mem = 64MB                                # min 64kB
    #maintenance_work_mem = 16MB            # min 1MB
    #max_stack_depth = 2MB                  # min 100kB
    
    #cstore_buffers = 512MB         #min 16MB
    
    # - Disk -
    
    #temp_file_limit = -1                   # limits per-session temp file space
                                            # in kB, or -1 for no limit
    
    #sql_use_spacelimit = -1                # limits for single SQL used space on single DN
                                            # in kB, or -1 for no limit
    
    # - Kernel Resource Usage -
    
    #max_files_per_process = 1000           # min 25
                                            # (change requires restart)
    #shared_preload_libraries = ''         # (change requires restart)
    # - Cost-Based Vacuum Delay -
    
    #vacuum_cost_delay = 0ms                # 0-100 milliseconds
    #vacuum_cost_page_hit = 1               # 0-10000 credits
    #vacuum_cost_page_miss = 10             # 0-10000 credits
    #vacuum_cost_page_dirty = 20            # 0-10000 credits
    #vacuum_cost_limit = 200                # 1-10000 credits
    
    # - Background Writer -
    
    #bgwriter_delay = 10s                   # 10-10000ms between rounds
    #bgwriter_lru_maxpages = 100            # 0-1000 max buffers written/round
    #bgwriter_lru_multiplier = 2.0          # 0-10.0 multipler on buffers scanned/round
    
    # - Asynchronous Behavior -
    
    #effective_io_concurrency = 1           # 1-1000; 0 disables prefetching
    
    
    #------------------------------------------------------------------------------
    # WRITE AHEAD LOG
    #------------------------------------------------------------------------------
    
    # - Settings -
    
    #wal_level = hot_standby                 # minimal, archive, hot_standby or logical
                                            # (change requires restart)
    #fsync = on                             # turns forced synchronization on or off
    #synchronous_commit = on                # synchronization level;
                                            # off, local, remote_receive, remote_write, or on
                                            # It's global control for all transactions
                                            # It could not be modified by gs_ctl reload, unless use setsyncmode.
    
    #wal_sync_method = fsync                # the default is the first option
                                            # supported by the operating system:
                                            #   open_datasync
                                            #   fdatasync (default on Linux)
                                            #   fsync
                                            #   fsync_writethrough
                                            #   open_sync
    #full_page_writes = on                  # recover from partial page writes
    #wal_buffers = 16MB                     # min 32kB
                                            # (change requires restart)
    #wal_writer_delay = 200ms               # 1-10000 milliseconds
    
    #commit_delay = 0                       # range 0-100000, in microseconds
    #commit_siblings = 5                    # range 1-1000
    
    # - Checkpoints -
    
    #checkpoint_segments = 64               # in logfile segments, min 1, 16MB each
    #checkpoint_timeout = 15min             # range 30s-1h
    #checkpoint_completion_target = 0.5     # checkpoint target duration, 0.0 - 1.0
    #checkpoint_warning = 5min              # 0 disables
    #checkpoint_wait_timeout = 60s  # maximum time wait checkpointer to start
    
    #enable_incremental_checkpoint = on      # enable incremental checkpoint
    #incremental_checkpoint_timeout = 60s    # range 1s-1h
    #pagewriter_sleep = 100ms               # dirty page writer sleep time, 0ms - 1h
    
    # - Archiving -
    
    #archive_mode = off             # allows archiving to be done
                                    # (change requires restart)
    #archive_command = ''           # command to use to archive a logfile segment
                                    # placeholders: %p = path of file to archive
                                    #               %f = file name only
                                    # e.g. 'test ! -f /mnt/server/archivedir/%f && cp %p /mnt/server/archivedir/%f'
    #archive_timeout = 0            # force a logfile segment switch after this
                                    # number of seconds; 0 disables
    #archive_dest = ''              # path to use to archive a logfile segment
    
    #------------------------------------------------------------------------------
    # REPLICATION
    #------------------------------------------------------------------------------
    
    # - heartbeat -
    #datanode_heartbeat_interval = 1s         # The heartbeat interval of the standby nodes.
                                     # The value is best configured less than half of
                                     # the wal_receiver_timeout and wal_sender_timeout.
    
    # - Sending Server(s) -
    
    # Set these on the master and on any standby that will send replication data.
    
    #max_wal_senders = 4             # max number of walsender processes
                                    # (change requires restart)
    #wal_keep_segments = 16          # in logfile segments, 16MB each; 0 disables
    #wal_sender_timeout = 6s        # in milliseconds; 0 disables
    #enable_slot_log = off
    #max_replication_slots = 4       # max number of replication slots.i
                                    # The value belongs to [1,7].
                                    # (change requires restart)
    #max_changes_in_memory = 4096
    #max_cached_tuplebufs = 8192
    
    #replconninfo1 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # or connect primary or standby on secondary
                                                    # The heartbeat thread will not start if not set localheartbeatport and remoteheartbeatport.
                                                    # e.g. 'localhost=10.145.130.2 localport=12211 localheartbeatport=12214 remotehost=10.145.130.3 remoteport=12212 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12213 remotehost=10.145.133.3 remoteport=12214'
    #replconninfo2 = ''             # replication connection information used to connect secondary on primary or standby,
                                                    # or connect primary or standby on secondary
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.4 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.4 remoteport=12314'
    #replconninfo3 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.5 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.5 remoteport=12314'
    #replconninfo4 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.6 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.6 remoteport=12314'
    #replconninfo5 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.7 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.7 remoteport=12314'
    #replconninfo6 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.8 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.8 remoteport=12314'
    #replconninfo7 = ''             # replication connection information used to connect primary on standby, or standby on primary,
                                                    # e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.9 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo1 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo2 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo3 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo4 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo5 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo6 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    #cross_cluster_replconninfo7 = ''             # replication connection information used to connect primary on primary cluster, or standby on standby cluster,
                                                    # e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
    
    # - Master Server -
    
    # These settings are ignored on a standby server.
    
    #synchronous_standby_names = '*' # standby servers that provide sync rep
                                    # comma-separated list of application_name
                                    # from standby(s); '*' = all
    #most_available_sync = off      # Whether master is allowed to continue
                                    # as standbalone after sync standby failure
                                    # It's global control for all transactions
    #vacuum_defer_cleanup_age = 0   # number of xacts by which cleanup is delayed
    #data_replicate_buffer_size = 16MB      # data replication buffer size
    #walsender_max_send_size = 8MB  # Size of walsender max send size
    #enable_data_replicate = on
    
    # - Standby Servers -
    
    # These settings are ignored on a master server.
    
    #hot_standby = on                        # "on" allows queries during recovery
                                            # (change requires restart)
    #max_standby_archive_delay = 30s        # max delay before canceling queries
                                            # when reading WAL from archive;
                                            # -1 allows indefinite delay
    #max_standby_streaming_delay = 30s      # max delay before canceling queries
                                            # when reading streaming WAL;
                                            # -1 allows indefinite delay
    #wal_receiver_status_interval = 5s      # send replies at least this often
                                            # 0 disables
    #hot_standby_feedback = off             # send info from standby to prevent
                                            # query conflicts
    #wal_receiver_timeout = 6s              # time that receiver waits for
                                            # communication from master
                                            # in milliseconds; 0 disables
    #wal_receiver_connect_timeout = 1s      # timeout that receiver connect master
                                                            # in seconds; 0 disables
    #wal_receiver_connect_retries = 1       # max retries that receiver connect master
    #wal_receiver_buffer_size = 64MB        # wal receiver buffer size
    #enable_xlog_prune = on # xlog keep for all standbys even through they are not connecting and donnot created replslot.
    #max_size_for_xlog_prune = 2147483647  # xlog keep for the wal size less than max_xlog_size when the enable_xlog_prune is on
    #max_logical_replication_workers = 4   # Maximum number of logical replication worker processes.
    
    #------------------------------------------------------------------------------
    # QUERY TUNING
    #------------------------------------------------------------------------------
    
    # - Planner Method Configuration -
    
    #enable_bitmapscan = on
    #enable_hashagg = on
    #enable_hashjoin = on
    #enable_indexscan = on
    #enable_indexonlyscan = on
    #enable_material = on
    #enable_mergejoin = on
    #enable_nestloop = on
    #enable_seqscan = on
    #enable_sort = on
    #enable_tidscan = on
    #enable_kill_query = off                 # optional: [on, off], default: off
    # - Planner Cost Constants -
    
    #seq_page_cost = 1.0                    # measured on an arbitrary scale
    #random_page_cost = 4.0                 # same scale as above
    #cpu_tuple_cost = 0.01                  # same scale as above
    #cpu_index_tuple_cost = 0.005           # same scale as above
    #cpu_operator_cost = 0.0025             # same scale as above
    #effective_cache_size = 128MB
    
    # - Genetic Query Optimizer -
    
    #geqo = on
    #geqo_threshold = 12
    #geqo_effort = 5                        # range 1-10
    #geqo_pool_size = 0                     # selects default based on effort
    #geqo_generations = 0                   # selects default based on effort
    #geqo_selection_bias = 2.0              # range 1.5-2.0
    #geqo_seed = 0.0                        # range 0.0-1.0
    
    # - Other Planner Options -
    
    #default_statistics_target = 100        # range 1-10000
    #constraint_exclusion = partition       # on, off, or partition
    #cursor_tuple_fraction = 0.1            # range 0.0-1.0
    #from_collapse_limit = 8
    #join_collapse_limit = 8                # 1 disables collapsing of explicit
                                            # JOIN clauses
    #plan_mode_seed = 0         # range -1-0x7fffffff
    #check_implicit_conversions = off
    
    #------------------------------------------------------------------------------
    # ERROR REPORTING AND LOGGING
    #------------------------------------------------------------------------------
    
    # - Where to Log -
    
    #log_destination = 'stderr'             # Valid values are combinations of
                                            # stderr, csvlog, syslog, and eventlog,
                                            # depending on platform.  csvlog
                                            # requires logging_collector to be on.
    
    # This is used when logging to stderr:
    #logging_collector = on                  # Enable capturing of stderr and csvlog
                                            # into log files. Required to be on for
                                            # csvlogs.
                                            # (change requires restart)
    
    # These are only used if logging_collector is on:
    #log_directory = 'pg_log'               # directory where log files are written,
                                            # can be absolute or relative to PGDATA
    #log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log' # log file name pattern,
                                            # can include strftime() escapes
    #log_file_mode = 0600                    # creation mode for log files,
                                            # begin with 0 to use octal notation
    #log_truncate_on_rotation = off         # If on, an existing log file with the
                                            # same name as the new log file will be
                                            # truncated rather than appended to.
                                            # But such truncation only occurs on
                                            # time-driven rotation, not on restarts
                                            # or size-driven rotation.  Default is
                                            # off, meaning append to existing files
                                            # in all cases.
    #log_rotation_age = 1d                  # Automatic rotation of logfiles will
                                            # happen after that time.  0 disables.
    #log_rotation_size = 20MB                # Automatic rotation of logfiles will
                                            # happen after that much log output.
                                            # 0 disables.
    
    # These are relevant when logging to syslog:
    #syslog_facility = 'LOCAL0'
    #syslog_ident = 'postgres'
    
    # This is only relevant when logging to eventlog (win32):
    #event_source = 'PostgreSQL'
    
    # - When to Log -
    
    #log_min_messages = warning             # values in order of decreasing detail:
                                            #   debug5
                                            #   debug4
                                            #   debug3
                                            #   debug2
                                            #   debug1
                                            #   info
                                            #   notice
                                            #   warning
                                            #   error
                                            #   log
                                            #   fatal
                                            #   panic
    
    #log_min_error_statement = error        # values in order of decreasing detail:
                                            #   debug5
                                            #   debug4
                                            #   debug3
                                            #   debug2
                                            #   debug1
                                            #   info
                                            #   notice
                                            #   warning
                                            #   error
                                            #   log
                                            #   fatal
                                            #   panic (effectively off)
    
    #log_min_duration_statement = 1800000    # -1 is disabled, 0 logs all statements
                                            # and their durations, > 0 logs only
                                            # statements running at least this number
                                            # of milliseconds
    
    
    # - What to Log -
    
    #debug_print_parse = off
    #debug_print_rewritten = off
    #debug_print_plan = off
    #debug_pretty_print = on
    #log_checkpoints = off
    #log_pagewriter = off
    #log_connections = off                   # log connection requirement from client
    #log_disconnections = off                # log disconnection from client
    #log_duration = off                      # log the execution time of each query
                                            # when log_duration is on and log_min_duration_statement
                                            # is larger than zero, log the ones whose execution time
                                            # is larger than this threshold
    #log_error_verbosity = default          # terse, default, or verbose messages
    #log_hostname = off                      # log hostname
    #log_line_prefix = '%m %u %d %h %p %S '  # special values:
                                            #   %a = application name
                                            #   %u = user name
                                            #   %d = database name
                                            #   %r = remote host and port
                                            #   %h = remote host
                                            #   %p = process ID
                                            #   %t = timestamp without milliseconds
                                            #   %m = timestamp with milliseconds
                                            #   %n = DataNode name
                                            #   %i = command tag
                                            #   %e = SQL state
                                            #   %c = logic thread ID
                                            #   %l = session line number
                                            #   %s = session start timestamp
                                            #   %v = virtual transaction ID
                                            #   %x = transaction ID (0 if none)
                                            #   %q = stop here in non-session
                                            #        processes
                                            #   %S = session ID
                                            #   %% = '%'
                                            # e.g. '<%u%%%d> '
    #log_lock_waits = off                   # log lock waits >= deadlock_timeout
    #log_statement = 'none'                 # none, ddl, mod, all
    #log_temp_files = -1                    # log temporary files equal or larger
                                            # than the specified size in kilobytes;
                                            # -1 disables, 0 logs all temp files
    #log_timezone = 'UCT'
    
    #------------------------------------------------------------------------------
    # ALARM
    #------------------------------------------------------------------------------
    #enable_alarm = on
    #connection_alarm_rate = 0.9
    #alarm_report_interval = 10
    #alarm_component = '/opt/snas/bin/snas_cm_cmd'
    
    #------------------------------------------------------------------------------
    # RUNTIME STATISTICS
    #------------------------------------------------------------------------------
    
    # - Query/Index Statistics Collector -
    
    #track_activities = on
    #track_counts = on
    #track_io_timing = off
    #track_functions = none                 # none, pl, all
    #track_activity_query_size = 1024       # (change requires restart)
    #update_process_title = on
    #stats_temp_directory = 'pg_stat_tmp'
    #track_thread_wait_status_interval = 30min # 0 to disable
    #track_sql_count = off
    #enbale_instr_track_wait = on
    
    # - Statistics Monitoring -
    
    #log_parser_stats = off
    #log_planner_stats = off
    #log_executor_stats = off
    #log_statement_stats = off
    
    #------------------------------------------------------------------------------
    # WORKLOAD MANAGER
    #------------------------------------------------------------------------------
    
    #use_workload_manager = on               # Enables workload manager in the system.
                                            # (change requires restart)
    #------------------------------------------------------------------------------
    # SECURITY POLICY
    #------------------------------------------------------------------------------
    #enable_security_policy = off
    #use_elastic_search = off
    #elastic_search_ip_addr = 'https://127.0.0.1' # what elastic search ip is, change https to http when elastic search is non-ssl mode
    
    
    #cpu_collect_timer = 30
    
    #------------------------------------------------------------------------------
    # AUTOVACUUM PARAMETERS
    #------------------------------------------------------------------------------
    
    #autovacuum = off                       # Enable autovacuum subprocess?  default value is 'on'
                                            # requires track_counts to also be on.
    #log_autovacuum_min_duration = -1       # -1 disables, 0 logs all actions and
                                            # their durations, > 0 logs only
                                            # actions running at least this number
                                            # of milliseconds.
    #autovacuum_max_workers = 3             # max number of autovacuum subprocesses
                                            # (change requires restart)
    #autovacuum_naptime = 1min              # time between autovacuum runs
    #autovacuum_vacuum_threshold = 50       # min number of row updates before
                                            # vacuum
    #autovacuum_analyze_threshold = 50      # min number of row updates before
                                            # analyze
    #autovacuum_vacuum_scale_factor = 0.2   # fraction of table size before vacuum
    #autovacuum_analyze_scale_factor = 0.1  # fraction of table size before analyze
    #autovacuum_freeze_max_age = 200000000  # maximum XID age before forced vacuum
                                            # (change requires restart)
    #autovacuum_vacuum_cost_delay = 20ms    # default vacuum cost delay for
                                            # autovacuum, in milliseconds;
                                            # -1 means use vacuum_cost_delay
    #autovacuum_vacuum_cost_limit = -1      # default vacuum cost limit for
                                            # autovacuum, -1 means use
                                            # vacuum_cost_limit
    
    
    #------------------------------------------------------------------------------
    # CLIENT CONNECTION DEFAULTS
    #------------------------------------------------------------------------------
    
    # - Statement Behavior -
    #client_min_messages = notice      # values in order of decreasing detail:
                       #   debug5
                       #   debug4
                       #   debug3
                       #   debug2
                       #   debug1
                       #   log
                       #   notice
                       #   warning
                       #   error
    #search_path = '"$user",public'         # schema names
    #default_tablespace = ''                # a tablespace name, '' uses the default
    #temp_tablespaces = ''                  # a list of tablespace names, '' uses
                                            # only default tablespace
    #check_function_bodies = on
    #default_transaction_isolation = 'read committed'
    #default_transaction_read_only = off
    #default_transaction_deferrable = off
    #session_replication_role = 'origin'
    #statement_timeout = 0                  # in milliseconds, 0 is disabled
    #vacuum_freeze_min_age = 50000000
    #vacuum_freeze_table_age = 150000000
    #bytea_output = 'hex'                   # hex, escape
    #xmlbinary = 'base64'
    #xmloption = 'content'
    #max_compile_functions = 1000
    #gin_pending_list_limit = 4MB
    # - Locale and Formatting -
    
    #datestyle = 'iso, mdy'
    #intervalstyle = 'postgres'
    #timezone = 'UCT'
    #timezone_abbreviations = 'Default'     # Select the set of available time zone
                                            # abbreviations.  Currently, there are
                                            #   Default
                                            #   Australia
                                            #   India
                                            # You can create your own file in
                                            # share/timezonesets/.
    #extra_float_digits = 0                 # min -15, max 3
    #client_encoding = sql_ascii            # actually, defaults to database
                                            # encoding
    
    # These settings are initialized by initdb, but they can be changed.
    #lc_messages = 'C'                       # locale for system error message
                                            # strings
    #lc_monetary = 'C'                       # locale for monetary formatting
    #lc_numeric = 'C'                        # locale for number formatting
    #lc_time = 'C'                           # locale for time formatting
    
    # default configuration for text search
    #default_text_search_config = 'pg_catalog.english'
    
    # - Other Defaults -
    
    #dynamic_library_path = '$libdir'
    #local_preload_libraries = ''
    
    #------------------------------------------------------------------------------
    # LOCK MANAGEMENT
    #------------------------------------------------------------------------------
    
    #deadlock_timeout = 1s
    #lockwait_timeout = 1200s                # Max of lockwait_timeout and deadlock_timeout + 1s
    #max_locks_per_transaction = 256                # min 10
                                            # (change requires restart)
    # Note:  Each lock table slot uses ~270 bytes of shared memory, and there are
    # max_locks_per_transaction * (max_connections + max_prepared_transactions)
    # lock table slots.
    #max_pred_locks_per_transaction = 64    # min 10
                                            # (change requires restart)
    
    #------------------------------------------------------------------------------
    # VERSION/PLATFORM COMPATIBILITY
    #------------------------------------------------------------------------------
    
    # - Previous openGauss Versions -
    
    #array_nulls = on
    #backslash_quote = safe_encoding        # on, off, or safe_encoding
    #default_with_oids = off
    #escape_string_warning = on
    #lo_compat_privileges = off
    #quote_all_identifiers = off
    #sql_inheritance = on
    #standard_conforming_strings = on
    #synchronize_seqscans = on
    
    # - Other Platforms and Clients -
    
    #transform_null_equals = off
    
    ##------------------------------------------------------------------------------
    # ERROR HANDLING
    #------------------------------------------------------------------------------
    
    #exit_on_error = off                    # terminate session on any error?
    #restart_after_crash = on               # reinitialize after backend crash?
    #omit_encoding_error = off              # omit untranslatable character error
    #data_sync_retry = off                  # retry or panic on failure to fsync data?
    
    #------------------------------------------------------------------------------
    # DATA NODES AND CONNECTION POOLING
    #------------------------------------------------------------------------------
    #cache_connection = on          # pooler cache connection
    
    #------------------------------------------------------------------------------
    # GTM CONNECTION
    #------------------------------------------------------------------------------
    
    #pgxc_node_name = 'gaussdb'                      # Coordinator or Datanode name
                                            # (change requires restart)
    
    ##------------------------------------------------------------------------------
    # OTHER PG-XC OPTIONS
    #------------------------------------------------------------------------------
    #enforce_two_phase_commit = on          # Enforce the usage of two-phase commit on transactions
                                            # where temporary objects are used or ON COMMIT actions
                                            # are pending.
                                            # Usage of commit instead of two-phase commit may break
                                            # data consistency so use at your own risk.
    
    #------------------------------------------------------------------------------
    # AUDIT
    #------------------------------------------------------------------------------
    
    #audit_enabled = on
    #audit_directory = 'pg_audit'
    #audit_data_format = 'binary'
    #audit_rotation_interval = 1d
    #audit_rotation_size = 10MB
    #audit_space_limit = 1024MB
    #audit_file_remain_threshold = 1048576
    #audit_login_logout = 7
    #audit_database_process = 1
    #audit_user_locked = 1
    #audit_user_violation = 0
    #audit_grant_revoke = 1
    #audit_system_object = 12295
    #audit_dml_state = 0
    #audit_dml_state_select = 0
    #audit_function_exec = 0
    #audit_copy_exec = 0
    #audit_set_parameter = 1                # whether audit set parameter operation
    #audit_xid_info = 0                     # whether record xid info in audit log
    #audit_thread_num = 1
    
    #Choose which style to print the explain info, normal,pretty,summary,run
    #explain_perf_mode = normal
    #------------------------------------------------------------------------------
    # CUSTOMIZED OPTIONS
    #------------------------------------------------------------------------------
    
    # Add settings for extensions here
    
    # ENABLE DATABASE PRIVILEGES SEPARATE
    #------------------------------------------------------------------------------
    #enableSeparationOfDuty = off
    #------------------------------------------------------------------------------
    
    
    #enable_fast_allocate = off
    #prefetch_quantity = 32MB
    #backwrite_quantity = 8MB
    #cstore_prefetch_quantity = 32768               #unit kb
    #cstore_backwrite_quantity = 8192               #unit kb
    #cstore_backwrite_max_threshold =  2097152              #unit kb
    #fast_extend_file_size = 8192           #unit kb
    
    #------------------------------------------------------------------------------
    # LLVM
    #------------------------------------------------------------------------------
    #enable_codegen = on                    # consider use LLVM optimization
    #enable_codegen_print = off             # dump the IR function
    #codegen_cost_threshold = 10000         # the threshold to allow use LLVM Optimization
    
    #------------------------------------------------------------------------------
    # JOB SCHEDULER OPTIONS
    #------------------------------------------------------------------------------
    #job_queue_processes = 10               # Number of concurrent jobs, optional: [0..1000], default: 10.
    
    #------------------------------------------------------------------------------
    # DCF OPTIONS
    #------------------------------------------------------------------------------
    #enable_dcf = off
    #
    #------------------------------------------------------------------------------
    # PLSQL COMPILE OPTIONS
    #------------------------------------------------------------------------------
    #plsql_show_all_error=off
    
    # use default port 5432
    
    ########################
    ## Notice: Do not remove the comments above directly,
    ## as it may cause the CUE voice template check to fail.
    ## Please write the parameters you want below.
    ########################
    
    
    max_connections = 200
    listen_addresses = '*'
    password_encryption_type = 0
    enable_slot_log = off
    
    # Do not modify the 'max_replication_slots' parameter as it may result in the failure to start the database service
    max_replication_slots = 8
    
    wal_level = logical
    job_queue_processes = 10
    log_min_duration_statement = 1800000
    session_timeout = 10min
    shared_buffers = 32MB
    bulk_write_ring_size = 2GB
    max_prepared_transactions = 200
    cstore_buffers = 512MB
    wal_level = hot_standby
    enable_incremental_checkpoint = on
    incremental_checkpoint_timeout = 60s
    max_wal_senders = 4
    wal_keep_segments = 16
    synchronous_standby_names = '*'
    walsender_max_send_size = 8MB
    hot_standby = on
    enable_kill_query = off
    
    logging_collector = on
    log_filename = 'postgresql-%Y-%m-%d_%H%M%S.log'
    log_file_mode = 0600
    log_rotation_size = 20MB
    log_connections = off
    log_disconnections = off
    log_duration = off
    log_hostname = off
    log_line_prefix = '%m %u %d %h %p %S '
    
    log_timezone = 'UCT'
    
    enable_alarm = on
    connection_alarm_rate = 0.9
    alarm_report_interval = 10
    alarm_component = '/opt/snas/bin/snas_cm_cmd'
    
    use_workload_manager = on
    datestyle = 'iso, mdy'
    timezone = 'UCT'
    lc_messages = 'C'
    lc_monetary = 'C'
    lc_numeric = 'C'
    lc_time = 'C'
    default_text_search_config = 'pg_catalog.english'
    lockwait_timeout = 1200s
    pgxc_node_name = 'gaussdb'
    audit_enabled = on
  # TODO: check if it should trust all
  pg_hba.conf: |
    host     all             all             0.0.0.0/0                md5
    host     all             all             ::/0                     md5
    local    all             all                                     trust
    host     all             all             127.0.0.1/32            trust
    host     all             all             ::1/128                 trust
    local     replication     all                                    trust
    host      replication     all             0.0.0.0/0               md5
    host      replication     all             ::/0                    md5
---
# Source: opengauss/templates/metrics-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opengauss-custom-metrics
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  custom-metrics.yaml: |-
    pg_postmaster:
      query: "/*kb-monitor*/SELECT pg_postmaster_start_time as start_time_seconds from pg_postmaster_start_time()"
      master: true
      metrics:
        - start_time_seconds:
            usage: "GAUGE"
            description: "Time at which postmaster started"

    pg_replication:
      query: |
        /*kb-monitor*/SELECT
        (case when (not pg_is_in_recovery() or pg_last_wal_receive_lsn() = pg_last_wal_replay_lsn()) then 0 else greatest (0, extract(epoch from (now() - pg_last_xact_replay_timestamp()))) end) as lag,
        (case when pg_is_in_recovery() then 0 else 1 end) as is_master
      master: true
      metrics:
        - lag:
            usage: "GAUGE"
            description: "Replication lag behind master in seconds"
        - is_master:
            usage: "GAUGE"
            description: "Instance is master or slave"

    pg_stat_user_tables:
      query: |
        /*kb-monitor*/SELECT
        current_database() datname,
        schemaname,
        relname,
        seq_scan,
        seq_tup_read,
        idx_scan,
        idx_tup_fetch,
        n_tup_ins,
        n_tup_upd,
        n_tup_del,
        n_tup_hot_upd,
        n_live_tup,
        n_dead_tup,
        n_mod_since_analyze,
        n_ins_since_vacuum,
        COALESCE(last_vacuum, '1970-01-01Z') as last_vacuum,
        COALESCE(last_autovacuum, '1970-01-01Z') as last_autovacuum,
        COALESCE(last_analyze, '1970-01-01Z') as last_analyze,
        COALESCE(last_autoanalyze, '1970-01-01Z') as last_autoanalyze,
        vacuum_count,
        autovacuum_count,
        analyze_count,
        autoanalyze_count
        FROM
        pg_stat_user_tables
      metrics:
        - datname:
            usage: "LABEL"
            description: "Name of current database"
        - schemaname:
            usage: "LABEL"
            description: "Name of the schema that this table is in"
        - relname:
            usage: "LABEL"
            description: "Name of this table"
        - seq_scan:
            usage: "COUNTER"
            description: "Number of sequential scans initiated on this table"
        - seq_tup_read:
            usage: "COUNTER"
            description: "Number of live rows fetched by sequential scans"
        - idx_scan:
            usage: "COUNTER"
            description: "Number of index scans initiated on this table"
        - idx_tup_fetch:
            usage: "COUNTER"
            description: "Number of live rows fetched by index scans"
        - n_tup_ins:
            usage: "COUNTER"
            description: "Number of rows inserted"
        - n_tup_upd:
            usage: "COUNTER"
            description: "Number of rows updated"
        - n_tup_del:
            usage: "COUNTER"
            description: "Number of rows deleted"
        - n_tup_hot_upd:
            usage: "COUNTER"
            description: "Number of rows HOT updated (i.e., with no separate index update required)"
        - n_live_tup:
            usage: "GAUGE"
            description: "Estimated number of live rows"
        - n_dead_tup:
            usage: "GAUGE"
            description: "Estimated number of dead rows"
        - n_mod_since_analyze:
            usage: "GAUGE"
            description: "Estimated number of rows changed since last analyze"
        - n_ins_since_vacuum:
            usage: "GAUGE"
            description: "Estimated number of rows inserted since this table was last vacuumed"
        - last_vacuum:
            usage: "GAUGE"
            description: "Last time at which this table was manually vacuumed (not counting VACUUM FULL)"
        - last_autovacuum:
            usage: "GAUGE"
            description: "Last time at which this table was vacuumed by the autovacuum daemon"
        - last_analyze:
            usage: "GAUGE"
            description: "Last time at which this table was manually analyzed"
        - last_autoanalyze:
            usage: "GAUGE"
            description: "Last time at which this table was analyzed by the autovacuum daemon"
        - vacuum_count:
            usage: "COUNTER"
            description: "Number of times this table has been manually vacuumed (not counting VACUUM FULL)"
        - autovacuum_count:
            usage: "COUNTER"
            description: "Number of times this table has been vacuumed by the autovacuum daemon"
        - analyze_count:
            usage: "COUNTER"
            description: "Number of times this table has been manually analyzed"
        - autoanalyze_count:
            usage: "COUNTER"
            description: "Number of times this table has been analyzed by the autovacuum daemon"

    pg_statio_user_tables:
      query: |
        /*kb-monitor*/SELECT
        current_database() datname,
        schemaname,
        relname,
        heap_blks_read,
        heap_blks_hit,
        idx_blks_read,
        idx_blks_hit,
        toast_blks_read,
        toast_blks_hit,
        tidx_blks_read,
        tidx_blks_hit
        FROM
        pg_statio_user_tables
      metrics:
        - datname:
            usage: "LABEL"
            description: "Name of current database"
        - schemaname:
            usage: "LABEL"
            description: "Name of the schema that this table is in"
        - relname:
            usage: "LABEL"
            description: "Name of this table"
        - heap_blks_read:
            usage: "COUNTER"
            description: "Number of disk blocks read from this table"
        - heap_blks_hit:
            usage: "COUNTER"
            description: "Number of buffer hits in this table"
        - idx_blks_read:
            usage: "COUNTER"
            description: "Number of disk blocks read from all indexes on this table"
        - idx_blks_hit:
            usage: "COUNTER"
            description: "Number of buffer hits in all indexes on this table"
        - toast_blks_read:
            usage: "COUNTER"
            description: "Number of disk blocks read from this table's TOAST table (if any)"
        - toast_blks_hit:
            usage: "COUNTER"
            description: "Number of buffer hits in this table's TOAST table (if any)"
        - tidx_blks_read:
            usage: "COUNTER"
            description: "Number of disk blocks read from this table's TOAST table indexes (if any)"
        - tidx_blks_hit:
            usage: "COUNTER"
            description: "Number of buffer hits in this table's TOAST table indexes (if any)"

    # WARNING: This set of metrics can be very expensive on a busy server as every unique query executed will create an additional time series
    pg_stat_statements_by_mean_exec_time:
      query: |
        /*kb-monitor*/SELECT
        t2.rolname,
        t3.datname,
        queryid,
        left(regexp_replace(trim(both ' ' from lower(query)),'\s+',' ','g'), 256) as query,
        plans,
        total_plan_time / 1000 as plan_time_seconds,
        min_plan_time / 1000 as min_plan_time_seconds,
        max_plan_time / 1000 as max_plan_time_seconds,
        mean_plan_time / 1000 as mean_plan_time_seconds,
        stddev_plan_time / 1000 as stddev_plan_time_seconds,
        calls,
        total_exec_time / 1000 as exec_time_seconds,
        min_exec_time / 1000 as min_exec_time_seconds,
        max_exec_time / 1000 as max_exec_time_seconds,
        mean_exec_time / 1000 as mean_exec_time_seconds,
        stddev_exec_time / 1000 as stddev_exec_time_seconds,
        rows,
        shared_blks_hit,
        shared_blks_read,
        shared_blks_dirtied,
        shared_blks_written,
        local_blks_hit,
        local_blks_read,
        local_blks_dirtied,
        local_blks_written,
        temp_blks_read,
        temp_blks_written,
        blk_read_time / 1000 as blk_read_time_seconds,
        blk_write_time / 1000 as blk_write_time_seconds,
        wal_records,
        wal_fpi,
        wal_bytes
        FROM
        pg_stat_statements t1
        JOIN
        pg_roles t2
        ON (t1.userid=t2.oid)
        JOIN
        pg_database t3
        ON (t1.dbid=t3.oid)
        WHERE t2.rolname != 'rdsadmin'
        ORDER BY mean_exec_time DESC
        LIMIT 50
      master: true
      metrics:
        - rolname:
            usage: "LABEL"
            description: "Name of user"
        - datname:
            usage: "LABEL"
            description: "Name of database"
        - queryid:
            usage: "LABEL"
            description: "Query ID"
        - query:
            usage: "LABEL"
            description: "First 64 chars for simple formatted query text"
        - plans:
            usage: "COUNTER"
            description: "Number of times the statement was planned"
        - plan_time_seconds:
            usage: "COUNTER"
            description: "Total time spent planning the statement"
        - min_plan_time_seconds:
            usage: "GAUGE"
            description: "Minimum time spent planning the statement"
        - max_plan_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent planning the statement"
        - mean_plan_time_seconds:
            usage: "GAUGE"
            description: "Mean time spent planning the statement"
        - stddev_plan_time_seconds:
            usage: "GAUGE"
            description: "Population standard deviation of time spent planning the statement"
        - calls:
            usage: "COUNTER"
            description: "Number of times executed"
        - exec_time_seconds:
            usage: "COUNTER"
            description: "Total time spent in the statement"
        - min_exec_time_seconds:
            usage: "GAUGE"
            description: "Minimum time spent in the statement"
        - max_exec_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent in the statement"
        - mean_exec_time_seconds:
            usage: "GAUGE"
            description: "Mean time spent in the statement"
        - stddev_exec_time_seconds:
            usage: "GAUGE"
            description: "Population standard deviation of time spent in the statement"
        - rows:
            usage: "COUNTER"
            description: "Total number of rows retrieved or affected by the statement"
        - shared_blks_hit:
            usage: "COUNTER"
            description: "Total number of shared block cache hits by the statement"
        - shared_blks_read:
            usage: "COUNTER"
            description: "Total number of shared blocks read by the statement"
        - shared_blks_dirtied:
            usage: "COUNTER"
            description: "Total number of shared blocks dirtied by the statement"
        - shared_blks_written:
            usage: "COUNTER"
            description: "Total number of shared blocks written by the statement"
        - local_blks_hit:
            usage: "COUNTER"
            description: "Total number of local block cache hits by the statement"
        - local_blks_read:
            usage: "COUNTER"
            description: "Total number of local blocks read by the statement"
        - local_blks_dirtied:
            usage: "COUNTER"
            description: "Total number of local blocks dirtied by the statement"
        - local_blks_written:
            usage: "COUNTER"
            description: "Total number of local blocks written by the statement"
        - temp_blks_read:
            usage: "COUNTER"
            description: "Total number of temp blocks read by the statement"
        - temp_blks_written:
            usage: "COUNTER"
            description: "Total number of temp blocks written by the statement"
        - blk_read_time_seconds:
            usage: "COUNTER"
            description: "Total time the statement spent reading blocks, in milliseconds (if track_io_timing is enabled, otherwise zero)"
        - blk_write_time_seconds:
            usage: "COUNTER"
            description: "Total time the statement spent writing blocks, in milliseconds (if track_io_timing is enabled, otherwise zero)"
        - wal_records:
            usage: "COUNTER"
            description: "Total number of WAL records generated by the statement"
        - wal_fpi:
            usage: "COUNTER"
            description: "Total number of WAL full page images generated by the statement"
        - wal_bytes:
            usage: "COUNTER"
            description: "Total amount of WAL generated by the statement in bytes"

    pg_stat_statements_by_calls:
      query: |
        /*kb-monitor*/SELECT
        t2.rolname,
        t3.datname,
        queryid,
        left(regexp_replace(trim(both ' ' from lower(query)),'\s+',' ','g'), 256) as query,
        plans,
        total_plan_time / 1000 as plan_time_seconds,
        min_plan_time / 1000 as min_plan_time_seconds,
        max_plan_time / 1000 as max_plan_time_seconds,
        mean_plan_time / 1000 as mean_plan_time_seconds,
        stddev_plan_time / 1000 as stddev_plan_time_seconds,
        calls,
        total_exec_time / 1000 as exec_time_seconds,
        min_exec_time / 1000 as min_exec_time_seconds,
        max_exec_time / 1000 as max_exec_time_seconds,
        mean_exec_time / 1000 as mean_exec_time_seconds,
        stddev_exec_time / 1000 as stddev_exec_time_seconds,
        rows,
        shared_blks_hit,
        shared_blks_read,
        shared_blks_dirtied,
        shared_blks_written,
        local_blks_hit,
        local_blks_read,
        local_blks_dirtied,
        local_blks_written,
        temp_blks_read,
        temp_blks_written,
        blk_read_time / 1000 as blk_read_time_seconds,
        blk_write_time / 1000 as blk_write_time_seconds,
        wal_records,
        wal_fpi,
        wal_bytes
        FROM
        pg_stat_statements t1
        JOIN
        pg_roles t2
        ON (t1.userid=t2.oid)
        JOIN
        pg_database t3
        ON (t1.dbid=t3.oid)
        WHERE t2.rolname != 'rdsadmin'
        ORDER BY calls DESC
        LIMIT 50
      master: true
      metrics:
        - rolname:
            usage: "LABEL"
            description: "Name of user"
        - datname:
            usage: "LABEL"
            description: "Name of database"
        - queryid:
            usage: "LABEL"
            description: "Query ID"
        - query:
            usage: "LABEL"
            description: "First 64 chars for simple formatted query text"
        - plans:
            usage: "COUNTER"
            description: "Number of times the statement was planned"
        - plan_time_seconds:
            usage: "COUNTER"
            description: "Total time spent planning the statement"
        - min_plan_time_seconds:
            usage: "GAUGE"
            description: "Minimum time spent planning the statement"
        - max_plan_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent planning the statement"
        - mean_plan_time_seconds:
            usage: "GAUGE"
            description: "Mean time spent planning the statement"
        - stddev_plan_time_seconds:
            usage: "GAUGE"
            description: "Population standard deviation of time spent planning the statement"
        - calls:
            usage: "COUNTER"
            description: "Number of times executed"
        - exec_time_seconds:
            usage: "COUNTER"
            description: "Total time spent in the statement"
        - min_exec_time_seconds:
            usage: "GAUGE"
            description: "Minimum time spent in the statement"
        - max_exec_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent in the statement"
        - mean_exec_time_seconds:
            usage: "GAUGE"
            description: "Mean time spent in the statement"
        - stddev_exec_time_seconds:
            usage: "GAUGE"
            description: "Population standard deviation of time spent in the statement"
        - rows:
            usage: "COUNTER"
            description: "Total number of rows retrieved or affected by the statement"
        - shared_blks_hit:
            usage: "COUNTER"
            description: "Total number of shared block cache hits by the statement"
        - shared_blks_read:
            usage: "COUNTER"
            description: "Total number of shared blocks read by the statement"
        - shared_blks_dirtied:
            usage: "COUNTER"
            description: "Total number of shared blocks dirtied by the statement"
        - shared_blks_written:
            usage: "COUNTER"
            description: "Total number of shared blocks written by the statement"
        - local_blks_hit:
            usage: "COUNTER"
            description: "Total number of local block cache hits by the statement"
        - local_blks_read:
            usage: "COUNTER"
            description: "Total number of local blocks read by the statement"
        - local_blks_dirtied:
            usage: "COUNTER"
            description: "Total number of local blocks dirtied by the statement"
        - local_blks_written:
            usage: "COUNTER"
            description: "Total number of local blocks written by the statement"
        - temp_blks_read:
            usage: "COUNTER"
            description: "Total number of temp blocks read by the statement"
        - temp_blks_written:
            usage: "COUNTER"
            description: "Total number of temp blocks written by the statement"
        - blk_read_time_seconds:
            usage: "COUNTER"
            description: "Total time the statement spent reading blocks, in milliseconds (if track_io_timing is enabled, otherwise zero)"
        - blk_write_time_seconds:
            usage: "COUNTER"
            description: "Total time the statement spent writing blocks, in milliseconds (if track_io_timing is enabled, otherwise zero)"
        - wal_records:
            usage: "COUNTER"
            description: "Total number of WAL records generated by the statement"
        - wal_fpi:
            usage: "COUNTER"
            description: "Total number of WAL full page images generated by the statement"
        - wal_bytes:
            usage: "COUNTER"
            description: "Total amount of WAL generated by the statement in bytes"

    pg_stat_statements_stats:
      query: |
        /*kb-monitor*/SELECT
          t2.rolname,
          t3.datname,
          calls,
          total_exec_time / 1000 as exec_time_seconds,
          mean_exec_time / 1000 as mean_exec_time_seconds,
          max_exec_time / 1000 as max_exec_time_seconds,
          rows
        FROM (
          SELECT
            userid,
            dbid,
            SUM(calls) AS calls,
            SUM(total_exec_time) as total_exec_time,
            AVG(mean_exec_time) as mean_exec_time,
            MAX(max_exec_time) as max_exec_time,
            SUM(rows) AS rows
          FROM
            pg_stat_statements
          GROUP BY userid, dbid
        ) tmp
        JOIN
          pg_roles t2
        ON (tmp.userid=t2.oid)
        JOIN
          pg_database t3
        ON (tmp.dbid=t3.oid)
        WHERE t2.rolname != 'rdsadmin'
      master: true
      metrics:
        - rolname:
            usage: "LABEL"
            description: "Name of user"
        - datname:
            usage: "LABEL"
            description: "Name of database"
        - calls:
            usage: "COUNTER"
            description: "Number of times executed"
        - exec_time_seconds:
            usage: "COUNTER"
            description: "Total time spent in the statement"
        - mean_exec_time_seconds:
            usage: "GAUGE"
            description: "Mean time spent in the statement"
        - max_exec_time_seconds:
            usage: "GAUGE"
            description: "Maximum time spent in the statement"
        - rows:
            usage: "COUNTER"
            description: "Total number of rows retrieved or affected by the statement"

    pg_wal_log_file:
      query: "/*kb-monitor*/SELECT count(*) AS count FROM pg_ls_dir('pg_wal') WHERE pg_ls_dir ~ '^[0-9A-F]{24}'"
      master: true
      metrics:
        - count:
            usage: "GAUGE"
            description: "Wal log file count"

    pg_stat_activity_detail:
      query: |
        /*kb-monitor*/SELECT
          datname,wait_event_type,wait_event,state,backend_type,COUNT(1) AS count
        FROM pg_stat_activity
        GROUP BY datname,wait_event_type,wait_event,state,backend_type
      master: true
      metrics:
        - datname:
            usage: "LABEL"
            description: "Name of current database"
        - wait_event_type:
            usage: "LABEL"
            description: "The type of event for which the backend is waiting, if any; otherwise NULL."
        - wait_event:
            usage: "LABEL"
            description: "Wait event name if backend is currently waiting, otherwise NULL. "
        - state:
            usage: "LABEL"
            description: "Current overall state of this backend."
        - backend_type:
            usage: "LABEL"
            description: "Type of current backend."
        - count:
            usage: "GAUGE"
            description: "Const value of 1"

    pg_locks_detail:
      query: |
        /*kb-monitor*/SELECT
          locktype,datname,relation,mode,granted,fastpath,max_wait_age_seconds,count
        FROM (
          SELECT locktype,database,relation,mode,granted,fastpath,MAX(wait_age_seconds) AS max_wait_age_seconds,COUNT(1) AS count
          FROM (
            SELECT locktype,database,relation::regclass,mode,granted::int,fastpath::int,
              COALESCE(EXTRACT(EPOCH FROM now() - waitstart),0) AS wait_age_seconds
            FROM pg_locks
          ) p1
          GROUP BY locktype,database,relation,mode,granted,fastpath
        ) p2
        LEFT JOIN (
          SELECT oid,datname FROM pg_database
        ) pd
        ON p2.database=pd.oid
      master: true
      metrics:
        - locktype:
            usage: "LABEL"
            description: "Type of the lockable object"
        - datname:
            usage: "LABEL"
            description: "Name of current database"
        - relation:
            usage: "LABEL"
            description: "Relation targeted by the lock, or null if the target is not a relation or part of a relation"
        - mode:
            usage: "LABEL"
            description: "Name of the lock mode held or desired by this process"
        - granted:
            usage: "LABEL"
            description: "True if lock is held, false if lock is awaited"
        - fastpath:
            usage: "LABEL"
            description: "True if lock was taken via fast path, false if taken via main lock table"
        - max_wait_age_seconds:
            usage: "GAUGE"
            description: "Max time in seconds when the server process started waiting for this lock, or null if the lock is held"
        - count:
            usage: "GAUGE"
            description: "Const value of 1"

    pg_stat_wal:
      query: |
        /*kb-monitor*/SELECT
          wal_records,
          wal_fpi,
          wal_bytes,
          wal_buffers_full,
          wal_write,
          wal_sync,
          wal_write_time / 1000 as wal_write_time_seconds,
          wal_sync_time / 1000 as wal_sync_time_seconds
        FROM pg_stat_wal
      master: true
      metrics:
        - wal_records:
            usage: "COUNTER"
            description: "Total number of WAL records generated"
        - wal_fpi:
            usage: "COUNTER"
            description: "Total number of WAL full page images generated"
        - wal_bytes:
            usage: "COUNTER"
            description: "Total amount of WAL generated in bytes"
        - wal_buffers_full:
            usage: "COUNTER"
            description: "Number of times WAL data was written to disk because WAL buffers became full"
        - wal_write:
            usage: "COUNTER"
            description: "Number of times WAL buffers were written out to disk via XLogWrite request."
        - wal_sync:
            usage: "COUNTER"
            description: "Number of times WAL files were synced to disk via issue_xlog_fsync request"
        - wal_write_time_seconds:
            usage: "COUNTER"
            description: "Total amount of time spent writing WAL buffers to disk via XLogWrite request"
        - wal_sync_time_seconds:
            usage: "COUNTER"
            description: "Total amount of time spent syncing WAL files to disk via issue_xlog_fsync request"
---
# Source: opengauss/templates/scripts.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: opengauss-scripts
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
data:
  
  setup.sh: |-
    #!/usr/bin/env bash
    set -Eeo pipefail
    
    # usage: file_env VAR [DEFAULT]
    #    ie: file_env 'XYZ_DB_PASSWORD' 'example'
    # (will allow for "$XYZ_DB_PASSWORD_FILE" to fill in the value of
    #  "$XYZ_DB_PASSWORD" from a file, especially for Docker's secrets feature)
    
    export GAUSSHOME=/usr/local/opengauss
    export PATH=$GAUSSHOME/bin:$PATH
    export LD_LIBRARY_PATH=$GAUSSHOME/lib:$LD_LIBRARY_PATH
    export LANG=en_US.UTF-8
    
    file_env() {
            local var="$1"
            local fileVar="${var}_FILE"
            local def="${2:-}"
            if [ "${!var:-}" ] && [ "${!fileVar:-}" ]; then
                    echo >&2 "error: both $var and $fileVar are set (but are exclusive)"
                    exit 1
            fi
            local val="$def"
            if [ "${!var:-}" ]; then
                    val="${!var}"
            elif [ "${!fileVar:-}" ]; then
                    val="$(< "${!fileVar}")"
            fi
            export "$var"="$val"
            unset "$fileVar"
    }
    
    # check to see if this file is being run or sourced from another script
    _is_sourced() {
            [ "${#FUNCNAME[@]}" -ge 2 ] \
                    && [ "${FUNCNAME[0]}" = '_is_sourced' ] \
                    && [ "${FUNCNAME[1]}" = 'source' ]
    }
    
    # used to create initial opengauss directories and if run as root, ensure ownership belong to the omm user
    docker_create_db_directories() {
            local user; user="$(id -u)"
    
            mkdir -p "$PGDATA"
            chmod 700 "$PGDATA"
    
            # ignore failure since it will be fine when using the image provided directory;
            mkdir -p /var/run/opengauss || :
            chmod 775 /var/run/opengauss || :
    
            # Create the transaction log directory before initdb is run so the directory is owned by the correct user
            if [ -n "$POSTGRES_INITDB_XLOGDIR" ]; then
                    mkdir -p "$POSTGRES_INITDB_XLOGDIR"
                    if [ "$user" = '0' ]; then
                            find "$POSTGRES_INITDB_XLOGDIR" \! -user postgres -exec chown postgres '{}' +
                    fi
                    chmod 700 "$POSTGRES_INITDB_XLOGDIR"
            fi
    
            # allow the container to be started with `--user`
            if [ "$user" = '0' ]; then
                    find "$PGDATA" \! -user omm -exec chown omm '{}' +
                    find /var/run/opengauss \! -user omm -exec chown omm '{}' +
            fi
    }
    
    # initialize empty PGDATA directory with new database via 'initdb'
    # arguments to `initdb` can be passed via POSTGRES_INITDB_ARGS or as arguments to this function
    # `initdb` automatically creates the "postgres", "template0", and "template1" dbnames
    # this is also where the database user is created, specified by `GS_USER` env
    docker_init_database_dir() {
            # "initdb" is particular about the current user existing in "/etc/passwd", so we use "nss_wrapper" to fake that if necessary
            if ! getent passwd "$(id -u)" &> /dev/null && [ -e /usr/lib/libnss_wrapper.so ]; then
                    export LD_PRELOAD='/usr/lib/libnss_wrapper.so'
                    export NSS_WRAPPER_PASSWD="$(mktemp)"
                    export NSS_WRAPPER_GROUP="$(mktemp)"
                    echo "postgres:x:$(id -u):$(id -g):PostgreSQL:$PGDATA:/bin/false" > "$NSS_WRAPPER_PASSWD"
                    echo "postgres:x:$(id -g):" > "$NSS_WRAPPER_GROUP"
            fi
    
            if [ -n "$POSTGRES_INITDB_XLOGDIR" ]; then
                    set -- --xlogdir "$POSTGRES_INITDB_XLOGDIR" "$@"
            fi
    
            cmdbase="gs_initdb --pwfile=<(echo "$GS_PASSWORD")"
          
            if [ -n "$GS_NODENAME" ]; then
                    cmdbase="$cmdbase --nodename=$GS_NODENAME"
            else
                    cmdbase="$cmdbase --nodename=gaussdb"
            fi
    
            if [ -n "$ENCODING" ]; then
                    cmdbase="$cmdbase --encoding=$ENCODING"
            else
                    cmdbase="$cmdbase --encoding=UTF-8"
            fi
    
            if [ -n "$LOCALE" ]; then
                    cmdbase="$cmdbase --locale=$LOCALE"
            else
                    cmdbase="$cmdbase --no-locale"
            fi
    
            if [ -n "$DBCOMPATIBILITY" ]; then
                    cmdbase="$cmdbase --dbcompatibility=$DBCOMPATIBILITY"
            else
                    cmdbase="$cmdbase --dbcompatibility=PG"
            fi
            if [ -n "$GS_USER" ]; then
                cmdbase="$cmdbase --user=$GS_USER"
            fi
    
            cmdbase="$cmdbase -D $PGDATA"
    
            eval $cmdbase
    
            # unset/cleanup "nss_wrapper" bits
            if [ "${LD_PRELOAD:-}" = '/usr/lib/libnss_wrapper.so' ]; then
                    rm -f "$NSS_WRAPPER_PASSWD" "$NSS_WRAPPER_GROUP"
                    unset LD_PRELOAD NSS_WRAPPER_PASSWD NSS_WRAPPER_GROUP
            fi
    }
    
    # print large warning if GS_PASSWORD is long
    # error if both GS_PASSWORD is empty and GS_HOST_AUTH_METHOD is not 'trust'
    # print large warning if GS_HOST_AUTH_METHOD is set to 'trust'
    # assumes database is not set up, ie: [ -z "$DATABASE_ALREADY_EXISTS" ]
    docker_verify_minimum_env() {
            # check password first so we can output the warning before postgres
            # messes it up
            if [[ "$GS_PASSWORD" =~  ^(.{8,}).*$ ]] &&  [[ "$GS_PASSWORD" =~ ^(.*[a-z]+).*$ ]] && [[ "$GS_PASSWORD" =~ ^(.*[A-Z]).*$ ]] &&  [[ "$GS_PASSWORD" =~ ^(.*[0-9]).*$ ]] && [[ "$GS_PASSWORD" =~ ^(.*[#?!@$%^&*-]).*$ ]]; then
                    cat >&2 <<-'EOWARN'
    
                            Message: The supplied GS_PASSWORD is meet requirements.
    
    EOWARN
            else
                     cat >&2 <<-'EOWARN'
    
                            Error: The supplied GS_PASSWORD is not meet requirements.
                            Please Check if the password contains uppercase, lowercase, numbers, special characters, and password length(8).
                            At least one uppercase, lowercase, numeric, special character.
                            Example: Enmo@123
    EOWARN
           exit 1
            fi
            if [ -z "$GS_PASSWORD" ] && [ 'trust' != "$GS_HOST_AUTH_METHOD" ]; then
                    # The - option suppresses leading tabs but *not* spaces. :)
                    cat >&2 <<-'EOE'
                            Error: Database is uninitialized and superuser password is not specified.
                                   You must specify GS_PASSWORD to a non-empty value for the
                                   superuser. For example, "-e GS_PASSWORD=password" on "docker run".
    
                                   You may also use "GS_HOST_AUTH_METHOD=trust" to allow all
                                   connections without a password. This is *not* recommended.
    
    EOE
                    exit 1
            fi
            if [ 'trust' = "$GS_HOST_AUTH_METHOD" ]; then
                    cat >&2 <<-'EOWARN'
                            ********************************************************************************
                            WARNING: GS_HOST_AUTH_METHOD has been set to "trust". This will allow
                                     anyone with access to the opengauss port to access your database without
                                     a password, even if GS_PASSWORD is set.
                                     It is not recommended to use GS_HOST_AUTH_METHOD=trust. Replace
                                     it with "-e GS_PASSWORD=password" instead to set a password in
                                     "docker run".
                            ********************************************************************************
    EOWARN
            fi
    }
    
    # usage: docker_process_init_files [file [file [...]]]
    #    ie: docker_process_init_files /always-initdb.d/*
    # process initializer files, based on file extensions and permissions
    docker_process_init_files() {
            # gsql here for backwards compatiblilty "${gsql[@]}"
            gsql=( docker_process_sql )
    
            echo
            local f
            for f; do
                    case "$f" in
                            *.sh)
                                    if [ -x "$f" ]; then
                                            echo "$0: running $f"
                                            "$f"
                                    else
                                            echo "$0: sourcing $f"
                                            . "$f"
                                    fi
                                    ;;
                            *.sql)    echo "$0: running $f"; docker_process_sql -f "$f"; echo ;;
                            *.sql.gz) echo "$0: running $f"; gunzip -c "$f" | docker_process_sql; echo ;;
                            *.sql.xz) echo "$0: running $f"; xzcat "$f" | docker_process_sql; echo ;;
                            *)        echo "$0: ignoring $f" ;;
                    esac
                    echo
            done
    }
    
    # Execute sql script, passed via stdin (or -f flag of pqsl)
    # usage: docker_process_sql [gsql-cli-args]
    #    ie: docker_process_sql --dbname=mydb <<<'INSERT ...'
    #    ie: docker_process_sql -f my-file.sql
    #    ie: docker_process_sql <my-file.sql
    docker_process_sql() {
            local query_runner=( gsql -v ON_ERROR_STOP=1 --username "$GS_USER" --password "$GS_PASSWORD")
            if [ -n "$GS_DB" ]; then
                    query_runner+=( --dbname "$GS_DB" )
            fi
    
            echo "Execute SQL: ${query_runner[@]} $@"
            "${query_runner[@]}" "$@"
    }
    
    # create initial database
    # uses environment variables for input: GS_DB
    docker_setup_db() {
            echo "GS_DB = $GS_DB"
            if [ "$GS_DB" != 'postgres' ]; then
                    GS_DB= docker_process_sql --dbname postgres --set db="$GS_DB" --set passwd="$GS_PASSWORD" <<-'EOSQL'
                            CREATE DATABASE :"db" ;
    
    EOSQL
                    echo
            fi
    }
    
    docker_setup_user() {
            if [ -n "$GS_USERNAME" ]; then
                    GS_DB= docker_process_sql --dbname postgres --set db="$GS_DB" --set passwd="$GS_PASSWORD" --set user="$GS_USERNAME" <<-'EOSQL'
                            create user :"user" with login password :"passwd" ;
                            grant all privileges to :"user" ;
    
    EOSQL
                    echo "default user is $GS_USERNAME"
            else
                    echo "default user is gaussdb"
            fi
    }
    
    
    docker_setup_rep_user() {
            if [ -n "$SERVER_MODE" ] && [ "$SERVER_MODE" = "primary" ]; then
                    GS_DB= docker_process_sql --dbname postgres --set passwd="RepUser@2020" --set user="repuser" <<-'EOSQL'
                            create user :"user" SYSADMIN REPLICATION password :"passwd" ;
    EOSQL
            else
                    echo " default no repuser created"
            fi
    }
    
    # Loads various settings that are used elsewhere in the script
    # This should be called before any other functions
    docker_setup_env() {
            export GS_USER=omm
            file_env 'POSTGRES_INITDB_ARGS'
            # default authentication method is md5
            : "${GS_HOST_AUTH_METHOD:=md5}"
    
            declare -g DATABASE_ALREADY_EXISTS
            # look specifically for OG_VERSION, as it is expected in the DB dir
            if [ -s "$PGDATA/PG_VERSION" ]; then
                    DATABASE_ALREADY_EXISTS='true'
            fi
    }
    
    # append GS_HOST_AUTH_METHOD to pg_hba.conf for "host" connections
    opengauss_setup_hba_conf() {
            if [ -e /tmp/pg_hba.conf ]; then
                cat /tmp/pg_hba.conf > "$PGDATA/pg_hba.conf"
                echo "Successfully replaced $PGDATA/pg_hba.conf with /tmp/pg_hba.conf."
            else
                {
                               echo
                               if [ 'trust' = "$GS_HOST_AUTH_METHOD" ]; then
                                       echo '# warning trust is enabled for all connections'
                               fi
                               echo "host all all 0.0.0.0/0 $GS_HOST_AUTH_METHOD"
                               echo "host replication gaussdb 0.0.0.0/0 md5"
                               if [ -n "$SERVER_MODE" ]; then
                                   echo "host replication repuser $OG_SUBNET trust"
                               fi
                       } >> "$PGDATA/pg_hba.conf"
            fi
    }
    
    # append parameter to postgres.conf for connections
    opengauss_setup_postgresql_conf() {
            if [ -e /tmp/postgresql.conf ]; then
                cat /tmp/postgresql.conf > "$PGDATA/postgresql.conf"
                echo "Successfully replaced $PGDATA/postgresql.conf with /tmp/postgresql.conf."
            else
                {
                                echo
                                if [ -n "$GS_PORT" ]; then
                                    echo "password_encryption_type = 1"
                                    echo "port = $GS_PORT"
                                    echo "wal_level = logical"
                                else
                                    echo '# use default port 5432'
                                    echo "password_encryption_type = 1"
                                    echo "wal_level = logical"
                                fi
    
                                if [ -n "$SERVER_MODE" ]; then
                                    echo "listen_addresses = '0.0.0.0'"
                                    echo "most_available_sync = on"
                                    echo "remote_read_mode = non_authentication"
                                    echo "pgxc_node_name = '$NODE_NAME'"
                                    echo -e "$REPL_CONN_INFO"
                                    if [ -n "$SYNCHRONOUS_STANDBY_NAMES" ]; then
                                        echo "synchronous_standby_names=$SYNCHRONOUS_STANDBY_NAMES"
                                    fi
                                else
                                    echo "listen_addresses = '*'"
                                fi
    
                                if [ -n "$OTHER_PG_CONF" ]; then
                                    echo -e "$OTHER_PG_CONF"
                                fi
    
                        } >> "$PGDATA/postgresql.conf"
            fi
    }
    opengauss_setup_mot_conf() {
             echo "enable_numa = false" >> "$PGDATA/mot.conf"
    }
    
    # start socket-only postgresql server for setting up or running scripts
    # all arguments will be passed along as arguments to `postgres` (via pg_ctl)
    docker_temp_server_start() {
            if [ "$1" = 'gaussdb' ]; then
                    shift
            fi
    
            # internal start of server in order to allow setup using gsql client
            # does not listen on external TCP/IP and waits until start finishes
            set -- "$@" -c listen_addresses='' -p "${PGPORT:-5432}"
    
            PGUSER="${PGUSER:-$GS_USER}" \
            gs_ctl -D "$PGDATA" \
                    -o "$(printf '%q ' "$@")" \
                    -w start
    }
    
    # stop postgresql server after done setting up user and running scripts
    docker_temp_server_stop() {
            PGUSER="${PGUSER:-postgres}" \
            gs_ctl -D "$PGDATA" -m fast -w stop
    }
    
    docker_slave_full_backup() {
            gs_ctl build -D "$PGDATA" -b full
    }
    
    # check arguments for an option that would cause opengauss to stop
    # return true if there is one
    
    _opengauss_want_help() {
            local arg
            count=1
            for arg; do
                    case "$arg" in
                            # postgres --help | grep 'then exit'
                            # leaving out -C on purpose since it always fails and is unhelpful:
                            # postgres: could not access the server configuration file "/var/lib/postgresql/data/postgresql.conf": No such file or directory
                            -'?'|--help|--describe-config|-V|--version)
                                    return 0
                                    ;;
                    esac
                    if [ "$arg" == "-M" ]; then
                            SERVER_MODE=${@:$count+1:1}
                            echo "openGauss DB SERVER_MODE = $SERVER_MODE"
                            shift
                    fi
                    count=$[$count + 1]
            done
            return 1
    }
    
    _main() {
            # if first arg looks like a flag, assume we want to run postgres server
            if [ "${1:0:1}" = '-' ]; then
                    set -- gaussdb "$@"
            fi
    
            if [ "$1" = 'gaussdb' ] && ! _opengauss_want_help "$@"; then
                    docker_setup_env
                    # setup data directories and permissions (when run as root)
                    docker_create_db_directories
                    if [ "$(id -u)" = '0' ]; then
                            # then restart script as postgres user
                            exec gosu omm "$BASH_SOURCE" "$@"
                    fi
    
                    # only run initialization on an empty data directory
                    if [ -z "$DATABASE_ALREADY_EXISTS" ]; then
                            docker_verify_minimum_env
    
                            # check dir permissions to reduce likelihood of half-initialized database
                            ls /docker-entrypoint-initdb.d/ > /dev/null
    
                            docker_init_database_dir
                            opengauss_setup_hba_conf
                            opengauss_setup_postgresql_conf
                            opengauss_setup_mot_conf
    
                            # PGPASSWORD is required for gsql when authentication is required for 'local' connections via pg_hba.conf and is otherwise harmless
                            # e.g. when '--auth=md5' or '--auth-local=md5' is used in POSTGRES_INITDB_ARGS
                            export PGPASSWORD="${PGPASSWORD:-$GS_PASSWORD}"
                            docker_temp_server_start "$@"
                            if [ -z "$SERVER_MODE" ] || [ "$SERVER_MODE" = "primary" ]; then
                            docker_setup_db
                            docker_setup_user
                            docker_setup_rep_user
                            docker_process_init_files /docker-entrypoint-initdb.d/*
                            fi
    
                            if [ -n "$SERVER_MODE" ] && [ "$SERVER_MODE" != "primary" ]; then
                                docker_slave_full_backup
                            fi
                            docker_temp_server_stop
                            unset PGPASSWORD
    
                            echo
                            echo 'openGauss  init process complete; ready for start up.'
                            echo
                    else
                            echo
                            echo 'openGauss Database directory appears to contain a database; Skipping initialization'
                            echo
                    fi
            fi
            exec "$@"
    }
    
    if ! _is_sourced; then
            _main "$@"
    fi
---
# Source: opengauss/templates/clusterdefinition.yaml
apiVersion: apps.kubeblocks.io/v1alpha1
kind: ClusterDefinition
metadata:
  name: opengauss
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  type: opengauss
  connectionCredential:
    username: kbadmin
    password: "p@ssW0rd1"
    endpoint: "$(SVC_FQDN):$(SVC_PORT_tcp-opengauss)"
    host: "$(SVC_FQDN)"
    port: "$(SVC_PORT_tcp-opengauss)"
  componentDefs:
    - name: opengauss
      workloadType: Stateful
      characterType: opengauss
      configSpecs:
        - name: opengauss-configuration
          templateRef: opengauss-configuration
          constraintRef: opengauss-cc
          keys:
            - postgresql.conf
          namespace: default
          volumeName: opengauss-config
          defaultMode: 0777
        - name: opengauss-custom-metrics
          templateRef: opengauss-custom-metrics
          namespace: default
          volumeName: opengauss-custom-metrics
          defaultMode: 0777
        - name: agamotto-configuration
          templateRef: opengauss-agamotto-configuration
          namespace: default
          volumeName: agamotto-configuration
          defaultMode: 0777
      scriptSpecs:
        - name: opengauss-scripts
          templateRef: opengauss-scripts
          namespace: default
          volumeName: scripts
          defaultMode: 0777
      logConfigs:
        - name: running
          filePathPattern: /var/lib/opengauss/data/pg_log/postgresql-*
      service:
        ports:
          - name: tcp-opengauss
            port: 5432
            targetPort: tcp-opengauss
      volumeTypes:
        - name: data
          type: data
        - name: log
          type: log
      podSpec:
        securityContext:
          runAsUser: 0
          fsGroup: 103
          runAsGroup: 103
        containers:
          - name: opengauss
            imagePullPolicy: IfNotPresent
            command:
              - sh
              - -c
              - |
                cp /home/omm/conf/* /tmp/
                chmod 777 /tmp/postgresql.conf /tmp/pg_hba.conf
                /kb-scripts/setup.sh gaussdb
            securityContext:
              runAsUser: 0
            ports:
              - name: tcp-opengauss
                containerPort: 5432
            env:
              - name: GS_USERNAME
                valueFrom:
                  secretKeyRef:
                    name: $(CONN_CREDENTIAL_SECRET_NAME)
                    key: username
              - name: GS_PASSWORD
                valueFrom:
                  secretKeyRef:
                    name: $(CONN_CREDENTIAL_SECRET_NAME)
                    key: password
              - name: GS_DB
                value: opengauss
              - name: GAUSSLOG
                value: /var/log/opengauss
              - name: PATH
                value: /usr/local/opengauss/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
              - name: GAUSSHOME
                value: /usr/local/opengauss
              - name: LD_LIBRARY_PATH
                value: /usr/local/opengauss/lib
              - name: PGDATA
                value: /var/lib/opengauss/data
            volumeMounts:
              - name: data
                mountPath: /var/lib/opengauss/data
              - name: log
                mountPath: /var/log/opengauss
              - name: scripts
                mountPath: /kb-scripts
              - name: opengauss-config
                mountPath: /home/omm/conf
        volumes:
          - name: dshm
            emptyDir:
              medium: Memory
---
# Source: opengauss/templates/clusterversion.yaml
apiVersion: apps.kubeblocks.io/v1alpha1
kind: ClusterVersion
metadata:
  # major version of the component defined in values.yaml
  name: opengauss-3.0.0
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  clusterDefinitionRef: opengauss
  componentVersions:
    - componentDefRef: opengauss
      versionsContext:
        containers:
          - name: opengauss
            image: docker.io/apecloud/opengauss:3.0.0
      systemAccountSpec:
        cmdExecutorConfig:
          image: docker.io/apecloud/opengauss:3.0.0
---
# Source: opengauss/templates/configconstraint.yaml
apiVersion: apps.kubeblocks.io/v1beta1
kind: ConfigConstraint
metadata:
  name: opengauss-cc
  labels:
    helm.sh/chart: opengauss-0.9.0
    app.kubernetes.io/name: opengauss
    app.kubernetes.io/instance: my-opengauss
    app.kubernetes.io/version: "5.0.0"
    app.kubernetes.io/managed-by: Helm
spec:
  # ConfigurationSchema that impose restrictions on engine parameter's rule
  parametersSchema:
    # top level pg configuration type
    topLevelKey: PGParameter

    # schemaInJSON: auto generate from cue scripts
    # example: ../../pkg/configuration/testdata/mysql_openapi.json
    cue: |-
      //Copyright (C) 2022-2023 ApeCloud Co., Ltd
      //
      //This file is part of KubeBlocks project
      //
      //This program is free software: you can redistribute it and/or modify
      //it under the terms of the GNU Affero General Public License as published by
      //the Free Software Foundation, either version 3 of the License, or
      //(at your option) any later version.
      //
      //This program is distributed in the hope that it will be useful
      //but WITHOUT ANY WARRANTY; without even the implied warranty of
      //MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
      //GNU Affero General Public License for more details.
      //
      //You should have received a copy of the GNU Affero General Public License
      //along with this program.  If not, see <http://www.gnu.org/licenses/>.
      
      // PostgreSQL parameters: https://postgresqlco.nf/doc/en/param/
      #PGParameter: {
      	// use data in another directory
      	data_directory?: string
      
      	// host-based authentication file
      	hba_file?: string
      
      	// ident configuration file
      	ident_file?: string
      
      	// If external_pid_file is not explicitly set, no extra PID file is written.
      	external_pid_file?: string
      
      	// what IP address(es) to listen on;
      	// comma-separated list of addresses;
      	// defaults to 'localhost'; use '*' for all
      	// (change requires restart)
      	listen_addresses?: string
      
      	local_bind_address?: string
      
      	// (change requires restart)
      	port?: int & >=1 & <=65535
      
      	// (change requires restart)
      	max_connections: int & >=0 & <=10000
      
      	// Note: Increasing max_connections costs ~400 bytes of shared memory per
      	// connection slot, plus lock space (see max_locks_per_transaction).
      	// (change requires restart)
      	sysadmin_reserved_connections?: int & >=0
      
      	// (change requires restart)
      	unix_socket_directory?: string
      
      	// (change requires restart)
      	unix_socket_group?: string
      
      	// begin with 0 to use octal notation
      	// (change requires restart)
      	unix_socket_permissions?: int & >=0 & <=4095
      
      	// 1s-600s
      	authentication_timeout: int & >=1 & <=600 @timeDurationResource(1s)
      
      	// allowed duration of any unused session, 0s-86400s (1 day), 0 is disabled
      	session_timeout: int & >=0 & <=86400 @timeDurationResource(1s)
      
      	// (change requires restart)
      	ssl?: string & "on" | "off"
      
      	// allowed SSL ciphers
      	// (change requires restart)
      	ssl_ciphers?: string
      
      	// 7-180 days
      	ssl_cert_notify_time: int & >=7 & <=180
      
      	// amount of data between renegotiations, no longer supported
      	// (change requires restart)
      	ssl_renegotiation_limit?: int
      
      	// (change requires restart)
      	ssl_cert_file?: string
      
      	// (change requires restart)
      	ssl_key_file?: string
      
      	// (change requires restart)
      	ssl_ca_file?: string
      
      	// (change requires restart)
      	ssl_crl_file?: string
      
      	// Kerberos and GSSAPI
      	// (change requires restart)
      	krb_server_keyfile?: string
      
      	// (Kerberos only)
      	krb_srvname?: string
      
      	// krb_caseins_users = off
      	krb_caseins_users?: string & "on" | "off"
      
      	// Whether to change the initial password of the initial user
      	modify_initial_password?: string & "on" | "off"
      
      	// Whether password complexity checks
      	password_policy?: int & >=0 & <=1
      
      	// Whether the new password can be reused in password_reuse_time days
      	password_reuse_time?: int & >=0
      
      	// Whether the new password can be reused
      	password_reuse_max?: int & >=0
      
      	// The account will be unlocked automatically after a specified period of time
      	password_lock_time?: int & >=0
      
      	// Enter the wrong password reached failed_login_attempts times, the current account will be locked
      	failed_login_attempts?: int & >=0
      
      	// Password storage type, 0 is md5 for PG, 1 is sha256 + md5, 2 is sha256 only
      	password_encryption_type?: int & >=0 & <=2
      
      	// The minimal password length(6-999)
      	password_min_length?: int & >=6 & <=999
      
      	// The maximal password length(6-999)
      	password_max_length?: int & >=6 & <=999
      
      	// The minimal upper character number in password(0-999)
      	password_min_uppercase?: int & >=0 & <=999
      
      	// The minimal lower character number in password(0-999)
      	password_min_lowercase?: int & >=0 & <=999
      
      	// The minimal digital character number in password(0-999)
      	password_min_digital?: int & >=0 & <=999
      
      	// The minimal special character number in password(0-999)
      	password_min_special?: int & >=0 & <=999
      
      	// The password effect time(0-999)
      	password_effect_time?: int & >=0 & <=999
      
      	// The password notify time(0-999)
      	password_notify_time?: int & >=0 & <=999
      
      	// TCP_KEEPIDLE, in seconds; 0 selects the system default
      	tcp_keepalives_idle?: int & >=0
      
      	// TCP_KEEPINTVL, in seconds; 0 selects the system default
      	tcp_keepalives_interval?: int & >=0
      
      	// TCP_KEEPCNT; 0 selects the system default
      	tcp_keepalives_count?: int & >=0
      
      
      	// memorypool_enable = false
      	memorypool_enable?: string & "on" | "off"
      
      	// memorypool_size = 512MB
      	memorypool_size?: string
      
      	// enable_memory_limit = true
      	enable_memory_limit?: string & "on" | "off"
      
      	// max_process_memory = 12GB
      	max_process_memory?: string
      
      	// UDFWorkerMemHardLimit = 1GB
      	UDFWorkerMemHardLimit?: string
      
      	// min 128kB
      	// (change requires restart)
      	shared_buffers: string
      
      	// for bulkload, max shared_buffers
      	bulk_write_ring_size?: string
      
      	// control shared buffers use in standby, 0.1-1.0
      	standby_shared_buffers_fraction?: float
      
      	// min 800kB
      	temp_buffers?: string
      
      	// zero disables the feature
      	// (change requires restart)
      	max_prepared_transactions: int & >=0
      
      	// min 64kB
      	work_mem?: string
      
      	// min 1MB
      	maintenance_work_mem?: string
      
      	// min 100kB
      	max_stack_depth?: string
      
      	// min 16MB
      	cstore_buffers?: string
      
      	// limits per-session temp file space in kB, or -1 for no limit
      	temp_file_limit?: int
      
      	// limits for single SQL used space on single DN in kB, or -1 for no limit
      	sql_use_spacelimit?: int
      
      	// min 25
      	max_files_per_process?: int
      
      	// (change requires restart)
      	shared_preload_libraries?: string
      
      	// 0-100 milliseconds
      	vacuum_cost_delay?: int @timeDurationResource(1ms)
      
      	// 0-10000 credits
      	vacuum_cost_page_hit?: int & >=0 & <=10000
      
      	// 0-10000 credits
      	vacuum_cost_page_miss?: int & >=0 & <=10000
      
      	// 0-10000 credits
      	vacuum_cost_page_dirty?: int & >=0 & <=10000
      
      	// 1-10000 credits
      	vacuum_cost_limit?: int & >=1 & <=10000
      
      	// 10-10000ms between rounds
      	bgwriter_delay?: int @timeDurationResource(1ms)
      
      	// 0-1000 max buffers written/round
      	bgwriter_lru_maxpages?: int & >=0 & <=1000
      
      	// 0-10.0 multipler on buffers scanned/round
      	bgwriter_lru_multiplier?: float & >=0 & <=10.0
      
      	// minimal, archive, hot_standby or logical
      	// (change requires restart)
      	wal_level?: string
      
      	// turns forced synchronization on or off
      	fsync?: string & "on" | "off"
      
      	// synchronization level;
      	// off, local, remote_receive, remote_write, or on
      	// It's global control for all transactions
      	// It could not be modified by gs_ctl reload, unless use setsyncmode.
      	synchronous_commit?: string
      
      	// Selects the method used for forcing WAL updates to disk.
      	wal_sync_method?: string & "fsync" | "fdatasync" | "open_sync" | "open_datasync" | "fsync_writethrough"
      
      	// recover from partial page writes
      	full_page_writes?: string & "on" | "off"
      
      	// min 32kB
      	// (change requires restart)
      	wal_buffers?: string
      
      	// 1-10000 milliseconds
      	wal_writer_delay?: int @timeDurationResource(1ms)
      
      	// range 0-100000, in microseconds
      	commit_delay?: int @timeDurationResource(1us)
      
      	// range 1-1000
      	commit_siblings?: int & >=1 & <=1000
      
      	// in logfile segments, min 1, 16MB each
      	checkpoint_segments?: int & >=1
      
      	// range 30s-1h
      	checkpoint_timeout?: int @timeDurationResource(1s)
      
      	// checkpoint target duration, 0.0 - 1.0
      	checkpoint_completion_target?: float & >=0.0 & <=1.0
      
      	// 0 disables
      	checkpoint_warning?: int @timeDurationResource(1s)
      
      	// maximum time wait checkpointer to start
      	checkpoint_wait_timeout?: int @timeDurationResource(1s)
      
      	// enable incremental checkpoint
      	enable_incremental_checkpoint?: string & "on" | "off"
      
      	// range 1s-1h
      	incremental_checkpoint_timeout?: int & >=1 & <=3600 @timeDurationResource(1s)
      
      	// dirty page writer sleep time, 0ms - 1h
      	pagewriter_sleep?: int & >=1 & <=360000 @timeDurationResource(1ms)
      
      	archive_mode?: string
      
      	archive_command?: string
      
      	archive_timeout?: int @timeDurationResource(1s)
      
      	// path to use to archive a logfile segment
      	archive_dest?: string
      
      
      	//------------------------------------------------
      	//  REPLICATION
      	//-------------------------------------------------
      	// The heartbeat interval of the standby nodes.
      	// The value is best configured less than half of
      	// the wal_receiver_timeout and wal_sender_timeout.
      	datanode_heartbeat_interval?: string @timeDurationResource(1s)
      
      	// max number of walsender processes
      	// (change requires restart)
      	max_wal_senders?: int
      
      	// in logfile segments, 16MB each; 0 disables
      	wal_keep_segments?: int & >=0
      
      	// in milliseconds; 0 disables
      	wal_sender_timeout?: int @timeDurationResource(1ms)
      
      	enable_slot_log?: string & "on" | "off"
      
      	// max number of replication slots.
      	// The value belongs to [1,7].
      	// (change requires restart)
      	max_replication_slots?: int & >=1 & <=8
      
      	max_changes_in_memory?: int
      
      	max_cached_tuplebufs?: int
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// or connect primary or standby on secondary
      	// The heartbeat thread will not start if not set localheartbeatport and remoteheartbeatport.
      	// e.g. 'localhost=10.145.130.2 localport=12211 localheartbeatport=12214 remotehost=10.145.130.3 remoteport=12212 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12213 remotehost=10.145.133.3 remoteport=12214'
      	replconninfo1?: string
      
      	// replication connection information used to connect secondary on primary or standby,
      	// or connect primary or standby on secondary
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.4 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.4 remoteport=12314'
      	replconninfo2?: string
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.5 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.5 remoteport=12314'
      	replconninfo3?: string
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.6 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.6 remoteport=12314'
      	replconninfo4?: string
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.7 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.7 remoteport=12314'
      	replconninfo5?: string
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.8 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.8 remoteport=12314'
      	replconninfo6?: string
      
      	// replication connection information used to connect primary on standby, or standby on primary,
      	// e.g. 'localhost=10.145.130.2 localport=12311 localheartbeatport=12214 remotehost=10.145.130.9 remoteport=12312 remoteheartbeatport=12215, localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
      	replconninfo7?: string
      
      	// replication connection information used to connect primary on primary cluster, or standby on standby cluster,
      	// e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
      	cross_cluster_replconninfo1?: string
      
      	// replication connection information used to connect primary on primary cluster, or standby on standby cluster,
      	// e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
      	cross_cluster_replconninfo2?: string
      
        // replication connection information used to connect primary on primary cluster, or standby on standby cluster,
      	// e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
      	cross_cluster_replconninfo3?: string
      
      	// replication connection information used to connect primary on primary cluster, or standby on standby cluster,
      	// e.g. 'localhost=10.145.133.2 localport=12313 remotehost=10.145.133.9 remoteport=12314'
      	cross_cluster_replconninfo4?: string
      
      	//  Master Server
      	// standby servers that provide sync rep
      	// comma-separated list of application_name
      	// from standby(s); '*' = all
      	// These settings are ignored on a standby server.
      	synchronous_standby_names?: string
      
      	// Whether master is allowed to continue
      	// as standbalone after sync standby failure
      	// It's global control for all transactions
      	most_available_sync?: string & "on" | "off"
      
      	// number of xacts by which cleanup is delayed
      	vacuum_defer_cleanup_age?: int
      
      	// data replication buffer size
      	data_replicate_buffer_size?: string
      
      	// Size of walsender max send size
      	walsender_max_send_size?: string
      
      	enable_data_replicate?: string & "on" | "off"
      
      	///  Standby Server
      	// "on" allows queries during recovery
      	// (change requires restart)
      	// These settings are ignored on a master server.
      	hot_standby?: string & "on" | "off"
      
      	// max delay before canceling queries
      	// when reading WAL from archive;
      	// -1 allows indefinite delay
      	max_standby_archive_delay?: string
      
      	// max delay before canceling queries
      	// when reading streaming WAL;
      	// -1 allows indefinite delay
      	max_standby_streaming_delay?: string
      
      	// send replies at least this often
      	// 0 disables
      	wal_receiver_status_interval?: string
      
      	// send info from standby to prevent
      	// query conflicts
      	hot_standby_feedback?: string & "on" | "off"
      
      	// time that receiver waits for
      	// communication from master
      	// in milliseconds; 0 disables
      	wal_receiver_timeout?: string
      
      	// timeout that receiver connect master
      	// in seconds; 0 disables
      	wal_receiver_connect_timeout?: string
      
      	// max retries that receiver connect master
      	wal_receiver_connect_retries?: int
      
      	// wal receiver buffer size
      	wal_receiver_buffer_size?: string
      
      	// xlog keep for all standbys even through they are not connecting and donnot created replslot.
      	enable_xlog_prune?: string & "on" | "off"
      
      	// xlog keep for the wal size less than max_xlog_size when the enable_xlog_prune is on
      	max_size_for_xlog_prune?: int
      
      	// Maximum number of logical replication worker processes.
      	max_logical_replication_workers?: int
      	// These settings are ignored on a master server.
      
      	enable_bitmapscan?: string & "on" | "off"
        enable_hashagg?: string & "on" | "off"
        enable_hashjoin?: string & "on" | "off"
        enable_indexscan?: string & "on" | "off"
        enable_indexonlyscan?: string & "on" | "off"
        enable_material?: string & "on" | "off"
        enable_mergejoin?: string & "on" | "off"
        enable_nestloop?: string & "on" | "off"
        enable_seqscan?: string & "on" | "off"
        enable_sort?: string & "on" | "off"
        enable_tidscan?: string & "on" | "off"
      
        enable_kill_query?: string
        // optional: [on, off], default: off
      
        // Planner Cost Constants
      
        seq_page_cost?: float
        // measured on an arbitrary scale
      
        random_page_cost?: float
        // same scale as above
      
        cpu_tuple_cost?: float
        // same scale as above
      
        cpu_index_tuple_cost?: float
        // same scale as above
      
        cpu_operator_cost?: float
        // same scale as above
      
        effective_cache_size?: string
      
        geqo?: string & "on" | "off"
      
        geqo_threshold?: int
      
        geqo_effort?: int
        // range 1-10
      
        geqo_pool_size?: int
        // selects default based on effort
      
        geqo_generations?: int
        // selects default based on effort
      
        geqo_selection_bias?: float
        // range 1.5-2.0
      
        geqo_seed?: float
        // range 0.0-1.0
      
        default_statistics_target?: int
        // range 1-10000
      
        constraint_exclusion?: string
        // on, off, or partition
      
        cursor_tuple_fraction?: float
        // range 0.0-1.0
      
        from_collapse_limit?: int
      
        join_collapse_limit?: int
        // 1 disables collapsing of explicit JOIN clauses
      
        plan_mode_seed?: int
        // range -1-0x7fffffff
      
        check_implicit_conversions?: string
        // off
      
        // Valid values are combinations of stderr, csvlog, syslog, and eventlog,
        // depending on platform. csvlog requires logging_collector to be on.
        log_destination?: string
      
        logging_collector?: string & "on" | "off"
        // Enable capturing of stderr and csvlog into log files. Required to be on for csvlogs.
        // (change requires restart)
      
        // directory where log files are written,
        // can be absolute or relative to PGDATA
        log_directory?: string
      
        // log file name pattern, can include strftime() escapes
        log_filename?: string
      
        // creation mode for log files, begin with 0 to use octal notation
        log_file_mode?: int
      
        // If on, an existing log file with the same name as the new log file will be
        // truncated rather than appended to. But such truncation only occurs on
        // time-driven rotation, not on restarts or size-driven rotation. Default is
        // off, meaning append to existing files in all cases.
        // log_truncate_on_rotation?: string
      
        // Automatic rotation of logfiles will happen after that time. 0 disables.
        // log_rotation_age?: string
      
        // Automatic rotation of logfiles will happen after that much log output.
        // 0 disables.
        log_rotation_size?: string
      
        syslog_facility?: string
        syslog_ident?: string
      
      	event_source?: string
      
      	log_min_messages?: string & "debug5" | "debug4" | "debug3" | "debug2" | "debug1" | "info" | "notice" | "warning" | "error" | "log" | "fatal" | "panic"
      	log_min_error_statement?: string & "debug5" | "debug4" | "debug3" | "debug2" | "debug1" | "info" | "notice" | "warning" | "error" | "log" | "fatal" | "panic"
      
      	log_min_duration_statement?: int @timeDurationResource(1min)
      
      	debug_print_parse?: string & "on" | "off"  
        debug_print_rewritten?: string & "on" | "off"  
        debug_print_plan?: string & "on" | "off"  
        debug_pretty_print?: string & "on" | "off"  
        log_checkpoints?: string & "on" | "off"  
        log_pagewriter?: string & "on" | "off"  
        log_connections?: string & "on" | "off"  
        log_disconnections?: string & "on" | "off"  
        log_duration?: string & "on" | "off"  
      
      	log_hostname?: string & "on" | "off"  
      	log_line_prefix?: string
      
      	log_lock_waits?: string & "on" | "off"  
      
      	log_statement?: string & "none" | "ddl" | "mod" | "all"
      	log_temp_files?: int & >=-1 & <=2147483647 @storeResource(1KB)
      
      
      	// Sets the time zone to use in log messages.
      	log_timezone?: string
      
      	enable_alarm?: string & "on" | "off"
      
      	connection_alarm_rate?: number
      
      	alarm_report_interval?: number
      
      	alarm_component?: string
      
      	track_activities?: string & "on" | "off"
      	track_counts?: string & "on" | "off"
      	track_io_timing?: string & "on" | "off"
      	track_functions?: string & "none"| "pl"| "all"
      	track_activity_query_size?: int
      	update_process_title?: string & "on" | "off"
      	stats_temp_directory?: string
      	track_thread_wait_status_interval?: string
      	track_sql_count?: string & "on" | "off"
      	enbale_instr_track_wait?: string & "on" | "off"
      
      	// Query Execution Statistics
      	log_parser_stats?: string
      	log_planner_stats?: string
      	log_executor_stats?: string
      	log_statement_stats?: string
      
      	use_workload_manager?: string
      
      
      	enable_security_policy?: string & "on" | "off"
      	use_elastic_search?: string & "on" | "off"
      	elastic_search_ip_addr?: string // what elastic search ip is, change https to http when elastic search is non-ssl mode
      
      	cpu_collect_timer?: int
      
      	autovacuum?: string & "on" | "off"
      
      	// (ms) Sets the minimum execution time above which autovacuum actions will be logged.
      	log_autovacuum_min_duration: int & >=-1 & <=2147483647 | *10000 @timeDurationResource()
      
      	// Sets the maximum number of simultaneously running autovacuum worker processes.
      	autovacuum_max_workers?: int & >=1 & <=8388607
      
      	// (s) Time to sleep between autovacuum runs.
      	autovacuum_naptime: int & >=1 & <=2147483 | *15 @timeDurationResource(1s)
      	// Minimum number of tuple updates or deletes prior to vacuum.
      	autovacuum_vacuum_threshold?: int & >=0 & <=2147483647
      	// Minimum number of tuple inserts, updates or deletes prior to analyze.
      	autovacuum_analyze_threshold?: int & >=0 & <=2147483647
      
      	// Number of tuple updates or deletes prior to vacuum as a fraction of reltuples.
      	autovacuum_vacuum_scale_factor: float & >=0 & <=100 | *0.1
      
      	// Number of tuple inserts, updates or deletes prior to analyze as a fraction of reltuples.
      	autovacuum_analyze_scale_factor: float & >=0 & <=100 | *0.05
      
      	// Age at which to autovacuum a table to prevent transaction ID wraparound.
      	autovacuum_freeze_max_age?: int & >=100000 & <=2000000000
      
      	// (ms) Vacuum cost delay in milliseconds, for autovacuum.
      	autovacuum_vacuum_cost_delay?: int & >=-1 & <=100 @timeDurationResource()
      
      	// Vacuum cost amount available before napping, for autovacuum.
      	autovacuum_vacuum_cost_limit?: int & >=-1 & <=10000
      
      	// Sets the message levels that are sent to the client.
      	client_min_messages?: string & "debug5" | "debug4" | "debug3" | "debug2" | "debug1" | "log" | "notice" | "warning" | "error"
      
      	// Sets the schema search order for names that are not schema-qualified.
      	search_path?: string
      
      	// Sets the default tablespace to create tables and indexes in.
      	default_tablespace?: string
      
      	// Sets the tablespace(s) to use for temporary tables and sort files.
      	temp_tablespaces?: string
      
      	// Check function bodies during CREATE FUNCTION.
      	check_function_bodies?: string & "on" | "off"  
      
      	// Sets the transaction isolation level of each new transaction.
      	default_transaction_isolation?: string & "serializable" | "repeatable read" | "read committed" | "read uncommitted"
      	// Sets the default read-only status of new transactions.
      	default_transaction_read_only?: string & "on" | "off"  
      
      
      	// Sets the default deferrable status of new transactions.
      	default_transaction_deferrable?: string & "on" | "off"  
      
      
      	// Sets the sessions behavior for triggers and rewrite rules.
      	session_replication_role?: string & "origin" | "replica" | "local"
      
      	// (ms) Sets the maximum allowed duration of any statement.
      	statement_timeout?: int & >=0 & <=2147483647 @timeDurationResource()
      
      	vacuum_freeze_min_age?: int & >=0 & <=1000000000
      
      	vacuum_freeze_table_age?: int & >=0 & <=2000000000
      
      	bytea_output?: string & "escape" | "hex"
      
      	xmlbinary?: string & "base64" | "hex"
      
      	xmloption?: string & "content" | "document"
      
      	max_compile_functions?: int
      
      	gin_pending_list_limit?: int & >=64 & <=2147483647 @storeResource(1KB)
      
      	// Sets the display format for date and time values.
      	datestyle?: string
      	// Sets the display format for interval values.
      	intervalstyle?: string & "postgres" | "postgres_verbose" | "sql_standard" | "iso_8601"
      
      	// Sets the time zone for displaying and interpreting time stamps.
      	timezone?: string
      
      	timezone_abbreviations ?: string
      
      	// Sets the number of digits displayed for floating-point values.
      	extra_float_digits?: int & >=-15 & <=3
      
      	// Sets the clients character set encoding.
      	client_encoding?: string
      
      	// Sets the language in which messages are displayed.
      	lc_messages?: string
      	// Sets the locale for formatting monetary amounts.
      	lc_monetary?: string
      
      	// Sets the locale for formatting numbers.
      	lc_numeric?: string
      
      	// Sets the locale for formatting date and time values.
      	lc_time?: string
      
      	default_text_search_config?: string
      
      	dynamic_library_path?: string
      
      	local_preload_libraries?: string
      	// (ms) Sets the time to wait on a lock before checking for deadlock.
      	deadlock_timeout?: int & >=1 & <=2147483647 @timeDurationResource()
      
      	lockwait_timeout?: string @timeDurationResource(1s) // Max of lockwait_timeout and deadlock_timeout + 1s
      	// Sets the maximum number of locks per transaction.
      	max_locks_per_transaction: int & >=10 & <=2147483647 | *64
      
      	// Sets the maximum number of predicate locks per transaction.
      	max_pred_locks_per_transaction?: int & >=10 & <=2147483647
      	// Enable input of NULL elements in arrays.
      	array_nulls?: string & "on" | "off"
      
      	// Sets whether "\" is allowed in string literals.
      	backslash_quote?: string & "safe_encoding" | "on" | "off"
      
      	default_with_oids?: string & "on" | "off"
      
      	// Warn about backslash escapes in ordinary string literals.
      	escape_string_warning?: string & "on" | "off"  
      
      	// Enables backward compatibility mode for privilege checks on large objects.
      	lo_compat_privileges ?: string & "on" | "off"
      
      	// Causes ... strings to treat backslashes literally.
      	standard_conforming_strings?: string & "on" | "off"  
      
      	// Enable synchronized sequential scans.
      	synchronize_seqscans?: string & "on" | "off"  
      
      	// Treats expr=NULL as expr IS NULL.
      	transform_null_equals?: string & "on" | "off"  
      
      
      	// Terminate session on any error.
      	exit_on_error?: string & "on" | "off"  
      
      	// Reinitialize server after backend crash.
      	restart_after_crash?: string & "on" | "off"  
      
      	omit_encoding_error?: string & "on" | "off"  
      
      	data_sync_retry?: string & "on" | "off"  
      
      	cache_connection?: string & "on" | "off"  
      
      	pgxc_node_name?: string
      
      	enforce_two_phase_commit?: string & "on" | "off"  
      
      	audit_enabled?: string & "on" | "off"
      	audit_directory?: string
      	audit_data_format?: string
      	audit_rotation_interval?: string  @timeDurationResource(1d)
      	audit_rotation_size?: int  @storeResource(1MB)
      	audit_space_limit?: int  @storeResource(1MB)
      	audit_file_remain_threshold?: int & >=0 & <=2147483647
      	audit_login_logout?: int & >=0
      	audit_database_process?: int & >=0
      	audit_user_locked?: int & >=0
      	audit_user_violation?: int & >=0
      	audit_grant_revoke?: int & >=0
      	audit_system_object?: int & >=0
      	audit_dml_state?: int & >=0
      	audit_dml_state_select?: int & >=0
      	audit_function_exec?: int & >=0
      	audit_copy_exec?: int & >=0
      	audit_set_parameter?: int & >=0
      	audit_xid_info?: int & >=0
      	audit_thread_num?: int & >=0
      
      	enableSeparationOfDuty?: string & "on" | "off"
      
      	enable_fast_allocate?: string & "on" | "off"
      	prefetch_quantity?: int  @storeResource(1MB)
      	backwrite_quantity?: int  @storeResource(1MB)
      	cstore_prefetch_quantity?: int & >=0
      	cstore_backwrite_quantity?: int & >=0
      	cstore_backwrite_max_threshold?: int & >=0
      	fast_extend_file_size?: int & >=0
      
      	enable_codegen?: string & "on" | "off"
      	enable_codegen_print?: string & "on" | "off"
      	codegen_cost_threshold?: int
      
      
      	job_queue_processes?: int & >=0 & <=1000
      
      	enable_dcf?: string & "on" | "off"
      	plsql_show_all_error?: string & "on" | "off"
      
      	...
      }
      
      configuration: #PGParameter & {
      }
      

  ##  require db instance restart
  ## staticParameters
  staticParameters:
    - shared_buffers
    - logging_collector
    - log_destination
    - log_directory
    - log_filename
    - log_file_mode
    - log_rotation_age
    - log_truncate_on_rotation
    - ssl
    - ssl_ca_file
    - ssl_crl_file
    - ssl_cert_file
    - ssl_key_file
    - shared_preload_libraries

  ## define immutable parameter list, this feature is not currently supported.
  immutableParameters:
    - archive_timeout
    - data_directory
    - exit_on_error
    - fsync
    - full_page_writes
    - hba_file
    - ident_file
    - listen_addresses
    - lo_compat_privileges
    - log_directory
    - log_file_mode
    - logging_collector
    - log_line_prefix
    - log_timezone
    - log_truncate_on_rotation
    - port
    - restart_after_crash
    - ssl
    - ssl_ca_file
    - ssl_cert_file
    - ssl_ciphers
    - ssl_key_file
    - stats_temp_directory
    - unix_socket_group
    - unix_socket_permissions
    - update_process_title
    - wal_sync_method



    # configuration file format
  fileFormatConfig:
    format: properties
